{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../Data2/\"\n",
    "data_file = \"Data_Tunes.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = '../Data2/Model_Weights/'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) \n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64): \n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    \n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))  \n",
    "        for batch_index in range(0, 16):   \n",
    "            for i in range(0, 64): \n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length), name = \"embd_1\")) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True, name = \"lstm_first\"))\n",
    "    model.add(Dropout(0.2, name = \"drp_1\"))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    model.load_weights(\"../Data/Model_Weights/Weights_80.h5\", by_name = True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 90):\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) \n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) \n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y)\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"../Data2/log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 87\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embd_1 (Embedding)           (16, 64, 512)             44544     \n",
      "_________________________________________________________________\n",
      "lstm_first (LSTM)            (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "drp_1 (Dropout)              (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (16, 64, 87)              22359     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (16, 64, 87)              0         \n",
      "=================================================================\n",
      "Total params: 1,904,983\n",
      "Trainable params: 1,904,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Total number of characters = 155222\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\viper3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 4.46612024307251, Accuracy: 0.0068359375\n",
      "Batch: 2, Loss: 4.447066783905029, Accuracy: 0.1748046875\n",
      "Batch: 3, Loss: 4.4128007888793945, Accuracy: 0.134765625\n",
      "Batch: 4, Loss: 4.320994853973389, Accuracy: 0.1025390625\n",
      "Batch: 5, Loss: 3.8982372283935547, Accuracy: 0.1435546875\n",
      "Batch: 6, Loss: 3.8405637741088867, Accuracy: 0.166015625\n",
      "Batch: 7, Loss: 3.581368923187256, Accuracy: 0.1640625\n",
      "Batch: 8, Loss: 3.613677978515625, Accuracy: 0.091796875\n",
      "Batch: 9, Loss: 3.6934750080108643, Accuracy: 0.060546875\n",
      "Batch: 10, Loss: 3.6075990200042725, Accuracy: 0.0615234375\n",
      "Batch: 11, Loss: 3.3685951232910156, Accuracy: 0.072265625\n",
      "Batch: 12, Loss: 3.529116153717041, Accuracy: 0.05859375\n",
      "Batch: 13, Loss: 3.717712879180908, Accuracy: 0.0703125\n",
      "Batch: 14, Loss: 3.436282157897949, Accuracy: 0.1396484375\n",
      "Batch: 15, Loss: 3.671248435974121, Accuracy: 0.1279296875\n",
      "Batch: 16, Loss: 3.380532741546631, Accuracy: 0.16015625\n",
      "Batch: 17, Loss: 3.3141872882843018, Accuracy: 0.1787109375\n",
      "Batch: 18, Loss: 3.3101189136505127, Accuracy: 0.171875\n",
      "Batch: 19, Loss: 3.585361957550049, Accuracy: 0.1298828125\n",
      "Batch: 20, Loss: 3.686293125152588, Accuracy: 0.1162109375\n",
      "Batch: 21, Loss: 3.505096673965454, Accuracy: 0.134765625\n",
      "Batch: 22, Loss: 3.292069435119629, Accuracy: 0.166015625\n",
      "Batch: 23, Loss: 3.362079620361328, Accuracy: 0.1435546875\n",
      "Batch: 24, Loss: 3.5317723751068115, Accuracy: 0.1220703125\n",
      "Batch: 25, Loss: 3.447852849960327, Accuracy: 0.1298828125\n",
      "Batch: 26, Loss: 3.444693088531494, Accuracy: 0.1240234375\n",
      "Batch: 27, Loss: 3.4117770195007324, Accuracy: 0.1318359375\n",
      "Batch: 28, Loss: 3.276503562927246, Accuracy: 0.13671875\n",
      "Batch: 29, Loss: 3.4601123332977295, Accuracy: 0.123046875\n",
      "Batch: 30, Loss: 3.753115177154541, Accuracy: 0.08203125\n",
      "Batch: 31, Loss: 3.6537885665893555, Accuracy: 0.103515625\n",
      "Batch: 32, Loss: 3.409005641937256, Accuracy: 0.1259765625\n",
      "Batch: 33, Loss: 3.448869466781616, Accuracy: 0.1533203125\n",
      "Batch: 34, Loss: 3.3879008293151855, Accuracy: 0.154296875\n",
      "Batch: 35, Loss: 3.487776756286621, Accuracy: 0.1181640625\n",
      "Batch: 36, Loss: 3.5946033000946045, Accuracy: 0.1015625\n",
      "Batch: 37, Loss: 3.45589017868042, Accuracy: 0.123046875\n",
      "Batch: 38, Loss: 3.365954637527466, Accuracy: 0.1416015625\n",
      "Batch: 39, Loss: 3.446200370788574, Accuracy: 0.1416015625\n",
      "Batch: 40, Loss: 3.560819149017334, Accuracy: 0.123046875\n",
      "Batch: 41, Loss: 3.506101369857788, Accuracy: 0.138671875\n",
      "Batch: 42, Loss: 3.342815399169922, Accuracy: 0.16796875\n",
      "Batch: 43, Loss: 3.234933376312256, Accuracy: 0.1806640625\n",
      "Batch: 44, Loss: 3.2483115196228027, Accuracy: 0.1728515625\n",
      "Batch: 45, Loss: 3.224752426147461, Accuracy: 0.1689453125\n",
      "Batch: 46, Loss: 3.5134124755859375, Accuracy: 0.1376953125\n",
      "Batch: 47, Loss: 3.5300607681274414, Accuracy: 0.125\n",
      "Batch: 48, Loss: 3.33133602142334, Accuracy: 0.1572265625\n",
      "Batch: 49, Loss: 3.3016977310180664, Accuracy: 0.1513671875\n",
      "Batch: 50, Loss: 3.2524189949035645, Accuracy: 0.15234375\n",
      "Batch: 51, Loss: 3.2531228065490723, Accuracy: 0.1572265625\n",
      "Batch: 52, Loss: 3.3209288120269775, Accuracy: 0.1435546875\n",
      "Batch: 53, Loss: 3.2768068313598633, Accuracy: 0.1396484375\n",
      "Batch: 54, Loss: 3.3043177127838135, Accuracy: 0.134765625\n",
      "Batch: 55, Loss: 3.2237062454223633, Accuracy: 0.15234375\n",
      "Batch: 56, Loss: 3.2928991317749023, Accuracy: 0.1533203125\n",
      "Batch: 57, Loss: 3.3185319900512695, Accuracy: 0.1240234375\n",
      "Batch: 58, Loss: 3.229149341583252, Accuracy: 0.15234375\n",
      "Batch: 59, Loss: 3.339958429336548, Accuracy: 0.1376953125\n",
      "Batch: 60, Loss: 3.2246947288513184, Accuracy: 0.1484375\n",
      "Batch: 61, Loss: 3.2236075401306152, Accuracy: 0.16015625\n",
      "Batch: 62, Loss: 3.302107810974121, Accuracy: 0.1494140625\n",
      "Batch: 63, Loss: 3.264033317565918, Accuracy: 0.1494140625\n",
      "Batch: 64, Loss: 3.2605714797973633, Accuracy: 0.1474609375\n",
      "Batch: 65, Loss: 3.2335314750671387, Accuracy: 0.162109375\n",
      "Batch: 66, Loss: 3.212287425994873, Accuracy: 0.162109375\n",
      "Batch: 67, Loss: 3.127004623413086, Accuracy: 0.1748046875\n",
      "Batch: 68, Loss: 3.161970615386963, Accuracy: 0.177734375\n",
      "Batch: 69, Loss: 3.2622416019439697, Accuracy: 0.1669921875\n",
      "Batch: 70, Loss: 3.2456347942352295, Accuracy: 0.171875\n",
      "Batch: 71, Loss: 3.2025156021118164, Accuracy: 0.1708984375\n",
      "Batch: 72, Loss: 3.20975399017334, Accuracy: 0.169921875\n",
      "Batch: 73, Loss: 3.3039157390594482, Accuracy: 0.150390625\n",
      "Batch: 74, Loss: 3.2366786003112793, Accuracy: 0.158203125\n",
      "Batch: 75, Loss: 3.1344473361968994, Accuracy: 0.1748046875\n",
      "Batch: 76, Loss: 3.1093955039978027, Accuracy: 0.17578125\n",
      "Batch: 77, Loss: 3.1837007999420166, Accuracy: 0.171875\n",
      "Batch: 78, Loss: 3.3263139724731445, Accuracy: 0.14453125\n",
      "Batch: 79, Loss: 3.300295829772949, Accuracy: 0.1484375\n",
      "Batch: 80, Loss: 3.076451301574707, Accuracy: 0.1767578125\n",
      "Batch: 81, Loss: 3.0319480895996094, Accuracy: 0.1884765625\n",
      "Batch: 82, Loss: 3.084167003631592, Accuracy: 0.1904296875\n",
      "Batch: 83, Loss: 3.142594814300537, Accuracy: 0.17578125\n",
      "Batch: 84, Loss: 3.190765380859375, Accuracy: 0.1689453125\n",
      "Batch: 85, Loss: 3.189760446548462, Accuracy: 0.1669921875\n",
      "Batch: 86, Loss: 3.1195552349090576, Accuracy: 0.1669921875\n",
      "Batch: 87, Loss: 3.144859552383423, Accuracy: 0.169921875\n",
      "Batch: 88, Loss: 3.170305013656616, Accuracy: 0.1630859375\n",
      "Batch: 89, Loss: 3.1442437171936035, Accuracy: 0.1708984375\n",
      "Batch: 90, Loss: 3.159524917602539, Accuracy: 0.171875\n",
      "Batch: 91, Loss: 3.0839734077453613, Accuracy: 0.1708984375\n",
      "Batch: 92, Loss: 3.114802598953247, Accuracy: 0.166015625\n",
      "Batch: 93, Loss: 3.069411277770996, Accuracy: 0.1708984375\n",
      "Batch: 94, Loss: 3.056129217147827, Accuracy: 0.1826171875\n",
      "Batch: 95, Loss: 2.989992141723633, Accuracy: 0.201171875\n",
      "Batch: 96, Loss: 3.1433777809143066, Accuracy: 0.1767578125\n",
      "Batch: 97, Loss: 3.1113736629486084, Accuracy: 0.1669921875\n",
      "Batch: 98, Loss: 3.122699022293091, Accuracy: 0.1748046875\n",
      "Batch: 99, Loss: 2.9950649738311768, Accuracy: 0.17578125\n",
      "Batch: 100, Loss: 2.954676628112793, Accuracy: 0.181640625\n",
      "Batch: 101, Loss: 2.964489459991455, Accuracy: 0.205078125\n",
      "Batch: 102, Loss: 2.9854025840759277, Accuracy: 0.1826171875\n",
      "Batch: 103, Loss: 3.113589286804199, Accuracy: 0.1865234375\n",
      "Batch: 104, Loss: 2.9945106506347656, Accuracy: 0.203125\n",
      "Batch: 105, Loss: 3.0122766494750977, Accuracy: 0.2001953125\n",
      "Batch: 106, Loss: 3.036285877227783, Accuracy: 0.193359375\n",
      "Batch: 107, Loss: 3.0980324745178223, Accuracy: 0.185546875\n",
      "Batch: 108, Loss: 3.0299806594848633, Accuracy: 0.197265625\n",
      "Batch: 109, Loss: 3.017256736755371, Accuracy: 0.2021484375\n",
      "Batch: 110, Loss: 2.895155906677246, Accuracy: 0.1923828125\n",
      "Batch: 111, Loss: 2.889400005340576, Accuracy: 0.1904296875\n",
      "Batch: 112, Loss: 3.0168840885162354, Accuracy: 0.20703125\n",
      "Batch: 113, Loss: 3.077019453048706, Accuracy: 0.1669921875\n",
      "Batch: 114, Loss: 2.9471595287323, Accuracy: 0.201171875\n",
      "Batch: 115, Loss: 2.9744341373443604, Accuracy: 0.2021484375\n",
      "Batch: 116, Loss: 2.9809112548828125, Accuracy: 0.201171875\n",
      "Batch: 117, Loss: 3.02299165725708, Accuracy: 0.1953125\n",
      "Batch: 118, Loss: 2.966899871826172, Accuracy: 0.1962890625\n",
      "Batch: 119, Loss: 3.060175895690918, Accuracy: 0.18359375\n",
      "Batch: 120, Loss: 2.950806140899658, Accuracy: 0.203125\n",
      "Batch: 121, Loss: 2.9850502014160156, Accuracy: 0.216796875\n",
      "Batch: 122, Loss: 2.9755074977874756, Accuracy: 0.2021484375\n",
      "Batch: 123, Loss: 2.9549410343170166, Accuracy: 0.19140625\n",
      "Batch: 124, Loss: 2.8916475772857666, Accuracy: 0.2138671875\n",
      "Batch: 125, Loss: 2.920266628265381, Accuracy: 0.1923828125\n",
      "Batch: 126, Loss: 2.8878231048583984, Accuracy: 0.201171875\n",
      "Batch: 127, Loss: 2.8970470428466797, Accuracy: 0.1962890625\n",
      "Batch: 128, Loss: 2.979405164718628, Accuracy: 0.181640625\n",
      "Batch: 129, Loss: 2.855685234069824, Accuracy: 0.2158203125\n",
      "Batch: 130, Loss: 2.9459497928619385, Accuracy: 0.1923828125\n",
      "Batch: 131, Loss: 2.880537986755371, Accuracy: 0.1943359375\n",
      "Batch: 132, Loss: 2.913327217102051, Accuracy: 0.208984375\n",
      "Batch: 133, Loss: 2.9315781593322754, Accuracy: 0.2060546875\n",
      "Batch: 134, Loss: 2.8703410625457764, Accuracy: 0.23046875\n",
      "Batch: 135, Loss: 2.8178651332855225, Accuracy: 0.2255859375\n",
      "Batch: 136, Loss: 2.83897066116333, Accuracy: 0.2158203125\n",
      "Batch: 137, Loss: 2.6936187744140625, Accuracy: 0.2421875\n",
      "Batch: 138, Loss: 2.7306289672851562, Accuracy: 0.255859375\n",
      "Batch: 139, Loss: 2.699861526489258, Accuracy: 0.2490234375\n",
      "Batch: 140, Loss: 2.770094871520996, Accuracy: 0.2490234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 141, Loss: 2.776789665222168, Accuracy: 0.220703125\n",
      "Batch: 142, Loss: 2.7627243995666504, Accuracy: 0.22265625\n",
      "Batch: 143, Loss: 2.787266254425049, Accuracy: 0.2255859375\n",
      "Batch: 144, Loss: 2.7433438301086426, Accuracy: 0.236328125\n",
      "Batch: 145, Loss: 2.6843678951263428, Accuracy: 0.2578125\n",
      "Batch: 146, Loss: 2.8480849266052246, Accuracy: 0.2353515625\n",
      "Batch: 147, Loss: 2.828176736831665, Accuracy: 0.24609375\n",
      "Batch: 148, Loss: 2.8613948822021484, Accuracy: 0.2509765625\n",
      "Batch: 149, Loss: 2.815991163253784, Accuracy: 0.2548828125\n",
      "Batch: 150, Loss: 2.716871976852417, Accuracy: 0.2587890625\n",
      "Batch: 151, Loss: 2.7701222896575928, Accuracy: 0.2568359375\n",
      "Epoch 2/90\n",
      "Batch: 1, Loss: 2.831461191177368, Accuracy: 0.2626953125\n",
      "Batch: 2, Loss: 2.5838873386383057, Accuracy: 0.2861328125\n",
      "Batch: 3, Loss: 2.6670429706573486, Accuracy: 0.2763671875\n",
      "Batch: 4, Loss: 2.7231669425964355, Accuracy: 0.25\n",
      "Batch: 5, Loss: 2.619192600250244, Accuracy: 0.287109375\n",
      "Batch: 6, Loss: 2.5537116527557373, Accuracy: 0.3037109375\n",
      "Batch: 7, Loss: 2.5853705406188965, Accuracy: 0.2822265625\n",
      "Batch: 8, Loss: 2.5522103309631348, Accuracy: 0.2958984375\n",
      "Batch: 9, Loss: 2.5519235134124756, Accuracy: 0.314453125\n",
      "Batch: 10, Loss: 2.5499114990234375, Accuracy: 0.2998046875\n",
      "Batch: 11, Loss: 2.5195837020874023, Accuracy: 0.3193359375\n",
      "Batch: 12, Loss: 2.549053192138672, Accuracy: 0.30859375\n",
      "Batch: 13, Loss: 2.525111198425293, Accuracy: 0.2783203125\n",
      "Batch: 14, Loss: 2.518998384475708, Accuracy: 0.3125\n",
      "Batch: 15, Loss: 2.5912296772003174, Accuracy: 0.28515625\n",
      "Batch: 16, Loss: 2.4864258766174316, Accuracy: 0.302734375\n",
      "Batch: 17, Loss: 2.4307827949523926, Accuracy: 0.328125\n",
      "Batch: 18, Loss: 2.5206775665283203, Accuracy: 0.3037109375\n",
      "Batch: 19, Loss: 2.5282814502716064, Accuracy: 0.302734375\n",
      "Batch: 20, Loss: 2.591224431991577, Accuracy: 0.2890625\n",
      "Batch: 21, Loss: 2.4306163787841797, Accuracy: 0.31640625\n",
      "Batch: 22, Loss: 2.4824228286743164, Accuracy: 0.3203125\n",
      "Batch: 23, Loss: 2.373058557510376, Accuracy: 0.33203125\n",
      "Batch: 24, Loss: 2.5165786743164062, Accuracy: 0.3046875\n",
      "Batch: 25, Loss: 2.405162811279297, Accuracy: 0.3115234375\n",
      "Batch: 26, Loss: 2.307278633117676, Accuracy: 0.345703125\n",
      "Batch: 27, Loss: 2.4698541164398193, Accuracy: 0.310546875\n",
      "Batch: 28, Loss: 2.3929877281188965, Accuracy: 0.3271484375\n",
      "Batch: 29, Loss: 2.3889851570129395, Accuracy: 0.3291015625\n",
      "Batch: 30, Loss: 2.5280373096466064, Accuracy: 0.29296875\n",
      "Batch: 31, Loss: 2.532921314239502, Accuracy: 0.30859375\n",
      "Batch: 32, Loss: 2.33573579788208, Accuracy: 0.341796875\n",
      "Batch: 33, Loss: 2.4262566566467285, Accuracy: 0.3349609375\n",
      "Batch: 34, Loss: 2.4626307487487793, Accuracy: 0.3359375\n",
      "Batch: 35, Loss: 2.417708396911621, Accuracy: 0.3251953125\n",
      "Batch: 36, Loss: 2.514376640319824, Accuracy: 0.3046875\n",
      "Batch: 37, Loss: 2.452956438064575, Accuracy: 0.3115234375\n",
      "Batch: 38, Loss: 2.3986001014709473, Accuracy: 0.328125\n",
      "Batch: 39, Loss: 2.4444613456726074, Accuracy: 0.322265625\n",
      "Batch: 40, Loss: 2.48598575592041, Accuracy: 0.3291015625\n",
      "Batch: 41, Loss: 2.501600742340088, Accuracy: 0.3349609375\n",
      "Batch: 42, Loss: 2.273956537246704, Accuracy: 0.3623046875\n",
      "Batch: 43, Loss: 2.192009925842285, Accuracy: 0.3935546875\n",
      "Batch: 44, Loss: 2.163015127182007, Accuracy: 0.3896484375\n",
      "Batch: 45, Loss: 2.147641658782959, Accuracy: 0.404296875\n",
      "Batch: 46, Loss: 2.3737435340881348, Accuracy: 0.3505859375\n",
      "Batch: 47, Loss: 2.4425220489501953, Accuracy: 0.3447265625\n",
      "Batch: 48, Loss: 2.372495651245117, Accuracy: 0.3720703125\n",
      "Batch: 49, Loss: 2.317866563796997, Accuracy: 0.341796875\n",
      "Batch: 50, Loss: 2.342097282409668, Accuracy: 0.337890625\n",
      "Batch: 51, Loss: 2.38527512550354, Accuracy: 0.322265625\n",
      "Batch: 52, Loss: 2.3190054893493652, Accuracy: 0.3583984375\n",
      "Batch: 53, Loss: 2.116485834121704, Accuracy: 0.3974609375\n",
      "Batch: 54, Loss: 2.2294490337371826, Accuracy: 0.3798828125\n",
      "Batch: 55, Loss: 2.214869976043701, Accuracy: 0.3798828125\n",
      "Batch: 56, Loss: 2.34147572517395, Accuracy: 0.359375\n",
      "Batch: 57, Loss: 2.356276035308838, Accuracy: 0.3408203125\n",
      "Batch: 58, Loss: 2.4807064533233643, Accuracy: 0.34765625\n",
      "Batch: 59, Loss: 2.415825843811035, Accuracy: 0.353515625\n",
      "Batch: 60, Loss: 2.247042179107666, Accuracy: 0.375\n",
      "Batch: 61, Loss: 2.2735681533813477, Accuracy: 0.3671875\n",
      "Batch: 62, Loss: 2.3835480213165283, Accuracy: 0.34375\n",
      "Batch: 63, Loss: 2.330617666244507, Accuracy: 0.3701171875\n",
      "Batch: 64, Loss: 2.306126356124878, Accuracy: 0.3662109375\n",
      "Batch: 65, Loss: 2.330667734146118, Accuracy: 0.3466796875\n",
      "Batch: 66, Loss: 2.238750457763672, Accuracy: 0.3623046875\n",
      "Batch: 67, Loss: 2.1600005626678467, Accuracy: 0.400390625\n",
      "Batch: 68, Loss: 2.29221510887146, Accuracy: 0.3701171875\n",
      "Batch: 69, Loss: 2.2596309185028076, Accuracy: 0.3818359375\n",
      "Batch: 70, Loss: 2.3437020778656006, Accuracy: 0.3759765625\n",
      "Batch: 71, Loss: 2.175462245941162, Accuracy: 0.380859375\n",
      "Batch: 72, Loss: 2.1969552040100098, Accuracy: 0.3876953125\n",
      "Batch: 73, Loss: 2.3388469219207764, Accuracy: 0.373046875\n",
      "Batch: 74, Loss: 2.2427258491516113, Accuracy: 0.380859375\n",
      "Batch: 75, Loss: 2.101679563522339, Accuracy: 0.4189453125\n",
      "Batch: 76, Loss: 2.1538643836975098, Accuracy: 0.376953125\n",
      "Batch: 77, Loss: 2.206493377685547, Accuracy: 0.376953125\n",
      "Batch: 78, Loss: 2.2838754653930664, Accuracy: 0.3681640625\n",
      "Batch: 79, Loss: 2.159623384475708, Accuracy: 0.412109375\n",
      "Batch: 80, Loss: 1.9988186359405518, Accuracy: 0.4443359375\n",
      "Batch: 81, Loss: 2.030874013900757, Accuracy: 0.40625\n",
      "Batch: 82, Loss: 2.0605480670928955, Accuracy: 0.4072265625\n",
      "Batch: 83, Loss: 2.0179214477539062, Accuracy: 0.4306640625\n",
      "Batch: 84, Loss: 2.1158761978149414, Accuracy: 0.4228515625\n",
      "Batch: 85, Loss: 2.0826447010040283, Accuracy: 0.42578125\n",
      "Batch: 86, Loss: 2.14628267288208, Accuracy: 0.4208984375\n",
      "Batch: 87, Loss: 2.1152005195617676, Accuracy: 0.4365234375\n",
      "Batch: 88, Loss: 2.169788122177124, Accuracy: 0.40234375\n",
      "Batch: 89, Loss: 2.1985926628112793, Accuracy: 0.404296875\n",
      "Batch: 90, Loss: 2.1202003955841064, Accuracy: 0.396484375\n",
      "Batch: 91, Loss: 2.1210854053497314, Accuracy: 0.4033203125\n",
      "Batch: 92, Loss: 2.144528388977051, Accuracy: 0.4072265625\n",
      "Batch: 93, Loss: 2.0715246200561523, Accuracy: 0.4169921875\n",
      "Batch: 94, Loss: 2.044862747192383, Accuracy: 0.41796875\n",
      "Batch: 95, Loss: 1.9925270080566406, Accuracy: 0.4384765625\n",
      "Batch: 96, Loss: 2.1353204250335693, Accuracy: 0.4150390625\n",
      "Batch: 97, Loss: 2.053976535797119, Accuracy: 0.431640625\n",
      "Batch: 98, Loss: 2.036217212677002, Accuracy: 0.4423828125\n",
      "Batch: 99, Loss: 2.002901077270508, Accuracy: 0.4248046875\n",
      "Batch: 100, Loss: 1.9658796787261963, Accuracy: 0.4482421875\n",
      "Batch: 101, Loss: 1.9725189208984375, Accuracy: 0.443359375\n",
      "Batch: 102, Loss: 1.963789463043213, Accuracy: 0.4375\n",
      "Batch: 103, Loss: 2.19342041015625, Accuracy: 0.38671875\n",
      "Batch: 104, Loss: 1.9464654922485352, Accuracy: 0.4453125\n",
      "Batch: 105, Loss: 2.0322353839874268, Accuracy: 0.4375\n",
      "Batch: 106, Loss: 2.096987724304199, Accuracy: 0.4033203125\n",
      "Batch: 107, Loss: 2.1996185779571533, Accuracy: 0.392578125\n",
      "Batch: 108, Loss: 2.1748743057250977, Accuracy: 0.40234375\n",
      "Batch: 109, Loss: 2.1406302452087402, Accuracy: 0.4140625\n",
      "Batch: 110, Loss: 1.9032231569290161, Accuracy: 0.4267578125\n",
      "Batch: 111, Loss: 1.959323525428772, Accuracy: 0.4443359375\n",
      "Batch: 112, Loss: 2.064927577972412, Accuracy: 0.435546875\n",
      "Batch: 113, Loss: 2.155819892883301, Accuracy: 0.4306640625\n",
      "Batch: 114, Loss: 2.0895495414733887, Accuracy: 0.4189453125\n",
      "Batch: 115, Loss: 2.1748485565185547, Accuracy: 0.4189453125\n",
      "Batch: 116, Loss: 2.1581954956054688, Accuracy: 0.400390625\n",
      "Batch: 117, Loss: 2.121133804321289, Accuracy: 0.4208984375\n",
      "Batch: 118, Loss: 2.007868766784668, Accuracy: 0.431640625\n",
      "Batch: 119, Loss: 2.106607437133789, Accuracy: 0.439453125\n",
      "Batch: 120, Loss: 2.0673608779907227, Accuracy: 0.4306640625\n",
      "Batch: 121, Loss: 2.1376161575317383, Accuracy: 0.416015625\n",
      "Batch: 122, Loss: 2.075519561767578, Accuracy: 0.4228515625\n",
      "Batch: 123, Loss: 2.08077335357666, Accuracy: 0.4345703125\n",
      "Batch: 124, Loss: 2.058614730834961, Accuracy: 0.4404296875\n",
      "Batch: 125, Loss: 2.0396206378936768, Accuracy: 0.4287109375\n",
      "Batch: 126, Loss: 2.043640375137329, Accuracy: 0.412109375\n",
      "Batch: 127, Loss: 2.0021653175354004, Accuracy: 0.451171875\n",
      "Batch: 128, Loss: 2.204960346221924, Accuracy: 0.3916015625\n",
      "Batch: 129, Loss: 2.0691676139831543, Accuracy: 0.427734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 130, Loss: 2.2083725929260254, Accuracy: 0.3955078125\n",
      "Batch: 131, Loss: 2.036464214324951, Accuracy: 0.4228515625\n",
      "Batch: 132, Loss: 2.1366958618164062, Accuracy: 0.4248046875\n",
      "Batch: 133, Loss: 2.043440818786621, Accuracy: 0.453125\n",
      "Batch: 134, Loss: 2.076584577560425, Accuracy: 0.3955078125\n",
      "Batch: 135, Loss: 1.9865593910217285, Accuracy: 0.443359375\n",
      "Batch: 136, Loss: 1.9978508949279785, Accuracy: 0.435546875\n",
      "Batch: 137, Loss: 1.7999932765960693, Accuracy: 0.4677734375\n",
      "Batch: 138, Loss: 1.7629802227020264, Accuracy: 0.4775390625\n",
      "Batch: 139, Loss: 1.8277746438980103, Accuracy: 0.4482421875\n",
      "Batch: 140, Loss: 1.9657220840454102, Accuracy: 0.4443359375\n",
      "Batch: 141, Loss: 1.9660707712173462, Accuracy: 0.462890625\n",
      "Batch: 142, Loss: 1.9919073581695557, Accuracy: 0.4365234375\n",
      "Batch: 143, Loss: 2.0715885162353516, Accuracy: 0.421875\n",
      "Batch: 144, Loss: 1.9853849411010742, Accuracy: 0.439453125\n",
      "Batch: 145, Loss: 1.9076793193817139, Accuracy: 0.4658203125\n",
      "Batch: 146, Loss: 2.131218433380127, Accuracy: 0.40234375\n",
      "Batch: 147, Loss: 2.0124094486236572, Accuracy: 0.419921875\n",
      "Batch: 148, Loss: 2.08376407623291, Accuracy: 0.3935546875\n",
      "Batch: 149, Loss: 2.0684616565704346, Accuracy: 0.4130859375\n",
      "Batch: 150, Loss: 1.9535595178604126, Accuracy: 0.44140625\n",
      "Batch: 151, Loss: 1.9793071746826172, Accuracy: 0.4453125\n",
      "Epoch 3/90\n",
      "Batch: 1, Loss: 2.1525790691375732, Accuracy: 0.3876953125\n",
      "Batch: 2, Loss: 1.8514692783355713, Accuracy: 0.4482421875\n",
      "Batch: 3, Loss: 1.929675817489624, Accuracy: 0.44921875\n",
      "Batch: 4, Loss: 1.9212573766708374, Accuracy: 0.4921875\n",
      "Batch: 5, Loss: 1.8621439933776855, Accuracy: 0.47265625\n",
      "Batch: 6, Loss: 1.8489859104156494, Accuracy: 0.4697265625\n",
      "Batch: 7, Loss: 1.854251742362976, Accuracy: 0.4638671875\n",
      "Batch: 8, Loss: 1.8190795183181763, Accuracy: 0.4697265625\n",
      "Batch: 9, Loss: 1.7815979719161987, Accuracy: 0.4853515625\n",
      "Batch: 10, Loss: 1.853048324584961, Accuracy: 0.466796875\n",
      "Batch: 11, Loss: 1.8517159223556519, Accuracy: 0.4501953125\n",
      "Batch: 12, Loss: 1.9880425930023193, Accuracy: 0.4345703125\n",
      "Batch: 13, Loss: 1.7802069187164307, Accuracy: 0.5048828125\n",
      "Batch: 14, Loss: 1.902909755706787, Accuracy: 0.4619140625\n",
      "Batch: 15, Loss: 1.9045542478561401, Accuracy: 0.4716796875\n",
      "Batch: 16, Loss: 1.8336069583892822, Accuracy: 0.45703125\n",
      "Batch: 17, Loss: 1.8737211227416992, Accuracy: 0.4521484375\n",
      "Batch: 18, Loss: 1.914440393447876, Accuracy: 0.44140625\n",
      "Batch: 19, Loss: 1.940863847732544, Accuracy: 0.44140625\n",
      "Batch: 20, Loss: 1.9701484441757202, Accuracy: 0.4404296875\n",
      "Batch: 21, Loss: 1.7848609685897827, Accuracy: 0.49609375\n",
      "Batch: 22, Loss: 1.9288463592529297, Accuracy: 0.453125\n",
      "Batch: 23, Loss: 1.8118014335632324, Accuracy: 0.466796875\n",
      "Batch: 24, Loss: 1.9017317295074463, Accuracy: 0.4560546875\n",
      "Batch: 25, Loss: 1.8137986660003662, Accuracy: 0.4736328125\n",
      "Batch: 26, Loss: 1.7375667095184326, Accuracy: 0.498046875\n",
      "Batch: 27, Loss: 1.889289140701294, Accuracy: 0.431640625\n",
      "Batch: 28, Loss: 1.8382099866867065, Accuracy: 0.4619140625\n",
      "Batch: 29, Loss: 1.8937379121780396, Accuracy: 0.44921875\n",
      "Batch: 30, Loss: 1.9363174438476562, Accuracy: 0.4677734375\n",
      "Batch: 31, Loss: 1.9341049194335938, Accuracy: 0.4736328125\n",
      "Batch: 32, Loss: 1.7677841186523438, Accuracy: 0.4931640625\n",
      "Batch: 33, Loss: 1.9286978244781494, Accuracy: 0.4521484375\n",
      "Batch: 34, Loss: 2.022876262664795, Accuracy: 0.42578125\n",
      "Batch: 35, Loss: 1.9343938827514648, Accuracy: 0.4541015625\n",
      "Batch: 36, Loss: 1.943732738494873, Accuracy: 0.470703125\n",
      "Batch: 37, Loss: 1.9849066734313965, Accuracy: 0.4384765625\n",
      "Batch: 38, Loss: 1.8672953844070435, Accuracy: 0.4658203125\n",
      "Batch: 39, Loss: 1.911928653717041, Accuracy: 0.455078125\n",
      "Batch: 40, Loss: 2.0003652572631836, Accuracy: 0.458984375\n",
      "Batch: 41, Loss: 2.0329296588897705, Accuracy: 0.4716796875\n",
      "Batch: 42, Loss: 1.7284427881240845, Accuracy: 0.5146484375\n",
      "Batch: 43, Loss: 1.8079283237457275, Accuracy: 0.470703125\n",
      "Batch: 44, Loss: 1.7967129945755005, Accuracy: 0.4677734375\n",
      "Batch: 45, Loss: 1.6923631429672241, Accuracy: 0.5068359375\n",
      "Batch: 46, Loss: 1.9172316789627075, Accuracy: 0.490234375\n",
      "Batch: 47, Loss: 1.9683218002319336, Accuracy: 0.4501953125\n",
      "Batch: 48, Loss: 1.8892065286636353, Accuracy: 0.4677734375\n",
      "Batch: 49, Loss: 1.9062681198120117, Accuracy: 0.451171875\n",
      "Batch: 50, Loss: 1.90964674949646, Accuracy: 0.4453125\n",
      "Batch: 51, Loss: 2.022575855255127, Accuracy: 0.416015625\n",
      "Batch: 52, Loss: 1.9405267238616943, Accuracy: 0.4521484375\n",
      "Batch: 53, Loss: 1.7053279876708984, Accuracy: 0.484375\n",
      "Batch: 54, Loss: 1.8711862564086914, Accuracy: 0.484375\n",
      "Batch: 55, Loss: 1.8118845224380493, Accuracy: 0.4765625\n",
      "Batch: 56, Loss: 1.9491515159606934, Accuracy: 0.4541015625\n",
      "Batch: 57, Loss: 1.8864352703094482, Accuracy: 0.48046875\n",
      "Batch: 58, Loss: 1.9218727350234985, Accuracy: 0.4482421875\n",
      "Batch: 59, Loss: 1.7923400402069092, Accuracy: 0.490234375\n",
      "Batch: 60, Loss: 1.7555947303771973, Accuracy: 0.4921875\n",
      "Batch: 61, Loss: 1.8611646890640259, Accuracy: 0.4599609375\n",
      "Batch: 62, Loss: 1.9362435340881348, Accuracy: 0.458984375\n",
      "Batch: 63, Loss: 1.8554530143737793, Accuracy: 0.474609375\n",
      "Batch: 64, Loss: 1.816490650177002, Accuracy: 0.50390625\n",
      "Batch: 65, Loss: 1.9002898931503296, Accuracy: 0.455078125\n",
      "Batch: 66, Loss: 1.7816144227981567, Accuracy: 0.490234375\n",
      "Batch: 67, Loss: 1.8119533061981201, Accuracy: 0.4912109375\n",
      "Batch: 68, Loss: 1.9519140720367432, Accuracy: 0.4619140625\n",
      "Batch: 69, Loss: 1.892764687538147, Accuracy: 0.4658203125\n",
      "Batch: 70, Loss: 1.933595895767212, Accuracy: 0.482421875\n",
      "Batch: 71, Loss: 1.8164688348770142, Accuracy: 0.46875\n",
      "Batch: 72, Loss: 1.773823857307434, Accuracy: 0.486328125\n",
      "Batch: 73, Loss: 1.8757083415985107, Accuracy: 0.482421875\n",
      "Batch: 74, Loss: 1.7922940254211426, Accuracy: 0.482421875\n",
      "Batch: 75, Loss: 1.7182737588882446, Accuracy: 0.5048828125\n",
      "Batch: 76, Loss: 1.8284294605255127, Accuracy: 0.4541015625\n",
      "Batch: 77, Loss: 1.843950867652893, Accuracy: 0.48046875\n",
      "Batch: 78, Loss: 1.8605495691299438, Accuracy: 0.5\n",
      "Batch: 79, Loss: 1.6984134912490845, Accuracy: 0.5400390625\n",
      "Batch: 80, Loss: 1.6469855308532715, Accuracy: 0.513671875\n",
      "Batch: 81, Loss: 1.777477502822876, Accuracy: 0.470703125\n",
      "Batch: 82, Loss: 1.7956972122192383, Accuracy: 0.4736328125\n",
      "Batch: 83, Loss: 1.6936105489730835, Accuracy: 0.537109375\n",
      "Batch: 84, Loss: 1.7633150815963745, Accuracy: 0.5263671875\n",
      "Batch: 85, Loss: 1.6390576362609863, Accuracy: 0.5400390625\n",
      "Batch: 86, Loss: 1.933834433555603, Accuracy: 0.453125\n",
      "Batch: 87, Loss: 1.7640190124511719, Accuracy: 0.5107421875\n",
      "Batch: 88, Loss: 1.9170902967453003, Accuracy: 0.4736328125\n",
      "Batch: 89, Loss: 1.9107121229171753, Accuracy: 0.4658203125\n",
      "Batch: 90, Loss: 1.7813198566436768, Accuracy: 0.4921875\n",
      "Batch: 91, Loss: 1.765694499015808, Accuracy: 0.490234375\n",
      "Batch: 92, Loss: 1.8598072528839111, Accuracy: 0.4755859375\n",
      "Batch: 93, Loss: 1.7564817667007446, Accuracy: 0.509765625\n",
      "Batch: 94, Loss: 1.7707711458206177, Accuracy: 0.49609375\n",
      "Batch: 95, Loss: 1.790451169013977, Accuracy: 0.4794921875\n",
      "Batch: 96, Loss: 1.8071188926696777, Accuracy: 0.4892578125\n",
      "Batch: 97, Loss: 1.7452638149261475, Accuracy: 0.51171875\n",
      "Batch: 98, Loss: 1.6753387451171875, Accuracy: 0.548828125\n",
      "Batch: 99, Loss: 1.6450449228286743, Accuracy: 0.517578125\n",
      "Batch: 100, Loss: 1.7024970054626465, Accuracy: 0.5009765625\n",
      "Batch: 101, Loss: 1.7440335750579834, Accuracy: 0.50390625\n",
      "Batch: 102, Loss: 1.6733293533325195, Accuracy: 0.4951171875\n",
      "Batch: 103, Loss: 1.8302764892578125, Accuracy: 0.4931640625\n",
      "Batch: 104, Loss: 1.6391315460205078, Accuracy: 0.52734375\n",
      "Batch: 105, Loss: 1.759496808052063, Accuracy: 0.4912109375\n",
      "Batch: 106, Loss: 1.8346891403198242, Accuracy: 0.4794921875\n",
      "Batch: 107, Loss: 1.944835901260376, Accuracy: 0.451171875\n",
      "Batch: 108, Loss: 1.8971304893493652, Accuracy: 0.466796875\n",
      "Batch: 109, Loss: 1.9195945262908936, Accuracy: 0.458984375\n",
      "Batch: 110, Loss: 1.596163034439087, Accuracy: 0.515625\n",
      "Batch: 111, Loss: 1.731919765472412, Accuracy: 0.4970703125\n",
      "Batch: 112, Loss: 1.7607321739196777, Accuracy: 0.5078125\n",
      "Batch: 113, Loss: 1.7964580059051514, Accuracy: 0.4970703125\n",
      "Batch: 114, Loss: 1.8565170764923096, Accuracy: 0.4736328125\n",
      "Batch: 115, Loss: 1.9697856903076172, Accuracy: 0.46484375\n",
      "Batch: 116, Loss: 1.9050886631011963, Accuracy: 0.4599609375\n",
      "Batch: 117, Loss: 1.8390802145004272, Accuracy: 0.50390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 118, Loss: 1.6733596324920654, Accuracy: 0.5380859375\n",
      "Batch: 119, Loss: 1.7210345268249512, Accuracy: 0.5283203125\n",
      "Batch: 120, Loss: 1.827167272567749, Accuracy: 0.4697265625\n",
      "Batch: 121, Loss: 1.9021729230880737, Accuracy: 0.470703125\n",
      "Batch: 122, Loss: 1.7523095607757568, Accuracy: 0.5185546875\n",
      "Batch: 123, Loss: 1.7651264667510986, Accuracy: 0.5068359375\n",
      "Batch: 124, Loss: 1.8163700103759766, Accuracy: 0.4931640625\n",
      "Batch: 125, Loss: 1.8005554676055908, Accuracy: 0.498046875\n",
      "Batch: 126, Loss: 1.7846416234970093, Accuracy: 0.474609375\n",
      "Batch: 127, Loss: 1.681760549545288, Accuracy: 0.5283203125\n",
      "Batch: 128, Loss: 1.902876377105713, Accuracy: 0.4560546875\n",
      "Batch: 129, Loss: 1.7709143161773682, Accuracy: 0.4892578125\n",
      "Batch: 130, Loss: 1.989154577255249, Accuracy: 0.4375\n",
      "Batch: 131, Loss: 1.793806791305542, Accuracy: 0.4814453125\n",
      "Batch: 132, Loss: 1.8686842918395996, Accuracy: 0.490234375\n",
      "Batch: 133, Loss: 1.7615689039230347, Accuracy: 0.498046875\n",
      "Batch: 134, Loss: 1.83571195602417, Accuracy: 0.4599609375\n",
      "Batch: 135, Loss: 1.7171258926391602, Accuracy: 0.513671875\n",
      "Batch: 136, Loss: 1.7185735702514648, Accuracy: 0.4921875\n",
      "Batch: 137, Loss: 1.6158530712127686, Accuracy: 0.50390625\n",
      "Batch: 138, Loss: 1.5385206937789917, Accuracy: 0.52734375\n",
      "Batch: 139, Loss: 1.614497184753418, Accuracy: 0.513671875\n",
      "Batch: 140, Loss: 1.7268294095993042, Accuracy: 0.498046875\n",
      "Batch: 141, Loss: 1.726723313331604, Accuracy: 0.4990234375\n",
      "Batch: 142, Loss: 1.7617859840393066, Accuracy: 0.474609375\n",
      "Batch: 143, Loss: 1.8197901248931885, Accuracy: 0.4765625\n",
      "Batch: 144, Loss: 1.747673511505127, Accuracy: 0.4892578125\n",
      "Batch: 145, Loss: 1.6513866186141968, Accuracy: 0.50390625\n",
      "Batch: 146, Loss: 1.8464069366455078, Accuracy: 0.455078125\n",
      "Batch: 147, Loss: 1.7450505495071411, Accuracy: 0.4873046875\n",
      "Batch: 148, Loss: 1.845927119255066, Accuracy: 0.443359375\n",
      "Batch: 149, Loss: 1.8125414848327637, Accuracy: 0.4638671875\n",
      "Batch: 150, Loss: 1.6981755495071411, Accuracy: 0.48828125\n",
      "Batch: 151, Loss: 1.710917592048645, Accuracy: 0.52734375\n",
      "Epoch 4/90\n",
      "Batch: 1, Loss: 1.9671030044555664, Accuracy: 0.4423828125\n",
      "Batch: 2, Loss: 1.649819016456604, Accuracy: 0.5\n",
      "Batch: 3, Loss: 1.6702470779418945, Accuracy: 0.5048828125\n",
      "Batch: 4, Loss: 1.5968730449676514, Accuracy: 0.5556640625\n",
      "Batch: 5, Loss: 1.5838345289230347, Accuracy: 0.5361328125\n",
      "Batch: 6, Loss: 1.686490535736084, Accuracy: 0.490234375\n",
      "Batch: 7, Loss: 1.6771743297576904, Accuracy: 0.490234375\n",
      "Batch: 8, Loss: 1.6400041580200195, Accuracy: 0.5\n",
      "Batch: 9, Loss: 1.5384896993637085, Accuracy: 0.5322265625\n",
      "Batch: 10, Loss: 1.6075160503387451, Accuracy: 0.5166015625\n",
      "Batch: 11, Loss: 1.6924859285354614, Accuracy: 0.4765625\n",
      "Batch: 12, Loss: 1.7996764183044434, Accuracy: 0.4501953125\n",
      "Batch: 13, Loss: 1.6461551189422607, Accuracy: 0.5087890625\n",
      "Batch: 14, Loss: 1.7054738998413086, Accuracy: 0.494140625\n",
      "Batch: 15, Loss: 1.640763282775879, Accuracy: 0.521484375\n",
      "Batch: 16, Loss: 1.6035652160644531, Accuracy: 0.509765625\n",
      "Batch: 17, Loss: 1.7096033096313477, Accuracy: 0.4619140625\n",
      "Batch: 18, Loss: 1.732787847518921, Accuracy: 0.4658203125\n",
      "Batch: 19, Loss: 1.787848711013794, Accuracy: 0.455078125\n",
      "Batch: 20, Loss: 1.6758776903152466, Accuracy: 0.5\n",
      "Batch: 21, Loss: 1.5797656774520874, Accuracy: 0.5419921875\n",
      "Batch: 22, Loss: 1.7862275838851929, Accuracy: 0.4677734375\n",
      "Batch: 23, Loss: 1.6985794305801392, Accuracy: 0.484375\n",
      "Batch: 24, Loss: 1.7449440956115723, Accuracy: 0.4619140625\n",
      "Batch: 25, Loss: 1.6038305759429932, Accuracy: 0.5009765625\n",
      "Batch: 26, Loss: 1.5471949577331543, Accuracy: 0.5322265625\n",
      "Batch: 27, Loss: 1.6686211824417114, Accuracy: 0.50390625\n",
      "Batch: 28, Loss: 1.654300570487976, Accuracy: 0.490234375\n",
      "Batch: 29, Loss: 1.7417309284210205, Accuracy: 0.4521484375\n",
      "Batch: 30, Loss: 1.6983678340911865, Accuracy: 0.498046875\n",
      "Batch: 31, Loss: 1.6632928848266602, Accuracy: 0.53515625\n",
      "Batch: 32, Loss: 1.5557780265808105, Accuracy: 0.5439453125\n",
      "Batch: 33, Loss: 1.7593566179275513, Accuracy: 0.48046875\n",
      "Batch: 34, Loss: 1.8354321718215942, Accuracy: 0.462890625\n",
      "Batch: 35, Loss: 1.7367851734161377, Accuracy: 0.478515625\n",
      "Batch: 36, Loss: 1.7208503484725952, Accuracy: 0.50390625\n",
      "Batch: 37, Loss: 1.7457001209259033, Accuracy: 0.4755859375\n",
      "Batch: 38, Loss: 1.6868977546691895, Accuracy: 0.48046875\n",
      "Batch: 39, Loss: 1.7099761962890625, Accuracy: 0.5048828125\n",
      "Batch: 40, Loss: 1.7478947639465332, Accuracy: 0.5263671875\n",
      "Batch: 41, Loss: 1.7785084247589111, Accuracy: 0.5146484375\n",
      "Batch: 42, Loss: 1.4925086498260498, Accuracy: 0.5537109375\n",
      "Batch: 43, Loss: 1.580353856086731, Accuracy: 0.5078125\n",
      "Batch: 44, Loss: 1.56723952293396, Accuracy: 0.5205078125\n",
      "Batch: 45, Loss: 1.4509437084197998, Accuracy: 0.5517578125\n",
      "Batch: 46, Loss: 1.691626787185669, Accuracy: 0.53125\n",
      "Batch: 47, Loss: 1.698561191558838, Accuracy: 0.5234375\n",
      "Batch: 48, Loss: 1.644994854927063, Accuracy: 0.5283203125\n",
      "Batch: 49, Loss: 1.7460933923721313, Accuracy: 0.4853515625\n",
      "Batch: 50, Loss: 1.694911241531372, Accuracy: 0.4970703125\n",
      "Batch: 51, Loss: 1.7826240062713623, Accuracy: 0.4697265625\n",
      "Batch: 52, Loss: 1.7440481185913086, Accuracy: 0.494140625\n",
      "Batch: 53, Loss: 1.4875447750091553, Accuracy: 0.541015625\n",
      "Batch: 54, Loss: 1.634569764137268, Accuracy: 0.5361328125\n",
      "Batch: 55, Loss: 1.6067225933074951, Accuracy: 0.51171875\n",
      "Batch: 56, Loss: 1.7249202728271484, Accuracy: 0.498046875\n",
      "Batch: 57, Loss: 1.6272225379943848, Accuracy: 0.5185546875\n",
      "Batch: 58, Loss: 1.7039144039154053, Accuracy: 0.501953125\n",
      "Batch: 59, Loss: 1.5145095586776733, Accuracy: 0.572265625\n",
      "Batch: 60, Loss: 1.5604526996612549, Accuracy: 0.5478515625\n",
      "Batch: 61, Loss: 1.6298391819000244, Accuracy: 0.5078125\n",
      "Batch: 62, Loss: 1.6800010204315186, Accuracy: 0.501953125\n",
      "Batch: 63, Loss: 1.6364531517028809, Accuracy: 0.5078125\n",
      "Batch: 64, Loss: 1.610499382019043, Accuracy: 0.5322265625\n",
      "Batch: 65, Loss: 1.6448593139648438, Accuracy: 0.498046875\n",
      "Batch: 66, Loss: 1.5151859521865845, Accuracy: 0.5419921875\n",
      "Batch: 67, Loss: 1.629501461982727, Accuracy: 0.515625\n",
      "Batch: 68, Loss: 1.7175681591033936, Accuracy: 0.5302734375\n",
      "Batch: 69, Loss: 1.652984619140625, Accuracy: 0.5244140625\n",
      "Batch: 70, Loss: 1.6820504665374756, Accuracy: 0.5361328125\n",
      "Batch: 71, Loss: 1.6452620029449463, Accuracy: 0.5068359375\n",
      "Batch: 72, Loss: 1.541811227798462, Accuracy: 0.5439453125\n",
      "Batch: 73, Loss: 1.6456079483032227, Accuracy: 0.5166015625\n",
      "Batch: 74, Loss: 1.5559011697769165, Accuracy: 0.533203125\n",
      "Batch: 75, Loss: 1.4982651472091675, Accuracy: 0.5546875\n",
      "Batch: 76, Loss: 1.6306406259536743, Accuracy: 0.4912109375\n",
      "Batch: 77, Loss: 1.6204298734664917, Accuracy: 0.494140625\n",
      "Batch: 78, Loss: 1.6164848804473877, Accuracy: 0.537109375\n",
      "Batch: 79, Loss: 1.451366662979126, Accuracy: 0.58984375\n",
      "Batch: 80, Loss: 1.4634954929351807, Accuracy: 0.5517578125\n",
      "Batch: 81, Loss: 1.6089057922363281, Accuracy: 0.490234375\n",
      "Batch: 82, Loss: 1.6193318367004395, Accuracy: 0.4892578125\n",
      "Batch: 83, Loss: 1.4518043994903564, Accuracy: 0.568359375\n",
      "Batch: 84, Loss: 1.5570878982543945, Accuracy: 0.560546875\n",
      "Batch: 85, Loss: 1.4497640132904053, Accuracy: 0.572265625\n",
      "Batch: 86, Loss: 1.7239654064178467, Accuracy: 0.494140625\n",
      "Batch: 87, Loss: 1.5442302227020264, Accuracy: 0.5478515625\n",
      "Batch: 88, Loss: 1.657450556755066, Accuracy: 0.517578125\n",
      "Batch: 89, Loss: 1.6759687662124634, Accuracy: 0.5068359375\n",
      "Batch: 90, Loss: 1.5267337560653687, Accuracy: 0.5322265625\n",
      "Batch: 91, Loss: 1.5258831977844238, Accuracy: 0.537109375\n",
      "Batch: 92, Loss: 1.6198328733444214, Accuracy: 0.5166015625\n",
      "Batch: 93, Loss: 1.5109379291534424, Accuracy: 0.537109375\n",
      "Batch: 94, Loss: 1.529618263244629, Accuracy: 0.529296875\n",
      "Batch: 95, Loss: 1.5548244714736938, Accuracy: 0.5166015625\n",
      "Batch: 96, Loss: 1.5637398958206177, Accuracy: 0.546875\n",
      "Batch: 97, Loss: 1.5028232336044312, Accuracy: 0.5595703125\n",
      "Batch: 98, Loss: 1.4427562952041626, Accuracy: 0.5908203125\n",
      "Batch: 99, Loss: 1.4362890720367432, Accuracy: 0.54296875\n",
      "Batch: 100, Loss: 1.5397287607192993, Accuracy: 0.529296875\n",
      "Batch: 101, Loss: 1.5629584789276123, Accuracy: 0.5224609375\n",
      "Batch: 102, Loss: 1.4479167461395264, Accuracy: 0.5556640625\n",
      "Batch: 103, Loss: 1.6100261211395264, Accuracy: 0.5546875\n",
      "Batch: 104, Loss: 1.4222769737243652, Accuracy: 0.5615234375\n",
      "Batch: 105, Loss: 1.5526971817016602, Accuracy: 0.537109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 106, Loss: 1.5794389247894287, Accuracy: 0.5166015625\n",
      "Batch: 107, Loss: 1.7551794052124023, Accuracy: 0.4951171875\n",
      "Batch: 108, Loss: 1.6872655153274536, Accuracy: 0.5107421875\n",
      "Batch: 109, Loss: 1.725913643836975, Accuracy: 0.4833984375\n",
      "Batch: 110, Loss: 1.3756574392318726, Accuracy: 0.5703125\n",
      "Batch: 111, Loss: 1.556215763092041, Accuracy: 0.521484375\n",
      "Batch: 112, Loss: 1.5305955410003662, Accuracy: 0.5498046875\n",
      "Batch: 113, Loss: 1.5571155548095703, Accuracy: 0.5419921875\n",
      "Batch: 114, Loss: 1.6451669931411743, Accuracy: 0.509765625\n",
      "Batch: 115, Loss: 1.7089881896972656, Accuracy: 0.5146484375\n",
      "Batch: 116, Loss: 1.6708184480667114, Accuracy: 0.505859375\n",
      "Batch: 117, Loss: 1.6535375118255615, Accuracy: 0.5390625\n",
      "Batch: 118, Loss: 1.4509191513061523, Accuracy: 0.58203125\n",
      "Batch: 119, Loss: 1.4608179330825806, Accuracy: 0.58203125\n",
      "Batch: 120, Loss: 1.6084058284759521, Accuracy: 0.5009765625\n",
      "Batch: 121, Loss: 1.6899523735046387, Accuracy: 0.498046875\n",
      "Batch: 122, Loss: 1.5031843185424805, Accuracy: 0.5634765625\n",
      "Batch: 123, Loss: 1.5213983058929443, Accuracy: 0.5712890625\n",
      "Batch: 124, Loss: 1.5522716045379639, Accuracy: 0.552734375\n",
      "Batch: 125, Loss: 1.596399188041687, Accuracy: 0.5146484375\n",
      "Batch: 126, Loss: 1.5909091234207153, Accuracy: 0.5068359375\n",
      "Batch: 127, Loss: 1.444291114807129, Accuracy: 0.5947265625\n",
      "Batch: 128, Loss: 1.700944185256958, Accuracy: 0.5146484375\n",
      "Batch: 129, Loss: 1.5463697910308838, Accuracy: 0.5322265625\n",
      "Batch: 130, Loss: 1.7570829391479492, Accuracy: 0.486328125\n",
      "Batch: 131, Loss: 1.583240270614624, Accuracy: 0.5244140625\n",
      "Batch: 132, Loss: 1.6601576805114746, Accuracy: 0.5224609375\n",
      "Batch: 133, Loss: 1.5561511516571045, Accuracy: 0.5322265625\n",
      "Batch: 134, Loss: 1.6023942232131958, Accuracy: 0.5224609375\n",
      "Batch: 135, Loss: 1.494428277015686, Accuracy: 0.546875\n",
      "Batch: 136, Loss: 1.5360703468322754, Accuracy: 0.5234375\n",
      "Batch: 137, Loss: 1.4330984354019165, Accuracy: 0.5341796875\n",
      "Batch: 138, Loss: 1.3254942893981934, Accuracy: 0.5810546875\n",
      "Batch: 139, Loss: 1.3900766372680664, Accuracy: 0.5517578125\n",
      "Batch: 140, Loss: 1.5312100648880005, Accuracy: 0.5234375\n",
      "Batch: 141, Loss: 1.518496036529541, Accuracy: 0.541015625\n",
      "Batch: 142, Loss: 1.574434757232666, Accuracy: 0.5185546875\n",
      "Batch: 143, Loss: 1.579886794090271, Accuracy: 0.5263671875\n",
      "Batch: 144, Loss: 1.5475823879241943, Accuracy: 0.5458984375\n",
      "Batch: 145, Loss: 1.4455149173736572, Accuracy: 0.5517578125\n",
      "Batch: 146, Loss: 1.643134593963623, Accuracy: 0.5009765625\n",
      "Batch: 147, Loss: 1.5245752334594727, Accuracy: 0.5361328125\n",
      "Batch: 148, Loss: 1.6912338733673096, Accuracy: 0.47265625\n",
      "Batch: 149, Loss: 1.6005033254623413, Accuracy: 0.4970703125\n",
      "Batch: 150, Loss: 1.4975477457046509, Accuracy: 0.533203125\n",
      "Batch: 151, Loss: 1.4665074348449707, Accuracy: 0.5634765625\n",
      "Epoch 5/90\n",
      "Batch: 1, Loss: 1.7969732284545898, Accuracy: 0.451171875\n",
      "Batch: 2, Loss: 1.490889549255371, Accuracy: 0.5263671875\n",
      "Batch: 3, Loss: 1.4756600856781006, Accuracy: 0.552734375\n",
      "Batch: 4, Loss: 1.3881418704986572, Accuracy: 0.5986328125\n",
      "Batch: 5, Loss: 1.4082577228546143, Accuracy: 0.580078125\n",
      "Batch: 6, Loss: 1.5238877534866333, Accuracy: 0.5126953125\n",
      "Batch: 7, Loss: 1.4480688571929932, Accuracy: 0.537109375\n",
      "Batch: 8, Loss: 1.4318430423736572, Accuracy: 0.5498046875\n",
      "Batch: 9, Loss: 1.4066952466964722, Accuracy: 0.5703125\n",
      "Batch: 10, Loss: 1.5048311948776245, Accuracy: 0.55078125\n",
      "Batch: 11, Loss: 1.624517560005188, Accuracy: 0.48046875\n",
      "Batch: 12, Loss: 1.663352131843567, Accuracy: 0.490234375\n",
      "Batch: 13, Loss: 1.367720127105713, Accuracy: 0.6044921875\n",
      "Batch: 14, Loss: 1.5962295532226562, Accuracy: 0.5048828125\n",
      "Batch: 15, Loss: 1.461835503578186, Accuracy: 0.5625\n",
      "Batch: 16, Loss: 1.455886960029602, Accuracy: 0.5615234375\n",
      "Batch: 17, Loss: 1.5850629806518555, Accuracy: 0.513671875\n",
      "Batch: 18, Loss: 1.5999233722686768, Accuracy: 0.509765625\n",
      "Batch: 19, Loss: 1.616015911102295, Accuracy: 0.529296875\n",
      "Batch: 20, Loss: 1.5050488710403442, Accuracy: 0.55859375\n",
      "Batch: 21, Loss: 1.4443819522857666, Accuracy: 0.5732421875\n",
      "Batch: 22, Loss: 1.6186814308166504, Accuracy: 0.5126953125\n",
      "Batch: 23, Loss: 1.4750020503997803, Accuracy: 0.537109375\n",
      "Batch: 24, Loss: 1.5323917865753174, Accuracy: 0.5224609375\n",
      "Batch: 25, Loss: 1.4666461944580078, Accuracy: 0.5361328125\n",
      "Batch: 26, Loss: 1.3959003686904907, Accuracy: 0.5732421875\n",
      "Batch: 27, Loss: 1.4803417921066284, Accuracy: 0.5244140625\n",
      "Batch: 28, Loss: 1.5182067155838013, Accuracy: 0.509765625\n",
      "Batch: 29, Loss: 1.5587642192840576, Accuracy: 0.5107421875\n",
      "Batch: 30, Loss: 1.490309476852417, Accuracy: 0.548828125\n",
      "Batch: 31, Loss: 1.473714828491211, Accuracy: 0.5771484375\n",
      "Batch: 32, Loss: 1.4126120805740356, Accuracy: 0.5576171875\n",
      "Batch: 33, Loss: 1.6134345531463623, Accuracy: 0.4990234375\n",
      "Batch: 34, Loss: 1.6865273714065552, Accuracy: 0.4931640625\n",
      "Batch: 35, Loss: 1.5515142679214478, Accuracy: 0.525390625\n",
      "Batch: 36, Loss: 1.5156781673431396, Accuracy: 0.54296875\n",
      "Batch: 37, Loss: 1.5478415489196777, Accuracy: 0.517578125\n",
      "Batch: 38, Loss: 1.5121808052062988, Accuracy: 0.5244140625\n",
      "Batch: 39, Loss: 1.5539419651031494, Accuracy: 0.5302734375\n",
      "Batch: 40, Loss: 1.5558887720108032, Accuracy: 0.548828125\n",
      "Batch: 41, Loss: 1.6284162998199463, Accuracy: 0.54296875\n",
      "Batch: 42, Loss: 1.3290263414382935, Accuracy: 0.5927734375\n",
      "Batch: 43, Loss: 1.4565942287445068, Accuracy: 0.5244140625\n",
      "Batch: 44, Loss: 1.4421026706695557, Accuracy: 0.5419921875\n",
      "Batch: 45, Loss: 1.3086681365966797, Accuracy: 0.5732421875\n",
      "Batch: 46, Loss: 1.5441964864730835, Accuracy: 0.5595703125\n",
      "Batch: 47, Loss: 1.4980278015136719, Accuracy: 0.55859375\n",
      "Batch: 48, Loss: 1.4831300973892212, Accuracy: 0.5625\n",
      "Batch: 49, Loss: 1.589307427406311, Accuracy: 0.5078125\n",
      "Batch: 50, Loss: 1.5480988025665283, Accuracy: 0.525390625\n",
      "Batch: 51, Loss: 1.6431686878204346, Accuracy: 0.5\n",
      "Batch: 52, Loss: 1.604612112045288, Accuracy: 0.5205078125\n",
      "Batch: 53, Loss: 1.324941873550415, Accuracy: 0.5703125\n",
      "Batch: 54, Loss: 1.4480713605880737, Accuracy: 0.5703125\n",
      "Batch: 55, Loss: 1.4668525457382202, Accuracy: 0.54296875\n",
      "Batch: 56, Loss: 1.5812731981277466, Accuracy: 0.5146484375\n",
      "Batch: 57, Loss: 1.463484287261963, Accuracy: 0.5498046875\n",
      "Batch: 58, Loss: 1.6033331155776978, Accuracy: 0.5166015625\n",
      "Batch: 59, Loss: 1.3837134838104248, Accuracy: 0.5927734375\n",
      "Batch: 60, Loss: 1.3901262283325195, Accuracy: 0.5830078125\n",
      "Batch: 61, Loss: 1.5306285619735718, Accuracy: 0.529296875\n",
      "Batch: 62, Loss: 1.494170069694519, Accuracy: 0.55078125\n",
      "Batch: 63, Loss: 1.4891383647918701, Accuracy: 0.5283203125\n",
      "Batch: 64, Loss: 1.4600094556808472, Accuracy: 0.556640625\n",
      "Batch: 65, Loss: 1.499754786491394, Accuracy: 0.546875\n",
      "Batch: 66, Loss: 1.3977065086364746, Accuracy: 0.576171875\n",
      "Batch: 67, Loss: 1.5428318977355957, Accuracy: 0.53515625\n",
      "Batch: 68, Loss: 1.6133328676223755, Accuracy: 0.5361328125\n",
      "Batch: 69, Loss: 1.505915641784668, Accuracy: 0.5478515625\n",
      "Batch: 70, Loss: 1.560915470123291, Accuracy: 0.5458984375\n",
      "Batch: 71, Loss: 1.5285059213638306, Accuracy: 0.5283203125\n",
      "Batch: 72, Loss: 1.4081001281738281, Accuracy: 0.5751953125\n",
      "Batch: 73, Loss: 1.5119497776031494, Accuracy: 0.5654296875\n",
      "Batch: 74, Loss: 1.421645164489746, Accuracy: 0.5517578125\n",
      "Batch: 75, Loss: 1.3660476207733154, Accuracy: 0.57421875\n",
      "Batch: 76, Loss: 1.530895709991455, Accuracy: 0.5078125\n",
      "Batch: 77, Loss: 1.5022375583648682, Accuracy: 0.521484375\n",
      "Batch: 78, Loss: 1.4935002326965332, Accuracy: 0.578125\n",
      "Batch: 79, Loss: 1.3025962114334106, Accuracy: 0.6201171875\n",
      "Batch: 80, Loss: 1.3651986122131348, Accuracy: 0.5625\n",
      "Batch: 81, Loss: 1.5243779420852661, Accuracy: 0.4873046875\n",
      "Batch: 82, Loss: 1.5089163780212402, Accuracy: 0.5068359375\n",
      "Batch: 83, Loss: 1.348212480545044, Accuracy: 0.5859375\n",
      "Batch: 84, Loss: 1.4364181756973267, Accuracy: 0.5859375\n",
      "Batch: 85, Loss: 1.3280495405197144, Accuracy: 0.5859375\n",
      "Batch: 86, Loss: 1.6113533973693848, Accuracy: 0.5029296875\n",
      "Batch: 87, Loss: 1.3910949230194092, Accuracy: 0.5751953125\n",
      "Batch: 88, Loss: 1.5385262966156006, Accuracy: 0.541015625\n",
      "Batch: 89, Loss: 1.5775108337402344, Accuracy: 0.5234375\n",
      "Batch: 90, Loss: 1.3991789817810059, Accuracy: 0.560546875\n",
      "Batch: 91, Loss: 1.4314696788787842, Accuracy: 0.546875\n",
      "Batch: 92, Loss: 1.52955961227417, Accuracy: 0.5234375\n",
      "Batch: 93, Loss: 1.417039155960083, Accuracy: 0.5673828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 94, Loss: 1.4130470752716064, Accuracy: 0.552734375\n",
      "Batch: 95, Loss: 1.4599239826202393, Accuracy: 0.5439453125\n",
      "Batch: 96, Loss: 1.4470911026000977, Accuracy: 0.564453125\n",
      "Batch: 97, Loss: 1.3294097185134888, Accuracy: 0.58203125\n",
      "Batch: 98, Loss: 1.3185031414031982, Accuracy: 0.599609375\n",
      "Batch: 99, Loss: 1.3147978782653809, Accuracy: 0.583984375\n",
      "Batch: 100, Loss: 1.4293618202209473, Accuracy: 0.552734375\n",
      "Batch: 101, Loss: 1.453383445739746, Accuracy: 0.5390625\n",
      "Batch: 102, Loss: 1.3640328645706177, Accuracy: 0.5595703125\n",
      "Batch: 103, Loss: 1.4645557403564453, Accuracy: 0.5625\n",
      "Batch: 104, Loss: 1.3532359600067139, Accuracy: 0.568359375\n",
      "Batch: 105, Loss: 1.4666082859039307, Accuracy: 0.5439453125\n",
      "Batch: 106, Loss: 1.5054612159729004, Accuracy: 0.537109375\n",
      "Batch: 107, Loss: 1.624757170677185, Accuracy: 0.5029296875\n",
      "Batch: 108, Loss: 1.5525163412094116, Accuracy: 0.515625\n",
      "Batch: 109, Loss: 1.6077959537506104, Accuracy: 0.4970703125\n",
      "Batch: 110, Loss: 1.2832832336425781, Accuracy: 0.59375\n",
      "Batch: 111, Loss: 1.497753381729126, Accuracy: 0.529296875\n",
      "Batch: 112, Loss: 1.4036219120025635, Accuracy: 0.568359375\n",
      "Batch: 113, Loss: 1.4537181854248047, Accuracy: 0.572265625\n",
      "Batch: 114, Loss: 1.5651196241378784, Accuracy: 0.515625\n",
      "Batch: 115, Loss: 1.6150978803634644, Accuracy: 0.548828125\n",
      "Batch: 116, Loss: 1.5435550212860107, Accuracy: 0.515625\n",
      "Batch: 117, Loss: 1.529672384262085, Accuracy: 0.54296875\n",
      "Batch: 118, Loss: 1.3049588203430176, Accuracy: 0.6083984375\n",
      "Batch: 119, Loss: 1.3759795427322388, Accuracy: 0.5791015625\n",
      "Batch: 120, Loss: 1.5211526155471802, Accuracy: 0.51953125\n",
      "Batch: 121, Loss: 1.5965678691864014, Accuracy: 0.509765625\n",
      "Batch: 122, Loss: 1.401172161102295, Accuracy: 0.5888671875\n",
      "Batch: 123, Loss: 1.4069809913635254, Accuracy: 0.5771484375\n",
      "Batch: 124, Loss: 1.4361605644226074, Accuracy: 0.576171875\n",
      "Batch: 125, Loss: 1.4966809749603271, Accuracy: 0.537109375\n",
      "Batch: 126, Loss: 1.4951014518737793, Accuracy: 0.51953125\n",
      "Batch: 127, Loss: 1.3546937704086304, Accuracy: 0.595703125\n",
      "Batch: 128, Loss: 1.5872772932052612, Accuracy: 0.5263671875\n",
      "Batch: 129, Loss: 1.434512734413147, Accuracy: 0.5390625\n",
      "Batch: 130, Loss: 1.6569024324417114, Accuracy: 0.501953125\n",
      "Batch: 131, Loss: 1.4843037128448486, Accuracy: 0.541015625\n",
      "Batch: 132, Loss: 1.5795087814331055, Accuracy: 0.533203125\n",
      "Batch: 133, Loss: 1.4365849494934082, Accuracy: 0.5537109375\n",
      "Batch: 134, Loss: 1.491443157196045, Accuracy: 0.5263671875\n",
      "Batch: 135, Loss: 1.386622428894043, Accuracy: 0.587890625\n",
      "Batch: 136, Loss: 1.4488470554351807, Accuracy: 0.537109375\n",
      "Batch: 137, Loss: 1.3596525192260742, Accuracy: 0.544921875\n",
      "Batch: 138, Loss: 1.2246533632278442, Accuracy: 0.59765625\n",
      "Batch: 139, Loss: 1.3017208576202393, Accuracy: 0.556640625\n",
      "Batch: 140, Loss: 1.4368023872375488, Accuracy: 0.54296875\n",
      "Batch: 141, Loss: 1.4229097366333008, Accuracy: 0.556640625\n",
      "Batch: 142, Loss: 1.4730236530303955, Accuracy: 0.533203125\n",
      "Batch: 143, Loss: 1.4708311557769775, Accuracy: 0.5517578125\n",
      "Batch: 144, Loss: 1.447661280632019, Accuracy: 0.5458984375\n",
      "Batch: 145, Loss: 1.3529939651489258, Accuracy: 0.560546875\n",
      "Batch: 146, Loss: 1.5419297218322754, Accuracy: 0.5244140625\n",
      "Batch: 147, Loss: 1.4347840547561646, Accuracy: 0.5517578125\n",
      "Batch: 148, Loss: 1.6069285869598389, Accuracy: 0.4931640625\n",
      "Batch: 149, Loss: 1.5201809406280518, Accuracy: 0.5302734375\n",
      "Batch: 150, Loss: 1.3969041109085083, Accuracy: 0.5615234375\n",
      "Batch: 151, Loss: 1.3723294734954834, Accuracy: 0.5791015625\n",
      "Epoch 6/90\n",
      "Batch: 1, Loss: 1.7147043943405151, Accuracy: 0.4892578125\n",
      "Batch: 2, Loss: 1.4223270416259766, Accuracy: 0.529296875\n",
      "Batch: 3, Loss: 1.3796377182006836, Accuracy: 0.552734375\n",
      "Batch: 4, Loss: 1.286501169204712, Accuracy: 0.6240234375\n",
      "Batch: 5, Loss: 1.3254388570785522, Accuracy: 0.5908203125\n",
      "Batch: 6, Loss: 1.4689449071884155, Accuracy: 0.515625\n",
      "Batch: 7, Loss: 1.3725496530532837, Accuracy: 0.5595703125\n",
      "Batch: 8, Loss: 1.3584483861923218, Accuracy: 0.5693359375\n",
      "Batch: 9, Loss: 1.2896665334701538, Accuracy: 0.587890625\n",
      "Batch: 10, Loss: 1.3488194942474365, Accuracy: 0.560546875\n",
      "Batch: 11, Loss: 1.5189601182937622, Accuracy: 0.5205078125\n",
      "Batch: 12, Loss: 1.5559651851654053, Accuracy: 0.5029296875\n",
      "Batch: 13, Loss: 1.2397210597991943, Accuracy: 0.6162109375\n",
      "Batch: 14, Loss: 1.4847996234893799, Accuracy: 0.537109375\n",
      "Batch: 15, Loss: 1.370633602142334, Accuracy: 0.5849609375\n",
      "Batch: 16, Loss: 1.3677752017974854, Accuracy: 0.57421875\n",
      "Batch: 17, Loss: 1.4612462520599365, Accuracy: 0.5283203125\n",
      "Batch: 18, Loss: 1.4577728509902954, Accuracy: 0.5283203125\n",
      "Batch: 19, Loss: 1.504629135131836, Accuracy: 0.5380859375\n",
      "Batch: 20, Loss: 1.4098145961761475, Accuracy: 0.583984375\n",
      "Batch: 21, Loss: 1.3387877941131592, Accuracy: 0.580078125\n",
      "Batch: 22, Loss: 1.523391604423523, Accuracy: 0.521484375\n",
      "Batch: 23, Loss: 1.3790887594223022, Accuracy: 0.5546875\n",
      "Batch: 24, Loss: 1.4300132989883423, Accuracy: 0.5517578125\n",
      "Batch: 25, Loss: 1.3769829273223877, Accuracy: 0.5595703125\n",
      "Batch: 26, Loss: 1.3071846961975098, Accuracy: 0.591796875\n",
      "Batch: 27, Loss: 1.396209955215454, Accuracy: 0.5478515625\n",
      "Batch: 28, Loss: 1.4455935955047607, Accuracy: 0.5283203125\n",
      "Batch: 29, Loss: 1.4620046615600586, Accuracy: 0.5244140625\n",
      "Batch: 30, Loss: 1.3961546421051025, Accuracy: 0.58203125\n",
      "Batch: 31, Loss: 1.3679571151733398, Accuracy: 0.58984375\n",
      "Batch: 32, Loss: 1.3279006481170654, Accuracy: 0.5712890625\n",
      "Batch: 33, Loss: 1.5362653732299805, Accuracy: 0.5224609375\n",
      "Batch: 34, Loss: 1.6212146282196045, Accuracy: 0.501953125\n",
      "Batch: 35, Loss: 1.4436051845550537, Accuracy: 0.5341796875\n",
      "Batch: 36, Loss: 1.45154869556427, Accuracy: 0.5556640625\n",
      "Batch: 37, Loss: 1.4526327848434448, Accuracy: 0.5390625\n",
      "Batch: 38, Loss: 1.427180528640747, Accuracy: 0.5400390625\n",
      "Batch: 39, Loss: 1.4777286052703857, Accuracy: 0.5537109375\n",
      "Batch: 40, Loss: 1.4783990383148193, Accuracy: 0.5703125\n",
      "Batch: 41, Loss: 1.5092475414276123, Accuracy: 0.556640625\n",
      "Batch: 42, Loss: 1.2280426025390625, Accuracy: 0.6240234375\n",
      "Batch: 43, Loss: 1.3798714876174927, Accuracy: 0.552734375\n",
      "Batch: 44, Loss: 1.3790783882141113, Accuracy: 0.5478515625\n",
      "Batch: 45, Loss: 1.2448433637619019, Accuracy: 0.5888671875\n",
      "Batch: 46, Loss: 1.4630320072174072, Accuracy: 0.56640625\n",
      "Batch: 47, Loss: 1.4031504392623901, Accuracy: 0.572265625\n",
      "Batch: 48, Loss: 1.3990061283111572, Accuracy: 0.572265625\n",
      "Batch: 49, Loss: 1.5107941627502441, Accuracy: 0.5322265625\n",
      "Batch: 50, Loss: 1.477147102355957, Accuracy: 0.52734375\n",
      "Batch: 51, Loss: 1.5521132946014404, Accuracy: 0.509765625\n",
      "Batch: 52, Loss: 1.510178565979004, Accuracy: 0.541015625\n",
      "Batch: 53, Loss: 1.2384138107299805, Accuracy: 0.6015625\n",
      "Batch: 54, Loss: 1.356447696685791, Accuracy: 0.59375\n",
      "Batch: 55, Loss: 1.4056572914123535, Accuracy: 0.556640625\n",
      "Batch: 56, Loss: 1.4951317310333252, Accuracy: 0.5419921875\n",
      "Batch: 57, Loss: 1.4033039808273315, Accuracy: 0.5693359375\n",
      "Batch: 58, Loss: 1.5131555795669556, Accuracy: 0.55078125\n",
      "Batch: 59, Loss: 1.301238775253296, Accuracy: 0.619140625\n",
      "Batch: 60, Loss: 1.3215718269348145, Accuracy: 0.609375\n",
      "Batch: 61, Loss: 1.433626651763916, Accuracy: 0.556640625\n",
      "Batch: 62, Loss: 1.4018304347991943, Accuracy: 0.5576171875\n",
      "Batch: 63, Loss: 1.4042171239852905, Accuracy: 0.541015625\n",
      "Batch: 64, Loss: 1.3695281744003296, Accuracy: 0.5859375\n",
      "Batch: 65, Loss: 1.4230912923812866, Accuracy: 0.5595703125\n",
      "Batch: 66, Loss: 1.3065482378005981, Accuracy: 0.6044921875\n",
      "Batch: 67, Loss: 1.4809223413467407, Accuracy: 0.560546875\n",
      "Batch: 68, Loss: 1.5197415351867676, Accuracy: 0.5517578125\n",
      "Batch: 69, Loss: 1.4229917526245117, Accuracy: 0.5576171875\n",
      "Batch: 70, Loss: 1.4614343643188477, Accuracy: 0.5703125\n",
      "Batch: 71, Loss: 1.4358289241790771, Accuracy: 0.5546875\n",
      "Batch: 72, Loss: 1.313640832901001, Accuracy: 0.5908203125\n",
      "Batch: 73, Loss: 1.4033253192901611, Accuracy: 0.580078125\n",
      "Batch: 74, Loss: 1.3404624462127686, Accuracy: 0.5849609375\n",
      "Batch: 75, Loss: 1.2773752212524414, Accuracy: 0.6005859375\n",
      "Batch: 76, Loss: 1.4464917182922363, Accuracy: 0.5283203125\n",
      "Batch: 77, Loss: 1.4160429239273071, Accuracy: 0.5517578125\n",
      "Batch: 78, Loss: 1.403642177581787, Accuracy: 0.5791015625\n",
      "Batch: 79, Loss: 1.2358243465423584, Accuracy: 0.634765625\n",
      "Batch: 80, Loss: 1.3004851341247559, Accuracy: 0.57421875\n",
      "Batch: 81, Loss: 1.4439836740493774, Accuracy: 0.525390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 82, Loss: 1.427407145500183, Accuracy: 0.5224609375\n",
      "Batch: 83, Loss: 1.273787498474121, Accuracy: 0.615234375\n",
      "Batch: 84, Loss: 1.3476026058197021, Accuracy: 0.591796875\n",
      "Batch: 85, Loss: 1.2678203582763672, Accuracy: 0.59765625\n",
      "Batch: 86, Loss: 1.5384883880615234, Accuracy: 0.5205078125\n",
      "Batch: 87, Loss: 1.3147426843643188, Accuracy: 0.5927734375\n",
      "Batch: 88, Loss: 1.4542491436004639, Accuracy: 0.5546875\n",
      "Batch: 89, Loss: 1.4793109893798828, Accuracy: 0.5478515625\n",
      "Batch: 90, Loss: 1.337890386581421, Accuracy: 0.5751953125\n",
      "Batch: 91, Loss: 1.3741652965545654, Accuracy: 0.5615234375\n",
      "Batch: 92, Loss: 1.418610692024231, Accuracy: 0.5546875\n",
      "Batch: 93, Loss: 1.3106300830841064, Accuracy: 0.609375\n",
      "Batch: 94, Loss: 1.3529497385025024, Accuracy: 0.5634765625\n",
      "Batch: 95, Loss: 1.400634765625, Accuracy: 0.548828125\n",
      "Batch: 96, Loss: 1.3721275329589844, Accuracy: 0.583984375\n",
      "Batch: 97, Loss: 1.251258134841919, Accuracy: 0.6064453125\n",
      "Batch: 98, Loss: 1.2556941509246826, Accuracy: 0.626953125\n",
      "Batch: 99, Loss: 1.2370262145996094, Accuracy: 0.6015625\n",
      "Batch: 100, Loss: 1.3731757402420044, Accuracy: 0.5673828125\n",
      "Batch: 101, Loss: 1.4116017818450928, Accuracy: 0.56640625\n",
      "Batch: 102, Loss: 1.290867567062378, Accuracy: 0.5810546875\n",
      "Batch: 103, Loss: 1.4122836589813232, Accuracy: 0.5947265625\n",
      "Batch: 104, Loss: 1.2670291662216187, Accuracy: 0.5947265625\n",
      "Batch: 105, Loss: 1.4155216217041016, Accuracy: 0.5498046875\n",
      "Batch: 106, Loss: 1.4303677082061768, Accuracy: 0.5576171875\n",
      "Batch: 107, Loss: 1.5540955066680908, Accuracy: 0.517578125\n",
      "Batch: 108, Loss: 1.4694247245788574, Accuracy: 0.5400390625\n",
      "Batch: 109, Loss: 1.5443816184997559, Accuracy: 0.515625\n",
      "Batch: 110, Loss: 1.1969873905181885, Accuracy: 0.609375\n",
      "Batch: 111, Loss: 1.4368261098861694, Accuracy: 0.533203125\n",
      "Batch: 112, Loss: 1.3638519048690796, Accuracy: 0.572265625\n",
      "Batch: 113, Loss: 1.3682239055633545, Accuracy: 0.595703125\n",
      "Batch: 114, Loss: 1.5164313316345215, Accuracy: 0.5322265625\n",
      "Batch: 115, Loss: 1.5409711599349976, Accuracy: 0.5458984375\n",
      "Batch: 116, Loss: 1.4744846820831299, Accuracy: 0.5361328125\n",
      "Batch: 117, Loss: 1.4550135135650635, Accuracy: 0.5673828125\n",
      "Batch: 118, Loss: 1.23960542678833, Accuracy: 0.6220703125\n",
      "Batch: 119, Loss: 1.2953510284423828, Accuracy: 0.607421875\n",
      "Batch: 120, Loss: 1.4609851837158203, Accuracy: 0.5419921875\n",
      "Batch: 121, Loss: 1.483055830001831, Accuracy: 0.544921875\n",
      "Batch: 122, Loss: 1.343705177307129, Accuracy: 0.595703125\n",
      "Batch: 123, Loss: 1.3277382850646973, Accuracy: 0.5888671875\n",
      "Batch: 124, Loss: 1.3892353773117065, Accuracy: 0.58203125\n",
      "Batch: 125, Loss: 1.4361212253570557, Accuracy: 0.56640625\n",
      "Batch: 126, Loss: 1.4202752113342285, Accuracy: 0.5517578125\n",
      "Batch: 127, Loss: 1.2706003189086914, Accuracy: 0.6298828125\n",
      "Batch: 128, Loss: 1.5255794525146484, Accuracy: 0.53515625\n",
      "Batch: 129, Loss: 1.3676520586013794, Accuracy: 0.5693359375\n",
      "Batch: 130, Loss: 1.579830288887024, Accuracy: 0.521484375\n",
      "Batch: 131, Loss: 1.4366822242736816, Accuracy: 0.5546875\n",
      "Batch: 132, Loss: 1.5074350833892822, Accuracy: 0.5390625\n",
      "Batch: 133, Loss: 1.350369930267334, Accuracy: 0.57421875\n",
      "Batch: 134, Loss: 1.4263741970062256, Accuracy: 0.564453125\n",
      "Batch: 135, Loss: 1.30793035030365, Accuracy: 0.603515625\n",
      "Batch: 136, Loss: 1.3764888048171997, Accuracy: 0.5693359375\n",
      "Batch: 137, Loss: 1.2855650186538696, Accuracy: 0.583984375\n",
      "Batch: 138, Loss: 1.1790722608566284, Accuracy: 0.6083984375\n",
      "Batch: 139, Loss: 1.2338427305221558, Accuracy: 0.5849609375\n",
      "Batch: 140, Loss: 1.3630964756011963, Accuracy: 0.560546875\n",
      "Batch: 141, Loss: 1.3676178455352783, Accuracy: 0.576171875\n",
      "Batch: 142, Loss: 1.406268835067749, Accuracy: 0.56640625\n",
      "Batch: 143, Loss: 1.4087852239608765, Accuracy: 0.5625\n",
      "Batch: 144, Loss: 1.3839774131774902, Accuracy: 0.5732421875\n",
      "Batch: 145, Loss: 1.3022704124450684, Accuracy: 0.5615234375\n",
      "Batch: 146, Loss: 1.4553799629211426, Accuracy: 0.5341796875\n",
      "Batch: 147, Loss: 1.3895134925842285, Accuracy: 0.56640625\n",
      "Batch: 148, Loss: 1.539715051651001, Accuracy: 0.5078125\n",
      "Batch: 149, Loss: 1.4264461994171143, Accuracy: 0.546875\n",
      "Batch: 150, Loss: 1.3251962661743164, Accuracy: 0.5791015625\n",
      "Batch: 151, Loss: 1.2928462028503418, Accuracy: 0.5927734375\n",
      "Epoch 7/90\n",
      "Batch: 1, Loss: 1.6450557708740234, Accuracy: 0.5009765625\n",
      "Batch: 2, Loss: 1.345159649848938, Accuracy: 0.5546875\n",
      "Batch: 3, Loss: 1.2779654264450073, Accuracy: 0.58984375\n",
      "Batch: 4, Loss: 1.211355447769165, Accuracy: 0.6298828125\n",
      "Batch: 5, Loss: 1.2454423904418945, Accuracy: 0.623046875\n",
      "Batch: 6, Loss: 1.3787790536880493, Accuracy: 0.55078125\n",
      "Batch: 7, Loss: 1.3031799793243408, Accuracy: 0.5849609375\n",
      "Batch: 8, Loss: 1.313627004623413, Accuracy: 0.57421875\n",
      "Batch: 9, Loss: 1.223607063293457, Accuracy: 0.6142578125\n",
      "Batch: 10, Loss: 1.2611035108566284, Accuracy: 0.595703125\n",
      "Batch: 11, Loss: 1.4577585458755493, Accuracy: 0.5458984375\n",
      "Batch: 12, Loss: 1.4927594661712646, Accuracy: 0.529296875\n",
      "Batch: 13, Loss: 1.166198492050171, Accuracy: 0.6357421875\n",
      "Batch: 14, Loss: 1.4291893243789673, Accuracy: 0.548828125\n",
      "Batch: 15, Loss: 1.2756267786026, Accuracy: 0.6083984375\n",
      "Batch: 16, Loss: 1.2937746047973633, Accuracy: 0.5869140625\n",
      "Batch: 17, Loss: 1.3917076587677002, Accuracy: 0.544921875\n",
      "Batch: 18, Loss: 1.3942919969558716, Accuracy: 0.5380859375\n",
      "Batch: 19, Loss: 1.4439153671264648, Accuracy: 0.5478515625\n",
      "Batch: 20, Loss: 1.3435713052749634, Accuracy: 0.59765625\n",
      "Batch: 21, Loss: 1.2840723991394043, Accuracy: 0.59765625\n",
      "Batch: 22, Loss: 1.4487502574920654, Accuracy: 0.546875\n",
      "Batch: 23, Loss: 1.3154821395874023, Accuracy: 0.5673828125\n",
      "Batch: 24, Loss: 1.3582215309143066, Accuracy: 0.5732421875\n",
      "Batch: 25, Loss: 1.327298641204834, Accuracy: 0.572265625\n",
      "Batch: 26, Loss: 1.241750717163086, Accuracy: 0.6025390625\n",
      "Batch: 27, Loss: 1.312457799911499, Accuracy: 0.5654296875\n",
      "Batch: 28, Loss: 1.371944546699524, Accuracy: 0.55078125\n",
      "Batch: 29, Loss: 1.3844292163848877, Accuracy: 0.5595703125\n",
      "Batch: 30, Loss: 1.3333690166473389, Accuracy: 0.603515625\n",
      "Batch: 31, Loss: 1.3274729251861572, Accuracy: 0.5908203125\n",
      "Batch: 32, Loss: 1.265066385269165, Accuracy: 0.58984375\n",
      "Batch: 33, Loss: 1.4609203338623047, Accuracy: 0.5322265625\n",
      "Batch: 34, Loss: 1.542130947113037, Accuracy: 0.52734375\n",
      "Batch: 35, Loss: 1.3920491933822632, Accuracy: 0.5361328125\n",
      "Batch: 36, Loss: 1.3641473054885864, Accuracy: 0.5810546875\n",
      "Batch: 37, Loss: 1.3516502380371094, Accuracy: 0.5693359375\n",
      "Batch: 38, Loss: 1.3180534839630127, Accuracy: 0.564453125\n",
      "Batch: 39, Loss: 1.390148639678955, Accuracy: 0.57421875\n",
      "Batch: 40, Loss: 1.419995665550232, Accuracy: 0.572265625\n",
      "Batch: 41, Loss: 1.4155553579330444, Accuracy: 0.576171875\n",
      "Batch: 42, Loss: 1.1661596298217773, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.324854850769043, Accuracy: 0.5771484375\n",
      "Batch: 44, Loss: 1.31904137134552, Accuracy: 0.5625\n",
      "Batch: 45, Loss: 1.1863771677017212, Accuracy: 0.615234375\n",
      "Batch: 46, Loss: 1.3699733018875122, Accuracy: 0.5908203125\n",
      "Batch: 47, Loss: 1.3223657608032227, Accuracy: 0.5888671875\n",
      "Batch: 48, Loss: 1.3059829473495483, Accuracy: 0.5986328125\n",
      "Batch: 49, Loss: 1.450408697128296, Accuracy: 0.552734375\n",
      "Batch: 50, Loss: 1.3800956010818481, Accuracy: 0.5634765625\n",
      "Batch: 51, Loss: 1.5023747682571411, Accuracy: 0.5244140625\n",
      "Batch: 52, Loss: 1.4495429992675781, Accuracy: 0.5625\n",
      "Batch: 53, Loss: 1.1808685064315796, Accuracy: 0.6171875\n",
      "Batch: 54, Loss: 1.3264590501785278, Accuracy: 0.6083984375\n",
      "Batch: 55, Loss: 1.3412083387374878, Accuracy: 0.5673828125\n",
      "Batch: 56, Loss: 1.4131531715393066, Accuracy: 0.5556640625\n",
      "Batch: 57, Loss: 1.3298414945602417, Accuracy: 0.5986328125\n",
      "Batch: 58, Loss: 1.4349647760391235, Accuracy: 0.5625\n",
      "Batch: 59, Loss: 1.2389819622039795, Accuracy: 0.619140625\n",
      "Batch: 60, Loss: 1.2442941665649414, Accuracy: 0.6083984375\n",
      "Batch: 61, Loss: 1.3882451057434082, Accuracy: 0.5546875\n",
      "Batch: 62, Loss: 1.3427889347076416, Accuracy: 0.5751953125\n",
      "Batch: 63, Loss: 1.3300666809082031, Accuracy: 0.5693359375\n",
      "Batch: 64, Loss: 1.3305069208145142, Accuracy: 0.5849609375\n",
      "Batch: 65, Loss: 1.3758471012115479, Accuracy: 0.560546875\n",
      "Batch: 66, Loss: 1.2607818841934204, Accuracy: 0.609375\n",
      "Batch: 67, Loss: 1.4257060289382935, Accuracy: 0.5634765625\n",
      "Batch: 68, Loss: 1.4795012474060059, Accuracy: 0.578125\n",
      "Batch: 69, Loss: 1.3653879165649414, Accuracy: 0.57421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 70, Loss: 1.395064353942871, Accuracy: 0.5849609375\n",
      "Batch: 71, Loss: 1.385195255279541, Accuracy: 0.564453125\n",
      "Batch: 72, Loss: 1.2649893760681152, Accuracy: 0.61328125\n",
      "Batch: 73, Loss: 1.3323345184326172, Accuracy: 0.603515625\n",
      "Batch: 74, Loss: 1.2570736408233643, Accuracy: 0.5908203125\n",
      "Batch: 75, Loss: 1.216668725013733, Accuracy: 0.6083984375\n",
      "Batch: 76, Loss: 1.3855681419372559, Accuracy: 0.5390625\n",
      "Batch: 77, Loss: 1.3471962213516235, Accuracy: 0.5595703125\n",
      "Batch: 78, Loss: 1.3524872064590454, Accuracy: 0.5859375\n",
      "Batch: 79, Loss: 1.1687349081039429, Accuracy: 0.6591796875\n",
      "Batch: 80, Loss: 1.242111086845398, Accuracy: 0.5859375\n",
      "Batch: 81, Loss: 1.409988284111023, Accuracy: 0.5107421875\n",
      "Batch: 82, Loss: 1.369179368019104, Accuracy: 0.5498046875\n",
      "Batch: 83, Loss: 1.2272123098373413, Accuracy: 0.623046875\n",
      "Batch: 84, Loss: 1.2750627994537354, Accuracy: 0.6064453125\n",
      "Batch: 85, Loss: 1.203683614730835, Accuracy: 0.6279296875\n",
      "Batch: 86, Loss: 1.4881808757781982, Accuracy: 0.533203125\n",
      "Batch: 87, Loss: 1.2590692043304443, Accuracy: 0.6142578125\n",
      "Batch: 88, Loss: 1.4043967723846436, Accuracy: 0.5859375\n",
      "Batch: 89, Loss: 1.4217979907989502, Accuracy: 0.5654296875\n",
      "Batch: 90, Loss: 1.2556190490722656, Accuracy: 0.6083984375\n",
      "Batch: 91, Loss: 1.3055591583251953, Accuracy: 0.5771484375\n",
      "Batch: 92, Loss: 1.3500289916992188, Accuracy: 0.576171875\n",
      "Batch: 93, Loss: 1.2507994174957275, Accuracy: 0.607421875\n",
      "Batch: 94, Loss: 1.283292531967163, Accuracy: 0.5830078125\n",
      "Batch: 95, Loss: 1.355297327041626, Accuracy: 0.56640625\n",
      "Batch: 96, Loss: 1.2912747859954834, Accuracy: 0.5859375\n",
      "Batch: 97, Loss: 1.1795594692230225, Accuracy: 0.6259765625\n",
      "Batch: 98, Loss: 1.201784610748291, Accuracy: 0.6328125\n",
      "Batch: 99, Loss: 1.182845115661621, Accuracy: 0.611328125\n",
      "Batch: 100, Loss: 1.2812237739562988, Accuracy: 0.59375\n",
      "Batch: 101, Loss: 1.3437254428863525, Accuracy: 0.576171875\n",
      "Batch: 102, Loss: 1.215848445892334, Accuracy: 0.6171875\n",
      "Batch: 103, Loss: 1.3384755849838257, Accuracy: 0.6083984375\n",
      "Batch: 104, Loss: 1.2059872150421143, Accuracy: 0.6044921875\n",
      "Batch: 105, Loss: 1.3527982234954834, Accuracy: 0.572265625\n",
      "Batch: 106, Loss: 1.3668456077575684, Accuracy: 0.580078125\n",
      "Batch: 107, Loss: 1.459553599357605, Accuracy: 0.5625\n",
      "Batch: 108, Loss: 1.3870456218719482, Accuracy: 0.5625\n",
      "Batch: 109, Loss: 1.4790936708450317, Accuracy: 0.5361328125\n",
      "Batch: 110, Loss: 1.1517198085784912, Accuracy: 0.6162109375\n",
      "Batch: 111, Loss: 1.3882209062576294, Accuracy: 0.5693359375\n",
      "Batch: 112, Loss: 1.2967605590820312, Accuracy: 0.59765625\n",
      "Batch: 113, Loss: 1.330488920211792, Accuracy: 0.6005859375\n",
      "Batch: 114, Loss: 1.4649484157562256, Accuracy: 0.556640625\n",
      "Batch: 115, Loss: 1.4578418731689453, Accuracy: 0.572265625\n",
      "Batch: 116, Loss: 1.4082045555114746, Accuracy: 0.5498046875\n",
      "Batch: 117, Loss: 1.3939241170883179, Accuracy: 0.5732421875\n",
      "Batch: 118, Loss: 1.1923120021820068, Accuracy: 0.630859375\n",
      "Batch: 119, Loss: 1.2369483709335327, Accuracy: 0.6220703125\n",
      "Batch: 120, Loss: 1.4003396034240723, Accuracy: 0.5615234375\n",
      "Batch: 121, Loss: 1.4444912672042847, Accuracy: 0.5478515625\n",
      "Batch: 122, Loss: 1.2853001356124878, Accuracy: 0.6181640625\n",
      "Batch: 123, Loss: 1.2498273849487305, Accuracy: 0.6025390625\n",
      "Batch: 124, Loss: 1.33235764503479, Accuracy: 0.58203125\n",
      "Batch: 125, Loss: 1.3567930459976196, Accuracy: 0.5732421875\n",
      "Batch: 126, Loss: 1.3641806840896606, Accuracy: 0.54296875\n",
      "Batch: 127, Loss: 1.2277605533599854, Accuracy: 0.6298828125\n",
      "Batch: 128, Loss: 1.4789273738861084, Accuracy: 0.552734375\n",
      "Batch: 129, Loss: 1.2926123142242432, Accuracy: 0.58203125\n",
      "Batch: 130, Loss: 1.5102128982543945, Accuracy: 0.537109375\n",
      "Batch: 131, Loss: 1.3643617630004883, Accuracy: 0.5712890625\n",
      "Batch: 132, Loss: 1.4451793432235718, Accuracy: 0.54296875\n",
      "Batch: 133, Loss: 1.2625946998596191, Accuracy: 0.5986328125\n",
      "Batch: 134, Loss: 1.3515002727508545, Accuracy: 0.5654296875\n",
      "Batch: 135, Loss: 1.2726483345031738, Accuracy: 0.603515625\n",
      "Batch: 136, Loss: 1.3101730346679688, Accuracy: 0.5751953125\n",
      "Batch: 137, Loss: 1.2229479551315308, Accuracy: 0.5947265625\n",
      "Batch: 138, Loss: 1.1115962266921997, Accuracy: 0.6396484375\n",
      "Batch: 139, Loss: 1.168247103691101, Accuracy: 0.6083984375\n",
      "Batch: 140, Loss: 1.3110411167144775, Accuracy: 0.5654296875\n",
      "Batch: 141, Loss: 1.3147565126419067, Accuracy: 0.583984375\n",
      "Batch: 142, Loss: 1.3574607372283936, Accuracy: 0.578125\n",
      "Batch: 143, Loss: 1.3489991426467896, Accuracy: 0.5859375\n",
      "Batch: 144, Loss: 1.3415589332580566, Accuracy: 0.580078125\n",
      "Batch: 145, Loss: 1.2452833652496338, Accuracy: 0.5869140625\n",
      "Batch: 146, Loss: 1.3882527351379395, Accuracy: 0.5595703125\n",
      "Batch: 147, Loss: 1.3473299741744995, Accuracy: 0.5634765625\n",
      "Batch: 148, Loss: 1.4834502935409546, Accuracy: 0.5263671875\n",
      "Batch: 149, Loss: 1.3713880777359009, Accuracy: 0.5546875\n",
      "Batch: 150, Loss: 1.2638674974441528, Accuracy: 0.603515625\n",
      "Batch: 151, Loss: 1.2437914609909058, Accuracy: 0.619140625\n",
      "Epoch 8/90\n",
      "Batch: 1, Loss: 1.5780084133148193, Accuracy: 0.5048828125\n",
      "Batch: 2, Loss: 1.3111766576766968, Accuracy: 0.564453125\n",
      "Batch: 3, Loss: 1.2580868005752563, Accuracy: 0.59375\n",
      "Batch: 4, Loss: 1.1666821241378784, Accuracy: 0.640625\n",
      "Batch: 5, Loss: 1.1982672214508057, Accuracy: 0.6171875\n",
      "Batch: 6, Loss: 1.3130252361297607, Accuracy: 0.5654296875\n",
      "Batch: 7, Loss: 1.248779058456421, Accuracy: 0.6005859375\n",
      "Batch: 8, Loss: 1.2322145700454712, Accuracy: 0.59375\n",
      "Batch: 9, Loss: 1.1638902425765991, Accuracy: 0.62890625\n",
      "Batch: 10, Loss: 1.217576503753662, Accuracy: 0.61328125\n",
      "Batch: 11, Loss: 1.4089847803115845, Accuracy: 0.5517578125\n",
      "Batch: 12, Loss: 1.4138023853302002, Accuracy: 0.5419921875\n",
      "Batch: 13, Loss: 1.1170051097869873, Accuracy: 0.6455078125\n",
      "Batch: 14, Loss: 1.3794443607330322, Accuracy: 0.56640625\n",
      "Batch: 15, Loss: 1.2280473709106445, Accuracy: 0.6259765625\n",
      "Batch: 16, Loss: 1.2304946184158325, Accuracy: 0.61328125\n",
      "Batch: 17, Loss: 1.3495084047317505, Accuracy: 0.5673828125\n",
      "Batch: 18, Loss: 1.3258072137832642, Accuracy: 0.5703125\n",
      "Batch: 19, Loss: 1.3998527526855469, Accuracy: 0.5576171875\n",
      "Batch: 20, Loss: 1.284653663635254, Accuracy: 0.615234375\n",
      "Batch: 21, Loss: 1.2227106094360352, Accuracy: 0.6015625\n",
      "Batch: 22, Loss: 1.389217734336853, Accuracy: 0.5634765625\n",
      "Batch: 23, Loss: 1.2559101581573486, Accuracy: 0.591796875\n",
      "Batch: 24, Loss: 1.3027299642562866, Accuracy: 0.5830078125\n",
      "Batch: 25, Loss: 1.2637104988098145, Accuracy: 0.59765625\n",
      "Batch: 26, Loss: 1.1549036502838135, Accuracy: 0.6259765625\n",
      "Batch: 27, Loss: 1.2363795042037964, Accuracy: 0.6005859375\n",
      "Batch: 28, Loss: 1.32184898853302, Accuracy: 0.568359375\n",
      "Batch: 29, Loss: 1.3529016971588135, Accuracy: 0.5673828125\n",
      "Batch: 30, Loss: 1.2715140581130981, Accuracy: 0.6171875\n",
      "Batch: 31, Loss: 1.2670749425888062, Accuracy: 0.609375\n",
      "Batch: 32, Loss: 1.1671442985534668, Accuracy: 0.6044921875\n",
      "Batch: 33, Loss: 1.4202122688293457, Accuracy: 0.5517578125\n",
      "Batch: 34, Loss: 1.476430058479309, Accuracy: 0.5439453125\n",
      "Batch: 35, Loss: 1.323431372642517, Accuracy: 0.5673828125\n",
      "Batch: 36, Loss: 1.309241533279419, Accuracy: 0.5869140625\n",
      "Batch: 37, Loss: 1.2838034629821777, Accuracy: 0.580078125\n",
      "Batch: 38, Loss: 1.295434832572937, Accuracy: 0.5703125\n",
      "Batch: 39, Loss: 1.3362512588500977, Accuracy: 0.59375\n",
      "Batch: 40, Loss: 1.356981635093689, Accuracy: 0.591796875\n",
      "Batch: 41, Loss: 1.3650810718536377, Accuracy: 0.5859375\n",
      "Batch: 42, Loss: 1.0984028577804565, Accuracy: 0.6435546875\n",
      "Batch: 43, Loss: 1.2778414487838745, Accuracy: 0.58984375\n",
      "Batch: 44, Loss: 1.26663339138031, Accuracy: 0.587890625\n",
      "Batch: 45, Loss: 1.1435706615447998, Accuracy: 0.6162109375\n",
      "Batch: 46, Loss: 1.2984955310821533, Accuracy: 0.60546875\n",
      "Batch: 47, Loss: 1.2558625936508179, Accuracy: 0.615234375\n",
      "Batch: 48, Loss: 1.251643419265747, Accuracy: 0.6083984375\n",
      "Batch: 49, Loss: 1.414393663406372, Accuracy: 0.564453125\n",
      "Batch: 50, Loss: 1.3366680145263672, Accuracy: 0.5615234375\n",
      "Batch: 51, Loss: 1.4260895252227783, Accuracy: 0.5341796875\n",
      "Batch: 52, Loss: 1.4003031253814697, Accuracy: 0.5810546875\n",
      "Batch: 53, Loss: 1.132307529449463, Accuracy: 0.6279296875\n",
      "Batch: 54, Loss: 1.2581799030303955, Accuracy: 0.6171875\n",
      "Batch: 55, Loss: 1.310723066329956, Accuracy: 0.5712890625\n",
      "Batch: 56, Loss: 1.3493603467941284, Accuracy: 0.5830078125\n",
      "Batch: 57, Loss: 1.2769685983657837, Accuracy: 0.6083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 1.3858221769332886, Accuracy: 0.5830078125\n",
      "Batch: 59, Loss: 1.1932458877563477, Accuracy: 0.6396484375\n",
      "Batch: 60, Loss: 1.194049596786499, Accuracy: 0.6328125\n",
      "Batch: 61, Loss: 1.326804280281067, Accuracy: 0.578125\n",
      "Batch: 62, Loss: 1.283628225326538, Accuracy: 0.5966796875\n",
      "Batch: 63, Loss: 1.3011351823806763, Accuracy: 0.5830078125\n",
      "Batch: 64, Loss: 1.260071039199829, Accuracy: 0.591796875\n",
      "Batch: 65, Loss: 1.310682773590088, Accuracy: 0.6025390625\n",
      "Batch: 66, Loss: 1.1987102031707764, Accuracy: 0.6357421875\n",
      "Batch: 67, Loss: 1.3775638341903687, Accuracy: 0.5712890625\n",
      "Batch: 68, Loss: 1.414866328239441, Accuracy: 0.5810546875\n",
      "Batch: 69, Loss: 1.3360660076141357, Accuracy: 0.5908203125\n",
      "Batch: 70, Loss: 1.3415818214416504, Accuracy: 0.5986328125\n",
      "Batch: 71, Loss: 1.3257968425750732, Accuracy: 0.587890625\n",
      "Batch: 72, Loss: 1.190817952156067, Accuracy: 0.6240234375\n",
      "Batch: 73, Loss: 1.2522265911102295, Accuracy: 0.611328125\n",
      "Batch: 74, Loss: 1.2138742208480835, Accuracy: 0.61328125\n",
      "Batch: 75, Loss: 1.1761045455932617, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.322099208831787, Accuracy: 0.5712890625\n",
      "Batch: 77, Loss: 1.3016715049743652, Accuracy: 0.57421875\n",
      "Batch: 78, Loss: 1.2717247009277344, Accuracy: 0.61328125\n",
      "Batch: 79, Loss: 1.1537830829620361, Accuracy: 0.6591796875\n",
      "Batch: 80, Loss: 1.1855559349060059, Accuracy: 0.6103515625\n",
      "Batch: 81, Loss: 1.355454921722412, Accuracy: 0.537109375\n",
      "Batch: 82, Loss: 1.340653419494629, Accuracy: 0.5537109375\n",
      "Batch: 83, Loss: 1.1719375848770142, Accuracy: 0.640625\n",
      "Batch: 84, Loss: 1.2232246398925781, Accuracy: 0.6396484375\n",
      "Batch: 85, Loss: 1.1525182723999023, Accuracy: 0.6318359375\n",
      "Batch: 86, Loss: 1.4151573181152344, Accuracy: 0.5595703125\n",
      "Batch: 87, Loss: 1.188523292541504, Accuracy: 0.6298828125\n",
      "Batch: 88, Loss: 1.3638825416564941, Accuracy: 0.599609375\n",
      "Batch: 89, Loss: 1.3490800857543945, Accuracy: 0.5849609375\n",
      "Batch: 90, Loss: 1.217103123664856, Accuracy: 0.6015625\n",
      "Batch: 91, Loss: 1.2772183418273926, Accuracy: 0.59765625\n",
      "Batch: 92, Loss: 1.3004231452941895, Accuracy: 0.5869140625\n",
      "Batch: 93, Loss: 1.194739818572998, Accuracy: 0.634765625\n",
      "Batch: 94, Loss: 1.2378668785095215, Accuracy: 0.6123046875\n",
      "Batch: 95, Loss: 1.2898643016815186, Accuracy: 0.5810546875\n",
      "Batch: 96, Loss: 1.243255615234375, Accuracy: 0.6201171875\n",
      "Batch: 97, Loss: 1.1420269012451172, Accuracy: 0.64453125\n",
      "Batch: 98, Loss: 1.1666845083236694, Accuracy: 0.634765625\n",
      "Batch: 99, Loss: 1.137363314628601, Accuracy: 0.630859375\n",
      "Batch: 100, Loss: 1.2448793649673462, Accuracy: 0.607421875\n",
      "Batch: 101, Loss: 1.3124834299087524, Accuracy: 0.5888671875\n",
      "Batch: 102, Loss: 1.1747162342071533, Accuracy: 0.62890625\n",
      "Batch: 103, Loss: 1.2929832935333252, Accuracy: 0.6162109375\n",
      "Batch: 104, Loss: 1.166061282157898, Accuracy: 0.619140625\n",
      "Batch: 105, Loss: 1.301567792892456, Accuracy: 0.5947265625\n",
      "Batch: 106, Loss: 1.2999143600463867, Accuracy: 0.58984375\n",
      "Batch: 107, Loss: 1.4198050498962402, Accuracy: 0.5458984375\n",
      "Batch: 108, Loss: 1.3388649225234985, Accuracy: 0.5771484375\n",
      "Batch: 109, Loss: 1.4242045879364014, Accuracy: 0.544921875\n",
      "Batch: 110, Loss: 1.100699782371521, Accuracy: 0.6494140625\n",
      "Batch: 111, Loss: 1.3328078985214233, Accuracy: 0.5576171875\n",
      "Batch: 112, Loss: 1.2404894828796387, Accuracy: 0.6083984375\n",
      "Batch: 113, Loss: 1.2623802423477173, Accuracy: 0.623046875\n",
      "Batch: 114, Loss: 1.4075926542282104, Accuracy: 0.5712890625\n",
      "Batch: 115, Loss: 1.410706639289856, Accuracy: 0.578125\n",
      "Batch: 116, Loss: 1.3748247623443604, Accuracy: 0.5615234375\n",
      "Batch: 117, Loss: 1.3248831033706665, Accuracy: 0.5849609375\n",
      "Batch: 118, Loss: 1.1624150276184082, Accuracy: 0.6328125\n",
      "Batch: 119, Loss: 1.1981114149093628, Accuracy: 0.6240234375\n",
      "Batch: 120, Loss: 1.3262250423431396, Accuracy: 0.57421875\n",
      "Batch: 121, Loss: 1.3780713081359863, Accuracy: 0.57421875\n",
      "Batch: 122, Loss: 1.2387150526046753, Accuracy: 0.6259765625\n",
      "Batch: 123, Loss: 1.22573721408844, Accuracy: 0.595703125\n",
      "Batch: 124, Loss: 1.2740426063537598, Accuracy: 0.5986328125\n",
      "Batch: 125, Loss: 1.331881046295166, Accuracy: 0.57421875\n",
      "Batch: 126, Loss: 1.321183204650879, Accuracy: 0.5595703125\n",
      "Batch: 127, Loss: 1.1915186643600464, Accuracy: 0.6376953125\n",
      "Batch: 128, Loss: 1.4056189060211182, Accuracy: 0.568359375\n",
      "Batch: 129, Loss: 1.2436063289642334, Accuracy: 0.603515625\n",
      "Batch: 130, Loss: 1.4531277418136597, Accuracy: 0.55859375\n",
      "Batch: 131, Loss: 1.3444340229034424, Accuracy: 0.5712890625\n",
      "Batch: 132, Loss: 1.392514705657959, Accuracy: 0.568359375\n",
      "Batch: 133, Loss: 1.2026091814041138, Accuracy: 0.607421875\n",
      "Batch: 134, Loss: 1.2846195697784424, Accuracy: 0.591796875\n",
      "Batch: 135, Loss: 1.2056283950805664, Accuracy: 0.623046875\n",
      "Batch: 136, Loss: 1.2662241458892822, Accuracy: 0.603515625\n",
      "Batch: 137, Loss: 1.174544095993042, Accuracy: 0.609375\n",
      "Batch: 138, Loss: 1.0646240711212158, Accuracy: 0.6669921875\n",
      "Batch: 139, Loss: 1.1253156661987305, Accuracy: 0.6259765625\n",
      "Batch: 140, Loss: 1.2460954189300537, Accuracy: 0.5849609375\n",
      "Batch: 141, Loss: 1.2597224712371826, Accuracy: 0.6083984375\n",
      "Batch: 142, Loss: 1.2924187183380127, Accuracy: 0.6005859375\n",
      "Batch: 143, Loss: 1.2951818704605103, Accuracy: 0.5849609375\n",
      "Batch: 144, Loss: 1.3070156574249268, Accuracy: 0.587890625\n",
      "Batch: 145, Loss: 1.198216199874878, Accuracy: 0.6015625\n",
      "Batch: 146, Loss: 1.345252275466919, Accuracy: 0.5703125\n",
      "Batch: 147, Loss: 1.2799367904663086, Accuracy: 0.5859375\n",
      "Batch: 148, Loss: 1.4127590656280518, Accuracy: 0.5341796875\n",
      "Batch: 149, Loss: 1.288271427154541, Accuracy: 0.572265625\n",
      "Batch: 150, Loss: 1.2102652788162231, Accuracy: 0.6171875\n",
      "Batch: 151, Loss: 1.1461249589920044, Accuracy: 0.6376953125\n",
      "Epoch 9/90\n",
      "Batch: 1, Loss: 1.4941935539245605, Accuracy: 0.5048828125\n",
      "Batch: 2, Loss: 1.2549169063568115, Accuracy: 0.5830078125\n",
      "Batch: 3, Loss: 1.198458194732666, Accuracy: 0.6064453125\n",
      "Batch: 4, Loss: 1.1064790487289429, Accuracy: 0.666015625\n",
      "Batch: 5, Loss: 1.1367969512939453, Accuracy: 0.6591796875\n",
      "Batch: 6, Loss: 1.2513971328735352, Accuracy: 0.5927734375\n",
      "Batch: 7, Loss: 1.1750078201293945, Accuracy: 0.6162109375\n",
      "Batch: 8, Loss: 1.1859900951385498, Accuracy: 0.607421875\n",
      "Batch: 9, Loss: 1.1240625381469727, Accuracy: 0.6416015625\n",
      "Batch: 10, Loss: 1.1362652778625488, Accuracy: 0.6337890625\n",
      "Batch: 11, Loss: 1.3459008932113647, Accuracy: 0.560546875\n",
      "Batch: 12, Loss: 1.3523881435394287, Accuracy: 0.5478515625\n",
      "Batch: 13, Loss: 1.0762306451797485, Accuracy: 0.65234375\n",
      "Batch: 14, Loss: 1.3231956958770752, Accuracy: 0.5654296875\n",
      "Batch: 15, Loss: 1.1759945154190063, Accuracy: 0.6435546875\n",
      "Batch: 16, Loss: 1.190018653869629, Accuracy: 0.6044921875\n",
      "Batch: 17, Loss: 1.2735295295715332, Accuracy: 0.59765625\n",
      "Batch: 18, Loss: 1.2656692266464233, Accuracy: 0.578125\n",
      "Batch: 19, Loss: 1.3397841453552246, Accuracy: 0.5830078125\n",
      "Batch: 20, Loss: 1.229252815246582, Accuracy: 0.6259765625\n",
      "Batch: 21, Loss: 1.1911664009094238, Accuracy: 0.6064453125\n",
      "Batch: 22, Loss: 1.3100881576538086, Accuracy: 0.5830078125\n",
      "Batch: 23, Loss: 1.2005932331085205, Accuracy: 0.599609375\n",
      "Batch: 24, Loss: 1.2614225149154663, Accuracy: 0.5869140625\n",
      "Batch: 25, Loss: 1.1991695165634155, Accuracy: 0.6142578125\n",
      "Batch: 26, Loss: 1.1222014427185059, Accuracy: 0.6298828125\n",
      "Batch: 27, Loss: 1.2134262323379517, Accuracy: 0.59765625\n",
      "Batch: 28, Loss: 1.2770951986312866, Accuracy: 0.583984375\n",
      "Batch: 29, Loss: 1.291155457496643, Accuracy: 0.57421875\n",
      "Batch: 30, Loss: 1.234557867050171, Accuracy: 0.6337890625\n",
      "Batch: 31, Loss: 1.2097949981689453, Accuracy: 0.6171875\n",
      "Batch: 32, Loss: 1.1272854804992676, Accuracy: 0.6171875\n",
      "Batch: 33, Loss: 1.3487975597381592, Accuracy: 0.5634765625\n",
      "Batch: 34, Loss: 1.417958378791809, Accuracy: 0.5517578125\n",
      "Batch: 35, Loss: 1.2937655448913574, Accuracy: 0.5625\n",
      "Batch: 36, Loss: 1.2761507034301758, Accuracy: 0.6015625\n",
      "Batch: 37, Loss: 1.2268767356872559, Accuracy: 0.611328125\n",
      "Batch: 38, Loss: 1.265437364578247, Accuracy: 0.5859375\n",
      "Batch: 39, Loss: 1.2896407842636108, Accuracy: 0.60546875\n",
      "Batch: 40, Loss: 1.3011178970336914, Accuracy: 0.611328125\n",
      "Batch: 41, Loss: 1.3171931505203247, Accuracy: 0.6044921875\n",
      "Batch: 42, Loss: 1.0469846725463867, Accuracy: 0.662109375\n",
      "Batch: 43, Loss: 1.2534645795822144, Accuracy: 0.5771484375\n",
      "Batch: 44, Loss: 1.2414783239364624, Accuracy: 0.58203125\n",
      "Batch: 45, Loss: 1.1038782596588135, Accuracy: 0.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46, Loss: 1.2590993642807007, Accuracy: 0.615234375\n",
      "Batch: 47, Loss: 1.1883364915847778, Accuracy: 0.6298828125\n",
      "Batch: 48, Loss: 1.184086799621582, Accuracy: 0.6201171875\n",
      "Batch: 49, Loss: 1.3812443017959595, Accuracy: 0.5791015625\n",
      "Batch: 50, Loss: 1.3031699657440186, Accuracy: 0.578125\n",
      "Batch: 51, Loss: 1.404526710510254, Accuracy: 0.5478515625\n",
      "Batch: 52, Loss: 1.3537354469299316, Accuracy: 0.5830078125\n",
      "Batch: 53, Loss: 1.0972038507461548, Accuracy: 0.6337890625\n",
      "Batch: 54, Loss: 1.201692819595337, Accuracy: 0.6298828125\n",
      "Batch: 55, Loss: 1.2540404796600342, Accuracy: 0.5947265625\n",
      "Batch: 56, Loss: 1.3069586753845215, Accuracy: 0.6025390625\n",
      "Batch: 57, Loss: 1.2224775552749634, Accuracy: 0.6240234375\n",
      "Batch: 58, Loss: 1.365211009979248, Accuracy: 0.57421875\n",
      "Batch: 59, Loss: 1.1511640548706055, Accuracy: 0.640625\n",
      "Batch: 60, Loss: 1.1519297361373901, Accuracy: 0.6318359375\n",
      "Batch: 61, Loss: 1.2656558752059937, Accuracy: 0.607421875\n",
      "Batch: 62, Loss: 1.2353713512420654, Accuracy: 0.6064453125\n",
      "Batch: 63, Loss: 1.2482506036758423, Accuracy: 0.6044921875\n",
      "Batch: 64, Loss: 1.2071356773376465, Accuracy: 0.625\n",
      "Batch: 65, Loss: 1.2672945261001587, Accuracy: 0.607421875\n",
      "Batch: 66, Loss: 1.1528980731964111, Accuracy: 0.6416015625\n",
      "Batch: 67, Loss: 1.3519036769866943, Accuracy: 0.5751953125\n",
      "Batch: 68, Loss: 1.3574103116989136, Accuracy: 0.5986328125\n",
      "Batch: 69, Loss: 1.2658534049987793, Accuracy: 0.6083984375\n",
      "Batch: 70, Loss: 1.291663408279419, Accuracy: 0.609375\n",
      "Batch: 71, Loss: 1.2750601768493652, Accuracy: 0.5947265625\n",
      "Batch: 72, Loss: 1.1560386419296265, Accuracy: 0.6357421875\n",
      "Batch: 73, Loss: 1.2010159492492676, Accuracy: 0.619140625\n",
      "Batch: 74, Loss: 1.1767916679382324, Accuracy: 0.625\n",
      "Batch: 75, Loss: 1.125441312789917, Accuracy: 0.640625\n",
      "Batch: 76, Loss: 1.2558479309082031, Accuracy: 0.5888671875\n",
      "Batch: 77, Loss: 1.2224195003509521, Accuracy: 0.60546875\n",
      "Batch: 78, Loss: 1.2345093488693237, Accuracy: 0.62890625\n",
      "Batch: 79, Loss: 1.0843170881271362, Accuracy: 0.662109375\n",
      "Batch: 80, Loss: 1.1325500011444092, Accuracy: 0.6181640625\n",
      "Batch: 81, Loss: 1.3260185718536377, Accuracy: 0.548828125\n",
      "Batch: 82, Loss: 1.298656702041626, Accuracy: 0.5908203125\n",
      "Batch: 83, Loss: 1.1359862089157104, Accuracy: 0.65234375\n",
      "Batch: 84, Loss: 1.1702854633331299, Accuracy: 0.64453125\n",
      "Batch: 85, Loss: 1.1187784671783447, Accuracy: 0.6396484375\n",
      "Batch: 86, Loss: 1.3600342273712158, Accuracy: 0.5751953125\n",
      "Batch: 87, Loss: 1.1522572040557861, Accuracy: 0.6376953125\n",
      "Batch: 88, Loss: 1.2928591966629028, Accuracy: 0.611328125\n",
      "Batch: 89, Loss: 1.302428960800171, Accuracy: 0.6044921875\n",
      "Batch: 90, Loss: 1.1650255918502808, Accuracy: 0.6259765625\n",
      "Batch: 91, Loss: 1.2442960739135742, Accuracy: 0.6201171875\n",
      "Batch: 92, Loss: 1.2527310848236084, Accuracy: 0.607421875\n",
      "Batch: 93, Loss: 1.1556150913238525, Accuracy: 0.6240234375\n",
      "Batch: 94, Loss: 1.186049222946167, Accuracy: 0.607421875\n",
      "Batch: 95, Loss: 1.2487610578536987, Accuracy: 0.595703125\n",
      "Batch: 96, Loss: 1.198180913925171, Accuracy: 0.6201171875\n",
      "Batch: 97, Loss: 1.1065940856933594, Accuracy: 0.640625\n",
      "Batch: 98, Loss: 1.129145622253418, Accuracy: 0.6416015625\n",
      "Batch: 99, Loss: 1.1104493141174316, Accuracy: 0.642578125\n",
      "Batch: 100, Loss: 1.1882680654525757, Accuracy: 0.6181640625\n",
      "Batch: 101, Loss: 1.2854089736938477, Accuracy: 0.5859375\n",
      "Batch: 102, Loss: 1.1593496799468994, Accuracy: 0.625\n",
      "Batch: 103, Loss: 1.2591898441314697, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.1178560256958008, Accuracy: 0.63671875\n",
      "Batch: 105, Loss: 1.2509632110595703, Accuracy: 0.6015625\n",
      "Batch: 106, Loss: 1.2874608039855957, Accuracy: 0.6103515625\n",
      "Batch: 107, Loss: 1.3732954263687134, Accuracy: 0.5810546875\n",
      "Batch: 108, Loss: 1.3156665563583374, Accuracy: 0.57421875\n",
      "Batch: 109, Loss: 1.388810634613037, Accuracy: 0.5439453125\n",
      "Batch: 110, Loss: 1.098073124885559, Accuracy: 0.64453125\n",
      "Batch: 111, Loss: 1.3005480766296387, Accuracy: 0.56640625\n",
      "Batch: 112, Loss: 1.216227650642395, Accuracy: 0.615234375\n",
      "Batch: 113, Loss: 1.2723770141601562, Accuracy: 0.615234375\n",
      "Batch: 114, Loss: 1.4082319736480713, Accuracy: 0.5693359375\n",
      "Batch: 115, Loss: 1.4187376499176025, Accuracy: 0.5908203125\n",
      "Batch: 116, Loss: 1.319393277168274, Accuracy: 0.58984375\n",
      "Batch: 117, Loss: 1.323534607887268, Accuracy: 0.5791015625\n",
      "Batch: 118, Loss: 1.1079723834991455, Accuracy: 0.6494140625\n",
      "Batch: 119, Loss: 1.1756742000579834, Accuracy: 0.642578125\n",
      "Batch: 120, Loss: 1.2782038450241089, Accuracy: 0.5908203125\n",
      "Batch: 121, Loss: 1.354941487312317, Accuracy: 0.576171875\n",
      "Batch: 122, Loss: 1.1993191242218018, Accuracy: 0.6337890625\n",
      "Batch: 123, Loss: 1.205151081085205, Accuracy: 0.6103515625\n",
      "Batch: 124, Loss: 1.2476694583892822, Accuracy: 0.6103515625\n",
      "Batch: 125, Loss: 1.2887370586395264, Accuracy: 0.5859375\n",
      "Batch: 126, Loss: 1.2807265520095825, Accuracy: 0.5830078125\n",
      "Batch: 127, Loss: 1.177756905555725, Accuracy: 0.6318359375\n",
      "Batch: 128, Loss: 1.3899059295654297, Accuracy: 0.57421875\n",
      "Batch: 129, Loss: 1.2153635025024414, Accuracy: 0.5966796875\n",
      "Batch: 130, Loss: 1.4218273162841797, Accuracy: 0.56640625\n",
      "Batch: 131, Loss: 1.32924222946167, Accuracy: 0.591796875\n",
      "Batch: 132, Loss: 1.3553109169006348, Accuracy: 0.572265625\n",
      "Batch: 133, Loss: 1.1688871383666992, Accuracy: 0.6298828125\n",
      "Batch: 134, Loss: 1.2700560092926025, Accuracy: 0.587890625\n",
      "Batch: 135, Loss: 1.1951136589050293, Accuracy: 0.6328125\n",
      "Batch: 136, Loss: 1.2269493341445923, Accuracy: 0.6083984375\n",
      "Batch: 137, Loss: 1.1446595191955566, Accuracy: 0.6240234375\n",
      "Batch: 138, Loss: 1.0399699211120605, Accuracy: 0.650390625\n",
      "Batch: 139, Loss: 1.103134036064148, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.228326439857483, Accuracy: 0.5966796875\n",
      "Batch: 141, Loss: 1.231619119644165, Accuracy: 0.6083984375\n",
      "Batch: 142, Loss: 1.2822144031524658, Accuracy: 0.6005859375\n",
      "Batch: 143, Loss: 1.27414870262146, Accuracy: 0.6015625\n",
      "Batch: 144, Loss: 1.256575584411621, Accuracy: 0.611328125\n",
      "Batch: 145, Loss: 1.1671403646469116, Accuracy: 0.609375\n",
      "Batch: 146, Loss: 1.2917413711547852, Accuracy: 0.5712890625\n",
      "Batch: 147, Loss: 1.2603422403335571, Accuracy: 0.587890625\n",
      "Batch: 148, Loss: 1.3768759965896606, Accuracy: 0.5400390625\n",
      "Batch: 149, Loss: 1.2524077892303467, Accuracy: 0.59375\n",
      "Batch: 150, Loss: 1.1772677898406982, Accuracy: 0.6279296875\n",
      "Batch: 151, Loss: 1.1118366718292236, Accuracy: 0.634765625\n",
      "Epoch 10/90\n",
      "Batch: 1, Loss: 1.4835222959518433, Accuracy: 0.533203125\n",
      "Batch: 2, Loss: 1.2397897243499756, Accuracy: 0.5966796875\n",
      "Batch: 3, Loss: 1.1633164882659912, Accuracy: 0.60546875\n",
      "Batch: 4, Loss: 1.071623682975769, Accuracy: 0.6591796875\n",
      "Batch: 5, Loss: 1.1223695278167725, Accuracy: 0.65234375\n",
      "Batch: 6, Loss: 1.2029941082000732, Accuracy: 0.6083984375\n",
      "Batch: 7, Loss: 1.141615867614746, Accuracy: 0.6259765625\n",
      "Batch: 8, Loss: 1.1263612508773804, Accuracy: 0.6416015625\n",
      "Batch: 9, Loss: 1.086739182472229, Accuracy: 0.654296875\n",
      "Batch: 10, Loss: 1.1036863327026367, Accuracy: 0.6494140625\n",
      "Batch: 11, Loss: 1.3209335803985596, Accuracy: 0.580078125\n",
      "Batch: 12, Loss: 1.3147386312484741, Accuracy: 0.5712890625\n",
      "Batch: 13, Loss: 1.0315866470336914, Accuracy: 0.662109375\n",
      "Batch: 14, Loss: 1.281264305114746, Accuracy: 0.5927734375\n",
      "Batch: 15, Loss: 1.1449700593948364, Accuracy: 0.65625\n",
      "Batch: 16, Loss: 1.1358134746551514, Accuracy: 0.63671875\n",
      "Batch: 17, Loss: 1.248094916343689, Accuracy: 0.587890625\n",
      "Batch: 18, Loss: 1.2226378917694092, Accuracy: 0.6103515625\n",
      "Batch: 19, Loss: 1.3074700832366943, Accuracy: 0.591796875\n",
      "Batch: 20, Loss: 1.1852182149887085, Accuracy: 0.630859375\n",
      "Batch: 21, Loss: 1.1490583419799805, Accuracy: 0.6298828125\n",
      "Batch: 22, Loss: 1.2819342613220215, Accuracy: 0.60546875\n",
      "Batch: 23, Loss: 1.1649291515350342, Accuracy: 0.609375\n",
      "Batch: 24, Loss: 1.2015421390533447, Accuracy: 0.599609375\n",
      "Batch: 25, Loss: 1.1653531789779663, Accuracy: 0.6279296875\n",
      "Batch: 26, Loss: 1.075551986694336, Accuracy: 0.6494140625\n",
      "Batch: 27, Loss: 1.1567710638046265, Accuracy: 0.609375\n",
      "Batch: 28, Loss: 1.2368721961975098, Accuracy: 0.595703125\n",
      "Batch: 29, Loss: 1.26247239112854, Accuracy: 0.5791015625\n",
      "Batch: 30, Loss: 1.1724052429199219, Accuracy: 0.6435546875\n",
      "Batch: 31, Loss: 1.1689000129699707, Accuracy: 0.6298828125\n",
      "Batch: 32, Loss: 1.092165470123291, Accuracy: 0.6279296875\n",
      "Batch: 33, Loss: 1.3174158334732056, Accuracy: 0.58203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 1.377090334892273, Accuracy: 0.5693359375\n",
      "Batch: 35, Loss: 1.2553921937942505, Accuracy: 0.583984375\n",
      "Batch: 36, Loss: 1.2302712202072144, Accuracy: 0.61328125\n",
      "Batch: 37, Loss: 1.1879322528839111, Accuracy: 0.6171875\n",
      "Batch: 38, Loss: 1.214348316192627, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.2503575086593628, Accuracy: 0.6044921875\n",
      "Batch: 40, Loss: 1.2772650718688965, Accuracy: 0.6171875\n",
      "Batch: 41, Loss: 1.2337052822113037, Accuracy: 0.609375\n",
      "Batch: 42, Loss: 1.0172231197357178, Accuracy: 0.673828125\n",
      "Batch: 43, Loss: 1.2181023359298706, Accuracy: 0.59375\n",
      "Batch: 44, Loss: 1.1922658681869507, Accuracy: 0.5947265625\n",
      "Batch: 45, Loss: 1.056501030921936, Accuracy: 0.65234375\n",
      "Batch: 46, Loss: 1.219149112701416, Accuracy: 0.6318359375\n",
      "Batch: 47, Loss: 1.169339656829834, Accuracy: 0.6328125\n",
      "Batch: 48, Loss: 1.1453412771224976, Accuracy: 0.62890625\n",
      "Batch: 49, Loss: 1.3249021768569946, Accuracy: 0.5703125\n",
      "Batch: 50, Loss: 1.2685937881469727, Accuracy: 0.6064453125\n",
      "Batch: 51, Loss: 1.343725323677063, Accuracy: 0.5654296875\n",
      "Batch: 52, Loss: 1.2897300720214844, Accuracy: 0.603515625\n",
      "Batch: 53, Loss: 1.05318021774292, Accuracy: 0.6435546875\n",
      "Batch: 54, Loss: 1.163672924041748, Accuracy: 0.6474609375\n",
      "Batch: 55, Loss: 1.232662558555603, Accuracy: 0.58984375\n",
      "Batch: 56, Loss: 1.2688565254211426, Accuracy: 0.5966796875\n",
      "Batch: 57, Loss: 1.1828296184539795, Accuracy: 0.6318359375\n",
      "Batch: 58, Loss: 1.2874526977539062, Accuracy: 0.607421875\n",
      "Batch: 59, Loss: 1.1270029544830322, Accuracy: 0.6572265625\n",
      "Batch: 60, Loss: 1.118906021118164, Accuracy: 0.6376953125\n",
      "Batch: 61, Loss: 1.2311220169067383, Accuracy: 0.6044921875\n",
      "Batch: 62, Loss: 1.2041735649108887, Accuracy: 0.61328125\n",
      "Batch: 63, Loss: 1.2006174325942993, Accuracy: 0.609375\n",
      "Batch: 64, Loss: 1.173941969871521, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.2604715824127197, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.1247690916061401, Accuracy: 0.6474609375\n",
      "Batch: 67, Loss: 1.279402732849121, Accuracy: 0.6064453125\n",
      "Batch: 68, Loss: 1.3151997327804565, Accuracy: 0.603515625\n",
      "Batch: 69, Loss: 1.2404227256774902, Accuracy: 0.6064453125\n",
      "Batch: 70, Loss: 1.2501696348190308, Accuracy: 0.6181640625\n",
      "Batch: 71, Loss: 1.2317358255386353, Accuracy: 0.6064453125\n",
      "Batch: 72, Loss: 1.1104657649993896, Accuracy: 0.650390625\n",
      "Batch: 73, Loss: 1.184605360031128, Accuracy: 0.640625\n",
      "Batch: 74, Loss: 1.1478946208953857, Accuracy: 0.638671875\n",
      "Batch: 75, Loss: 1.0863583087921143, Accuracy: 0.6552734375\n",
      "Batch: 76, Loss: 1.2239208221435547, Accuracy: 0.5849609375\n",
      "Batch: 77, Loss: 1.182560682296753, Accuracy: 0.6044921875\n",
      "Batch: 78, Loss: 1.19725501537323, Accuracy: 0.623046875\n",
      "Batch: 79, Loss: 1.085497260093689, Accuracy: 0.677734375\n",
      "Batch: 80, Loss: 1.116628885269165, Accuracy: 0.6279296875\n",
      "Batch: 81, Loss: 1.2614277601242065, Accuracy: 0.583984375\n",
      "Batch: 82, Loss: 1.2419688701629639, Accuracy: 0.5966796875\n",
      "Batch: 83, Loss: 1.0939185619354248, Accuracy: 0.669921875\n",
      "Batch: 84, Loss: 1.142794132232666, Accuracy: 0.6435546875\n",
      "Batch: 85, Loss: 1.0912843942642212, Accuracy: 0.65234375\n",
      "Batch: 86, Loss: 1.3396961688995361, Accuracy: 0.580078125\n",
      "Batch: 87, Loss: 1.096735954284668, Accuracy: 0.666015625\n",
      "Batch: 88, Loss: 1.2511004209518433, Accuracy: 0.6259765625\n",
      "Batch: 89, Loss: 1.257973074913025, Accuracy: 0.6220703125\n",
      "Batch: 90, Loss: 1.1251931190490723, Accuracy: 0.6318359375\n",
      "Batch: 91, Loss: 1.2117173671722412, Accuracy: 0.6162109375\n",
      "Batch: 92, Loss: 1.2146518230438232, Accuracy: 0.6005859375\n",
      "Batch: 93, Loss: 1.1407147645950317, Accuracy: 0.646484375\n",
      "Batch: 94, Loss: 1.1408147811889648, Accuracy: 0.623046875\n",
      "Batch: 95, Loss: 1.2230210304260254, Accuracy: 0.6015625\n",
      "Batch: 96, Loss: 1.2021939754486084, Accuracy: 0.61328125\n",
      "Batch: 97, Loss: 1.0698621273040771, Accuracy: 0.65234375\n",
      "Batch: 98, Loss: 1.0841963291168213, Accuracy: 0.6611328125\n",
      "Batch: 99, Loss: 1.0698018074035645, Accuracy: 0.6474609375\n",
      "Batch: 100, Loss: 1.131316065788269, Accuracy: 0.6474609375\n",
      "Batch: 101, Loss: 1.227126955986023, Accuracy: 0.5927734375\n",
      "Batch: 102, Loss: 1.1028395891189575, Accuracy: 0.625\n",
      "Batch: 103, Loss: 1.221746563911438, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.083693027496338, Accuracy: 0.62890625\n",
      "Batch: 105, Loss: 1.2106225490570068, Accuracy: 0.59765625\n",
      "Batch: 106, Loss: 1.210716962814331, Accuracy: 0.603515625\n",
      "Batch: 107, Loss: 1.3000136613845825, Accuracy: 0.583984375\n",
      "Batch: 108, Loss: 1.2315691709518433, Accuracy: 0.58984375\n",
      "Batch: 109, Loss: 1.343927025794983, Accuracy: 0.5390625\n",
      "Batch: 110, Loss: 1.0220375061035156, Accuracy: 0.6533203125\n",
      "Batch: 111, Loss: 1.2685906887054443, Accuracy: 0.5693359375\n",
      "Batch: 112, Loss: 1.1872520446777344, Accuracy: 0.6259765625\n",
      "Batch: 113, Loss: 1.185302972793579, Accuracy: 0.6396484375\n",
      "Batch: 114, Loss: 1.3365848064422607, Accuracy: 0.5947265625\n",
      "Batch: 115, Loss: 1.3193469047546387, Accuracy: 0.6025390625\n",
      "Batch: 116, Loss: 1.274094581604004, Accuracy: 0.5830078125\n",
      "Batch: 117, Loss: 1.259516954421997, Accuracy: 0.5888671875\n",
      "Batch: 118, Loss: 1.056025743484497, Accuracy: 0.6630859375\n",
      "Batch: 119, Loss: 1.10672128200531, Accuracy: 0.65625\n",
      "Batch: 120, Loss: 1.2513904571533203, Accuracy: 0.5947265625\n",
      "Batch: 121, Loss: 1.2933671474456787, Accuracy: 0.6005859375\n",
      "Batch: 122, Loss: 1.1377894878387451, Accuracy: 0.65234375\n",
      "Batch: 123, Loss: 1.1331419944763184, Accuracy: 0.6396484375\n",
      "Batch: 124, Loss: 1.2022466659545898, Accuracy: 0.61328125\n",
      "Batch: 125, Loss: 1.2241196632385254, Accuracy: 0.607421875\n",
      "Batch: 126, Loss: 1.2291088104248047, Accuracy: 0.599609375\n",
      "Batch: 127, Loss: 1.0824167728424072, Accuracy: 0.681640625\n",
      "Batch: 128, Loss: 1.3299553394317627, Accuracy: 0.587890625\n",
      "Batch: 129, Loss: 1.1505415439605713, Accuracy: 0.63671875\n",
      "Batch: 130, Loss: 1.3736315965652466, Accuracy: 0.5771484375\n",
      "Batch: 131, Loss: 1.2712368965148926, Accuracy: 0.5947265625\n",
      "Batch: 132, Loss: 1.2811535596847534, Accuracy: 0.599609375\n",
      "Batch: 133, Loss: 1.1039185523986816, Accuracy: 0.6259765625\n",
      "Batch: 134, Loss: 1.202564001083374, Accuracy: 0.6123046875\n",
      "Batch: 135, Loss: 1.1322689056396484, Accuracy: 0.646484375\n",
      "Batch: 136, Loss: 1.201416015625, Accuracy: 0.619140625\n",
      "Batch: 137, Loss: 1.0895617008209229, Accuracy: 0.63671875\n",
      "Batch: 138, Loss: 0.9793349504470825, Accuracy: 0.669921875\n",
      "Batch: 139, Loss: 1.0718073844909668, Accuracy: 0.64453125\n",
      "Batch: 140, Loss: 1.134446144104004, Accuracy: 0.6162109375\n",
      "Batch: 141, Loss: 1.181592583656311, Accuracy: 0.6123046875\n",
      "Batch: 142, Loss: 1.212419033050537, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.2293238639831543, Accuracy: 0.599609375\n",
      "Batch: 144, Loss: 1.2174280881881714, Accuracy: 0.6171875\n",
      "Batch: 145, Loss: 1.1013259887695312, Accuracy: 0.6298828125\n",
      "Batch: 146, Loss: 1.236128568649292, Accuracy: 0.591796875\n",
      "Batch: 147, Loss: 1.2042996883392334, Accuracy: 0.603515625\n",
      "Batch: 148, Loss: 1.302403450012207, Accuracy: 0.5654296875\n",
      "Batch: 149, Loss: 1.2037559747695923, Accuracy: 0.58984375\n",
      "Batch: 150, Loss: 1.1201138496398926, Accuracy: 0.6337890625\n",
      "Batch: 151, Loss: 1.0465261936187744, Accuracy: 0.662109375\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/90\n",
      "Batch: 1, Loss: 1.4347906112670898, Accuracy: 0.5283203125\n",
      "Batch: 2, Loss: 1.2034387588500977, Accuracy: 0.59765625\n",
      "Batch: 3, Loss: 1.1259243488311768, Accuracy: 0.6181640625\n",
      "Batch: 4, Loss: 1.0482540130615234, Accuracy: 0.67578125\n",
      "Batch: 5, Loss: 1.0414937734603882, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.171492338180542, Accuracy: 0.611328125\n",
      "Batch: 7, Loss: 1.1297564506530762, Accuracy: 0.62890625\n",
      "Batch: 8, Loss: 1.1030640602111816, Accuracy: 0.6328125\n",
      "Batch: 9, Loss: 1.040229082107544, Accuracy: 0.6767578125\n",
      "Batch: 10, Loss: 1.0798834562301636, Accuracy: 0.666015625\n",
      "Batch: 11, Loss: 1.2812812328338623, Accuracy: 0.5791015625\n",
      "Batch: 12, Loss: 1.293738842010498, Accuracy: 0.57421875\n",
      "Batch: 13, Loss: 0.9955772757530212, Accuracy: 0.677734375\n",
      "Batch: 14, Loss: 1.2587506771087646, Accuracy: 0.607421875\n",
      "Batch: 15, Loss: 1.1116273403167725, Accuracy: 0.6650390625\n",
      "Batch: 16, Loss: 1.1137232780456543, Accuracy: 0.6474609375\n",
      "Batch: 17, Loss: 1.2032109498977661, Accuracy: 0.6083984375\n",
      "Batch: 18, Loss: 1.2032170295715332, Accuracy: 0.603515625\n",
      "Batch: 19, Loss: 1.2812817096710205, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.1367602348327637, Accuracy: 0.626953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 21, Loss: 1.1005818843841553, Accuracy: 0.65625\n",
      "Batch: 22, Loss: 1.2140480279922485, Accuracy: 0.6123046875\n",
      "Batch: 23, Loss: 1.1448631286621094, Accuracy: 0.62109375\n",
      "Batch: 24, Loss: 1.1876333951950073, Accuracy: 0.603515625\n",
      "Batch: 25, Loss: 1.1564264297485352, Accuracy: 0.6298828125\n",
      "Batch: 26, Loss: 1.0413289070129395, Accuracy: 0.6484375\n",
      "Batch: 27, Loss: 1.0954160690307617, Accuracy: 0.6171875\n",
      "Batch: 28, Loss: 1.1716725826263428, Accuracy: 0.5966796875\n",
      "Batch: 29, Loss: 1.2008243799209595, Accuracy: 0.609375\n",
      "Batch: 30, Loss: 1.1360483169555664, Accuracy: 0.65234375\n",
      "Batch: 31, Loss: 1.099495768547058, Accuracy: 0.66015625\n",
      "Batch: 32, Loss: 1.0543606281280518, Accuracy: 0.6455078125\n",
      "Batch: 33, Loss: 1.262247920036316, Accuracy: 0.5810546875\n",
      "Batch: 34, Loss: 1.320991039276123, Accuracy: 0.5732421875\n",
      "Batch: 35, Loss: 1.2069482803344727, Accuracy: 0.6064453125\n",
      "Batch: 36, Loss: 1.2018418312072754, Accuracy: 0.62890625\n",
      "Batch: 37, Loss: 1.146406888961792, Accuracy: 0.6201171875\n",
      "Batch: 38, Loss: 1.194112777709961, Accuracy: 0.6005859375\n",
      "Batch: 39, Loss: 1.2065916061401367, Accuracy: 0.6279296875\n",
      "Batch: 40, Loss: 1.2284678220748901, Accuracy: 0.6298828125\n",
      "Batch: 41, Loss: 1.2141432762145996, Accuracy: 0.6298828125\n",
      "Batch: 42, Loss: 0.9612333178520203, Accuracy: 0.7001953125\n",
      "Batch: 43, Loss: 1.171689748764038, Accuracy: 0.6142578125\n",
      "Batch: 44, Loss: 1.149014949798584, Accuracy: 0.6044921875\n",
      "Batch: 45, Loss: 1.0211740732192993, Accuracy: 0.6552734375\n",
      "Batch: 46, Loss: 1.1591315269470215, Accuracy: 0.6494140625\n",
      "Batch: 47, Loss: 1.1495472192764282, Accuracy: 0.6484375\n",
      "Batch: 48, Loss: 1.0668549537658691, Accuracy: 0.6591796875\n",
      "Batch: 49, Loss: 1.2784199714660645, Accuracy: 0.595703125\n",
      "Batch: 50, Loss: 1.2150516510009766, Accuracy: 0.619140625\n",
      "Batch: 51, Loss: 1.311668038368225, Accuracy: 0.576171875\n",
      "Batch: 52, Loss: 1.2625480890274048, Accuracy: 0.61328125\n",
      "Batch: 53, Loss: 1.0269001722335815, Accuracy: 0.6533203125\n",
      "Batch: 54, Loss: 1.1361165046691895, Accuracy: 0.650390625\n",
      "Batch: 55, Loss: 1.1985714435577393, Accuracy: 0.595703125\n",
      "Batch: 56, Loss: 1.2183234691619873, Accuracy: 0.61328125\n",
      "Batch: 57, Loss: 1.1588201522827148, Accuracy: 0.626953125\n",
      "Batch: 58, Loss: 1.2483305931091309, Accuracy: 0.6201171875\n",
      "Batch: 59, Loss: 1.1040027141571045, Accuracy: 0.65625\n",
      "Batch: 60, Loss: 1.0614720582962036, Accuracy: 0.65625\n",
      "Batch: 61, Loss: 1.1826810836791992, Accuracy: 0.6142578125\n",
      "Batch: 62, Loss: 1.1429579257965088, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.1428228616714478, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.1435332298278809, Accuracy: 0.6279296875\n",
      "Batch: 65, Loss: 1.179644227027893, Accuracy: 0.640625\n",
      "Batch: 66, Loss: 1.068098783493042, Accuracy: 0.671875\n",
      "Batch: 67, Loss: 1.23642098903656, Accuracy: 0.6083984375\n",
      "Batch: 68, Loss: 1.2980173826217651, Accuracy: 0.6201171875\n",
      "Batch: 69, Loss: 1.1874104738235474, Accuracy: 0.6259765625\n",
      "Batch: 70, Loss: 1.2086639404296875, Accuracy: 0.623046875\n",
      "Batch: 71, Loss: 1.183319330215454, Accuracy: 0.634765625\n",
      "Batch: 72, Loss: 1.0707647800445557, Accuracy: 0.6611328125\n",
      "Batch: 73, Loss: 1.1289266347885132, Accuracy: 0.6513671875\n",
      "Batch: 74, Loss: 1.1038765907287598, Accuracy: 0.6396484375\n",
      "Batch: 75, Loss: 1.0627973079681396, Accuracy: 0.6474609375\n",
      "Batch: 76, Loss: 1.1776602268218994, Accuracy: 0.615234375\n",
      "Batch: 77, Loss: 1.1273729801177979, Accuracy: 0.6318359375\n",
      "Batch: 78, Loss: 1.1650407314300537, Accuracy: 0.63671875\n",
      "Batch: 79, Loss: 1.0374871492385864, Accuracy: 0.6865234375\n",
      "Batch: 80, Loss: 1.0751264095306396, Accuracy: 0.62890625\n",
      "Batch: 81, Loss: 1.228069543838501, Accuracy: 0.5888671875\n",
      "Batch: 82, Loss: 1.2164686918258667, Accuracy: 0.603515625\n",
      "Batch: 83, Loss: 1.0413126945495605, Accuracy: 0.6865234375\n",
      "Batch: 84, Loss: 1.110583782196045, Accuracy: 0.650390625\n",
      "Batch: 85, Loss: 1.0358071327209473, Accuracy: 0.6640625\n",
      "Batch: 86, Loss: 1.2690446376800537, Accuracy: 0.59375\n",
      "Batch: 87, Loss: 1.071405291557312, Accuracy: 0.67578125\n",
      "Batch: 88, Loss: 1.219383955001831, Accuracy: 0.6240234375\n",
      "Batch: 89, Loss: 1.2216572761535645, Accuracy: 0.6142578125\n",
      "Batch: 90, Loss: 1.0795626640319824, Accuracy: 0.662109375\n",
      "Batch: 91, Loss: 1.1640514135360718, Accuracy: 0.638671875\n",
      "Batch: 92, Loss: 1.1573266983032227, Accuracy: 0.6220703125\n",
      "Batch: 93, Loss: 1.1086492538452148, Accuracy: 0.650390625\n",
      "Batch: 94, Loss: 1.1055275201797485, Accuracy: 0.634765625\n",
      "Batch: 95, Loss: 1.1783051490783691, Accuracy: 0.6103515625\n",
      "Batch: 96, Loss: 1.134833812713623, Accuracy: 0.6298828125\n",
      "Batch: 97, Loss: 1.0234370231628418, Accuracy: 0.6669921875\n",
      "Batch: 98, Loss: 1.0648226737976074, Accuracy: 0.67578125\n",
      "Batch: 99, Loss: 1.042892336845398, Accuracy: 0.6552734375\n",
      "Batch: 100, Loss: 1.124157190322876, Accuracy: 0.6328125\n",
      "Batch: 101, Loss: 1.2034285068511963, Accuracy: 0.6064453125\n",
      "Batch: 102, Loss: 1.0814142227172852, Accuracy: 0.6533203125\n",
      "Batch: 103, Loss: 1.2009023427963257, Accuracy: 0.650390625\n",
      "Batch: 104, Loss: 1.0719983577728271, Accuracy: 0.64453125\n",
      "Batch: 105, Loss: 1.1777253150939941, Accuracy: 0.6142578125\n",
      "Batch: 106, Loss: 1.159728765487671, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.245417833328247, Accuracy: 0.6123046875\n",
      "Batch: 108, Loss: 1.1782362461090088, Accuracy: 0.6123046875\n",
      "Batch: 109, Loss: 1.270567536354065, Accuracy: 0.58203125\n",
      "Batch: 110, Loss: 0.9820552468299866, Accuracy: 0.6787109375\n",
      "Batch: 111, Loss: 1.2004655599594116, Accuracy: 0.5888671875\n",
      "Batch: 112, Loss: 1.120920181274414, Accuracy: 0.6533203125\n",
      "Batch: 113, Loss: 1.1718237400054932, Accuracy: 0.6455078125\n",
      "Batch: 114, Loss: 1.3059477806091309, Accuracy: 0.5693359375\n",
      "Batch: 115, Loss: 1.2867507934570312, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.2291357517242432, Accuracy: 0.59765625\n",
      "Batch: 117, Loss: 1.2349458932876587, Accuracy: 0.6123046875\n",
      "Batch: 118, Loss: 1.0374481678009033, Accuracy: 0.677734375\n",
      "Batch: 119, Loss: 1.0506305694580078, Accuracy: 0.66015625\n",
      "Batch: 120, Loss: 1.1870675086975098, Accuracy: 0.6220703125\n",
      "Batch: 121, Loss: 1.2444595098495483, Accuracy: 0.6025390625\n",
      "Batch: 122, Loss: 1.1274851560592651, Accuracy: 0.650390625\n",
      "Batch: 123, Loss: 1.1221147775650024, Accuracy: 0.642578125\n",
      "Batch: 124, Loss: 1.177814245223999, Accuracy: 0.6123046875\n",
      "Batch: 125, Loss: 1.2194504737854004, Accuracy: 0.619140625\n",
      "Batch: 126, Loss: 1.1882598400115967, Accuracy: 0.6044921875\n",
      "Batch: 127, Loss: 1.0739089250564575, Accuracy: 0.67578125\n",
      "Batch: 128, Loss: 1.2850641012191772, Accuracy: 0.603515625\n",
      "Batch: 129, Loss: 1.087127923965454, Accuracy: 0.6357421875\n",
      "Batch: 130, Loss: 1.342553734779358, Accuracy: 0.5634765625\n",
      "Batch: 131, Loss: 1.2280000448226929, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.2511850595474243, Accuracy: 0.6064453125\n",
      "Batch: 133, Loss: 1.0753642320632935, Accuracy: 0.650390625\n",
      "Batch: 134, Loss: 1.1888442039489746, Accuracy: 0.611328125\n",
      "Batch: 135, Loss: 1.0942926406860352, Accuracy: 0.6591796875\n",
      "Batch: 136, Loss: 1.1499496698379517, Accuracy: 0.630859375\n",
      "Batch: 137, Loss: 1.0560849905014038, Accuracy: 0.6416015625\n",
      "Batch: 138, Loss: 0.9473087787628174, Accuracy: 0.671875\n",
      "Batch: 139, Loss: 1.0339159965515137, Accuracy: 0.662109375\n",
      "Batch: 140, Loss: 1.1304070949554443, Accuracy: 0.6201171875\n",
      "Batch: 141, Loss: 1.1286871433258057, Accuracy: 0.63671875\n",
      "Batch: 142, Loss: 1.1782313585281372, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.1761932373046875, Accuracy: 0.6240234375\n",
      "Batch: 144, Loss: 1.161991000175476, Accuracy: 0.63671875\n",
      "Batch: 145, Loss: 1.0777461528778076, Accuracy: 0.626953125\n",
      "Batch: 146, Loss: 1.1911327838897705, Accuracy: 0.6220703125\n",
      "Batch: 147, Loss: 1.1603392362594604, Accuracy: 0.6259765625\n",
      "Batch: 148, Loss: 1.2825493812561035, Accuracy: 0.57421875\n",
      "Batch: 149, Loss: 1.1551363468170166, Accuracy: 0.6162109375\n",
      "Batch: 150, Loss: 1.062272071838379, Accuracy: 0.6376953125\n",
      "Batch: 151, Loss: 1.0293514728546143, Accuracy: 0.6728515625\n",
      "Epoch 12/90\n",
      "Batch: 1, Loss: 1.4094665050506592, Accuracy: 0.5439453125\n",
      "Batch: 2, Loss: 1.1640774011611938, Accuracy: 0.6162109375\n",
      "Batch: 3, Loss: 1.0939059257507324, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 1.0265862941741943, Accuracy: 0.677734375\n",
      "Batch: 5, Loss: 1.0379183292388916, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.1290738582611084, Accuracy: 0.625\n",
      "Batch: 7, Loss: 1.0915299654006958, Accuracy: 0.6455078125\n",
      "Batch: 8, Loss: 1.054368019104004, Accuracy: 0.65234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9, Loss: 1.0011067390441895, Accuracy: 0.671875\n",
      "Batch: 10, Loss: 1.0248019695281982, Accuracy: 0.6630859375\n",
      "Batch: 11, Loss: 1.2218620777130127, Accuracy: 0.5908203125\n",
      "Batch: 12, Loss: 1.2320481538772583, Accuracy: 0.5966796875\n",
      "Batch: 13, Loss: 0.9705637097358704, Accuracy: 0.6884765625\n",
      "Batch: 14, Loss: 1.2203842401504517, Accuracy: 0.6025390625\n",
      "Batch: 15, Loss: 1.0635039806365967, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.0756967067718506, Accuracy: 0.66015625\n",
      "Batch: 17, Loss: 1.1587891578674316, Accuracy: 0.6142578125\n",
      "Batch: 18, Loss: 1.1604430675506592, Accuracy: 0.6123046875\n",
      "Batch: 19, Loss: 1.2189114093780518, Accuracy: 0.626953125\n",
      "Batch: 20, Loss: 1.0795214176177979, Accuracy: 0.64453125\n",
      "Batch: 21, Loss: 1.0925260782241821, Accuracy: 0.646484375\n",
      "Batch: 22, Loss: 1.1913979053497314, Accuracy: 0.6318359375\n",
      "Batch: 23, Loss: 1.1189255714416504, Accuracy: 0.6298828125\n",
      "Batch: 24, Loss: 1.124490737915039, Accuracy: 0.630859375\n",
      "Batch: 25, Loss: 1.1363416910171509, Accuracy: 0.634765625\n",
      "Batch: 26, Loss: 1.0210200548171997, Accuracy: 0.673828125\n",
      "Batch: 27, Loss: 1.0748436450958252, Accuracy: 0.6337890625\n",
      "Batch: 28, Loss: 1.163651943206787, Accuracy: 0.603515625\n",
      "Batch: 29, Loss: 1.1561859846115112, Accuracy: 0.6171875\n",
      "Batch: 30, Loss: 1.1022146940231323, Accuracy: 0.658203125\n",
      "Batch: 31, Loss: 1.0691866874694824, Accuracy: 0.6689453125\n",
      "Batch: 32, Loss: 1.0514113903045654, Accuracy: 0.6474609375\n",
      "Batch: 33, Loss: 1.2386372089385986, Accuracy: 0.5966796875\n",
      "Batch: 34, Loss: 1.272245168685913, Accuracy: 0.5947265625\n",
      "Batch: 35, Loss: 1.170240879058838, Accuracy: 0.6142578125\n",
      "Batch: 36, Loss: 1.1657450199127197, Accuracy: 0.6279296875\n",
      "Batch: 37, Loss: 1.1112089157104492, Accuracy: 0.6279296875\n",
      "Batch: 38, Loss: 1.1431777477264404, Accuracy: 0.6240234375\n",
      "Batch: 39, Loss: 1.156001091003418, Accuracy: 0.6318359375\n",
      "Batch: 40, Loss: 1.1902873516082764, Accuracy: 0.6142578125\n",
      "Batch: 41, Loss: 1.158860206604004, Accuracy: 0.6376953125\n",
      "Batch: 42, Loss: 0.949463963508606, Accuracy: 0.6904296875\n",
      "Batch: 43, Loss: 1.1588280200958252, Accuracy: 0.6318359375\n",
      "Batch: 44, Loss: 1.125502347946167, Accuracy: 0.6279296875\n",
      "Batch: 45, Loss: 0.9957895278930664, Accuracy: 0.6669921875\n",
      "Batch: 46, Loss: 1.126389503479004, Accuracy: 0.6572265625\n",
      "Batch: 47, Loss: 1.0899958610534668, Accuracy: 0.6611328125\n",
      "Batch: 48, Loss: 1.04396390914917, Accuracy: 0.6630859375\n",
      "Batch: 49, Loss: 1.2409708499908447, Accuracy: 0.5947265625\n",
      "Batch: 50, Loss: 1.1938576698303223, Accuracy: 0.6201171875\n",
      "Batch: 51, Loss: 1.268165111541748, Accuracy: 0.5986328125\n",
      "Batch: 52, Loss: 1.2303009033203125, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.0177810192108154, Accuracy: 0.6533203125\n",
      "Batch: 54, Loss: 1.0881552696228027, Accuracy: 0.6474609375\n",
      "Batch: 55, Loss: 1.1598429679870605, Accuracy: 0.6181640625\n",
      "Batch: 56, Loss: 1.1899367570877075, Accuracy: 0.6015625\n",
      "Batch: 57, Loss: 1.1334624290466309, Accuracy: 0.6396484375\n",
      "Batch: 58, Loss: 1.2280762195587158, Accuracy: 0.6357421875\n",
      "Batch: 59, Loss: 1.0738651752471924, Accuracy: 0.673828125\n",
      "Batch: 60, Loss: 1.0260131359100342, Accuracy: 0.6748046875\n",
      "Batch: 61, Loss: 1.1644506454467773, Accuracy: 0.6220703125\n",
      "Batch: 62, Loss: 1.1221624612808228, Accuracy: 0.6484375\n",
      "Batch: 63, Loss: 1.118774175643921, Accuracy: 0.6513671875\n",
      "Batch: 64, Loss: 1.0864994525909424, Accuracy: 0.6484375\n",
      "Batch: 65, Loss: 1.1497657299041748, Accuracy: 0.6396484375\n",
      "Batch: 66, Loss: 1.068216323852539, Accuracy: 0.6611328125\n",
      "Batch: 67, Loss: 1.201936960220337, Accuracy: 0.615234375\n",
      "Batch: 68, Loss: 1.2392427921295166, Accuracy: 0.6162109375\n",
      "Batch: 69, Loss: 1.1868139505386353, Accuracy: 0.609375\n",
      "Batch: 70, Loss: 1.1601285934448242, Accuracy: 0.63671875\n",
      "Batch: 71, Loss: 1.158134937286377, Accuracy: 0.6240234375\n",
      "Batch: 72, Loss: 1.031290054321289, Accuracy: 0.662109375\n",
      "Batch: 73, Loss: 1.1025997400283813, Accuracy: 0.65234375\n",
      "Batch: 74, Loss: 1.0470843315124512, Accuracy: 0.662109375\n",
      "Batch: 75, Loss: 1.0070505142211914, Accuracy: 0.6748046875\n",
      "Batch: 76, Loss: 1.1348623037338257, Accuracy: 0.6279296875\n",
      "Batch: 77, Loss: 1.0875217914581299, Accuracy: 0.6533203125\n",
      "Batch: 78, Loss: 1.111647129058838, Accuracy: 0.6494140625\n",
      "Batch: 79, Loss: 1.0086703300476074, Accuracy: 0.68359375\n",
      "Batch: 80, Loss: 1.0390686988830566, Accuracy: 0.6484375\n",
      "Batch: 81, Loss: 1.1799578666687012, Accuracy: 0.607421875\n",
      "Batch: 82, Loss: 1.164262056350708, Accuracy: 0.626953125\n",
      "Batch: 83, Loss: 1.012657642364502, Accuracy: 0.685546875\n",
      "Batch: 84, Loss: 1.0985517501831055, Accuracy: 0.66015625\n",
      "Batch: 85, Loss: 0.9996727108955383, Accuracy: 0.681640625\n",
      "Batch: 86, Loss: 1.2502343654632568, Accuracy: 0.6162109375\n",
      "Batch: 87, Loss: 1.0317363739013672, Accuracy: 0.7001953125\n",
      "Batch: 88, Loss: 1.178716778755188, Accuracy: 0.638671875\n",
      "Batch: 89, Loss: 1.1795649528503418, Accuracy: 0.6357421875\n",
      "Batch: 90, Loss: 1.0511038303375244, Accuracy: 0.6689453125\n",
      "Batch: 91, Loss: 1.1265084743499756, Accuracy: 0.6533203125\n",
      "Batch: 92, Loss: 1.1272318363189697, Accuracy: 0.6376953125\n",
      "Batch: 93, Loss: 1.0700454711914062, Accuracy: 0.6630859375\n",
      "Batch: 94, Loss: 1.05986487865448, Accuracy: 0.654296875\n",
      "Batch: 95, Loss: 1.1264798641204834, Accuracy: 0.6279296875\n",
      "Batch: 96, Loss: 1.094771385192871, Accuracy: 0.6533203125\n",
      "Batch: 97, Loss: 0.9965355396270752, Accuracy: 0.6904296875\n",
      "Batch: 98, Loss: 1.0192079544067383, Accuracy: 0.677734375\n",
      "Batch: 99, Loss: 1.0116465091705322, Accuracy: 0.66796875\n",
      "Batch: 100, Loss: 1.070375680923462, Accuracy: 0.6650390625\n",
      "Batch: 101, Loss: 1.1637356281280518, Accuracy: 0.634765625\n",
      "Batch: 102, Loss: 1.046240210533142, Accuracy: 0.6533203125\n",
      "Batch: 103, Loss: 1.14384126663208, Accuracy: 0.6416015625\n",
      "Batch: 104, Loss: 1.0206389427185059, Accuracy: 0.6640625\n",
      "Batch: 105, Loss: 1.1223547458648682, Accuracy: 0.6318359375\n",
      "Batch: 106, Loss: 1.1269112825393677, Accuracy: 0.638671875\n",
      "Batch: 107, Loss: 1.2117403745651245, Accuracy: 0.626953125\n",
      "Batch: 108, Loss: 1.1280301809310913, Accuracy: 0.6318359375\n",
      "Batch: 109, Loss: 1.2510006427764893, Accuracy: 0.5947265625\n",
      "Batch: 110, Loss: 0.964740514755249, Accuracy: 0.6787109375\n",
      "Batch: 111, Loss: 1.183882474899292, Accuracy: 0.6064453125\n",
      "Batch: 112, Loss: 1.0967211723327637, Accuracy: 0.669921875\n",
      "Batch: 113, Loss: 1.1339367628097534, Accuracy: 0.640625\n",
      "Batch: 114, Loss: 1.2714216709136963, Accuracy: 0.607421875\n",
      "Batch: 115, Loss: 1.247246265411377, Accuracy: 0.634765625\n",
      "Batch: 116, Loss: 1.1990008354187012, Accuracy: 0.609375\n",
      "Batch: 117, Loss: 1.1961438655853271, Accuracy: 0.6259765625\n",
      "Batch: 118, Loss: 0.9908093214035034, Accuracy: 0.681640625\n",
      "Batch: 119, Loss: 1.0383777618408203, Accuracy: 0.6796875\n",
      "Batch: 120, Loss: 1.1664767265319824, Accuracy: 0.62890625\n",
      "Batch: 121, Loss: 1.2068302631378174, Accuracy: 0.607421875\n",
      "Batch: 122, Loss: 1.081009864807129, Accuracy: 0.66796875\n",
      "Batch: 123, Loss: 1.0779951810836792, Accuracy: 0.6640625\n",
      "Batch: 124, Loss: 1.1680766344070435, Accuracy: 0.6318359375\n",
      "Batch: 125, Loss: 1.1860142946243286, Accuracy: 0.6259765625\n",
      "Batch: 126, Loss: 1.1550804376602173, Accuracy: 0.603515625\n",
      "Batch: 127, Loss: 1.0300829410552979, Accuracy: 0.6904296875\n",
      "Batch: 128, Loss: 1.2334867715835571, Accuracy: 0.611328125\n",
      "Batch: 129, Loss: 1.0689973831176758, Accuracy: 0.6591796875\n",
      "Batch: 130, Loss: 1.288977861404419, Accuracy: 0.58984375\n",
      "Batch: 131, Loss: 1.1811925172805786, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.2284948825836182, Accuracy: 0.60546875\n",
      "Batch: 133, Loss: 1.0455275774002075, Accuracy: 0.6513671875\n",
      "Batch: 134, Loss: 1.1415181159973145, Accuracy: 0.62109375\n",
      "Batch: 135, Loss: 1.0682852268218994, Accuracy: 0.6611328125\n",
      "Batch: 136, Loss: 1.1096885204315186, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.0360220670700073, Accuracy: 0.658203125\n",
      "Batch: 138, Loss: 0.9257327318191528, Accuracy: 0.6943359375\n",
      "Batch: 139, Loss: 1.0046775341033936, Accuracy: 0.673828125\n",
      "Batch: 140, Loss: 1.0954554080963135, Accuracy: 0.646484375\n",
      "Batch: 141, Loss: 1.1239163875579834, Accuracy: 0.6474609375\n",
      "Batch: 142, Loss: 1.155200481414795, Accuracy: 0.6298828125\n",
      "Batch: 143, Loss: 1.1389203071594238, Accuracy: 0.6259765625\n",
      "Batch: 144, Loss: 1.127724051475525, Accuracy: 0.6435546875\n",
      "Batch: 145, Loss: 1.0461499691009521, Accuracy: 0.6474609375\n",
      "Batch: 146, Loss: 1.1549394130706787, Accuracy: 0.6337890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 147, Loss: 1.1281702518463135, Accuracy: 0.6328125\n",
      "Batch: 148, Loss: 1.2538799047470093, Accuracy: 0.58984375\n",
      "Batch: 149, Loss: 1.1251418590545654, Accuracy: 0.615234375\n",
      "Batch: 150, Loss: 1.0473958253860474, Accuracy: 0.6591796875\n",
      "Batch: 151, Loss: 0.9791310429573059, Accuracy: 0.6904296875\n",
      "Epoch 13/90\n",
      "Batch: 1, Loss: 1.373604655265808, Accuracy: 0.5400390625\n",
      "Batch: 2, Loss: 1.1375919580459595, Accuracy: 0.615234375\n",
      "Batch: 3, Loss: 1.0573456287384033, Accuracy: 0.640625\n",
      "Batch: 4, Loss: 1.0025360584259033, Accuracy: 0.6845703125\n",
      "Batch: 5, Loss: 0.9793983101844788, Accuracy: 0.677734375\n",
      "Batch: 6, Loss: 1.0829139947891235, Accuracy: 0.6552734375\n",
      "Batch: 7, Loss: 1.043731451034546, Accuracy: 0.6474609375\n",
      "Batch: 8, Loss: 1.0186468362808228, Accuracy: 0.666015625\n",
      "Batch: 9, Loss: 0.9765702486038208, Accuracy: 0.6845703125\n",
      "Batch: 10, Loss: 1.0052403211593628, Accuracy: 0.681640625\n",
      "Batch: 11, Loss: 1.1962937116622925, Accuracy: 0.59375\n",
      "Batch: 12, Loss: 1.1987366676330566, Accuracy: 0.6064453125\n",
      "Batch: 13, Loss: 0.9411014914512634, Accuracy: 0.685546875\n",
      "Batch: 14, Loss: 1.1805777549743652, Accuracy: 0.619140625\n",
      "Batch: 15, Loss: 1.0316715240478516, Accuracy: 0.6806640625\n",
      "Batch: 16, Loss: 1.042425513267517, Accuracy: 0.6650390625\n",
      "Batch: 17, Loss: 1.1288654804229736, Accuracy: 0.6162109375\n",
      "Batch: 18, Loss: 1.121457576751709, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.1843152046203613, Accuracy: 0.62109375\n",
      "Batch: 20, Loss: 1.0416892766952515, Accuracy: 0.66015625\n",
      "Batch: 21, Loss: 1.040959119796753, Accuracy: 0.6611328125\n",
      "Batch: 22, Loss: 1.139141321182251, Accuracy: 0.6376953125\n",
      "Batch: 23, Loss: 1.1035053730010986, Accuracy: 0.6357421875\n",
      "Batch: 24, Loss: 1.1190316677093506, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.0716642141342163, Accuracy: 0.6640625\n",
      "Batch: 26, Loss: 0.9884782433509827, Accuracy: 0.68359375\n",
      "Batch: 27, Loss: 1.0333311557769775, Accuracy: 0.6484375\n",
      "Batch: 28, Loss: 1.1333959102630615, Accuracy: 0.6220703125\n",
      "Batch: 29, Loss: 1.1245648860931396, Accuracy: 0.630859375\n",
      "Batch: 30, Loss: 1.0464805364608765, Accuracy: 0.6611328125\n",
      "Batch: 31, Loss: 1.044272541999817, Accuracy: 0.662109375\n",
      "Batch: 32, Loss: 0.9890958666801453, Accuracy: 0.6826171875\n",
      "Batch: 33, Loss: 1.1849148273468018, Accuracy: 0.619140625\n",
      "Batch: 34, Loss: 1.2263967990875244, Accuracy: 0.60546875\n",
      "Batch: 35, Loss: 1.135824203491211, Accuracy: 0.626953125\n",
      "Batch: 36, Loss: 1.148547649383545, Accuracy: 0.64453125\n",
      "Batch: 37, Loss: 1.0916757583618164, Accuracy: 0.6376953125\n",
      "Batch: 38, Loss: 1.1073977947235107, Accuracy: 0.63671875\n",
      "Batch: 39, Loss: 1.1392878293991089, Accuracy: 0.634765625\n",
      "Batch: 40, Loss: 1.1414625644683838, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.103292465209961, Accuracy: 0.658203125\n",
      "Batch: 42, Loss: 0.9134561419487, Accuracy: 0.7021484375\n",
      "Batch: 43, Loss: 1.1261801719665527, Accuracy: 0.62890625\n",
      "Batch: 44, Loss: 1.0792829990386963, Accuracy: 0.6318359375\n",
      "Batch: 45, Loss: 0.967185378074646, Accuracy: 0.681640625\n",
      "Batch: 46, Loss: 1.0810704231262207, Accuracy: 0.6474609375\n",
      "Batch: 47, Loss: 1.0638084411621094, Accuracy: 0.65625\n",
      "Batch: 48, Loss: 1.0154467821121216, Accuracy: 0.673828125\n",
      "Batch: 49, Loss: 1.2165725231170654, Accuracy: 0.609375\n",
      "Batch: 50, Loss: 1.1563498973846436, Accuracy: 0.6201171875\n",
      "Batch: 51, Loss: 1.225762128829956, Accuracy: 0.5986328125\n",
      "Batch: 52, Loss: 1.1919047832489014, Accuracy: 0.6279296875\n",
      "Batch: 53, Loss: 0.9869750142097473, Accuracy: 0.6611328125\n",
      "Batch: 54, Loss: 1.0911636352539062, Accuracy: 0.6455078125\n",
      "Batch: 55, Loss: 1.1491937637329102, Accuracy: 0.607421875\n",
      "Batch: 56, Loss: 1.1682542562484741, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.0859618186950684, Accuracy: 0.66015625\n",
      "Batch: 58, Loss: 1.172773838043213, Accuracy: 0.6337890625\n",
      "Batch: 59, Loss: 1.0377706289291382, Accuracy: 0.6875\n",
      "Batch: 60, Loss: 0.9859924912452698, Accuracy: 0.6796875\n",
      "Batch: 61, Loss: 1.1150336265563965, Accuracy: 0.64453125\n",
      "Batch: 62, Loss: 1.0656977891921997, Accuracy: 0.6533203125\n",
      "Batch: 63, Loss: 1.0935477018356323, Accuracy: 0.6416015625\n",
      "Batch: 64, Loss: 1.0668089389801025, Accuracy: 0.6455078125\n",
      "Batch: 65, Loss: 1.1225026845932007, Accuracy: 0.64453125\n",
      "Batch: 66, Loss: 1.0329021215438843, Accuracy: 0.67578125\n",
      "Batch: 67, Loss: 1.150514841079712, Accuracy: 0.623046875\n",
      "Batch: 68, Loss: 1.1994600296020508, Accuracy: 0.62890625\n",
      "Batch: 69, Loss: 1.1324262619018555, Accuracy: 0.6259765625\n",
      "Batch: 70, Loss: 1.1429837942123413, Accuracy: 0.63671875\n",
      "Batch: 71, Loss: 1.1223254203796387, Accuracy: 0.6240234375\n",
      "Batch: 72, Loss: 0.980066180229187, Accuracy: 0.6796875\n",
      "Batch: 73, Loss: 1.063422679901123, Accuracy: 0.67578125\n",
      "Batch: 74, Loss: 1.030015230178833, Accuracy: 0.6826171875\n",
      "Batch: 75, Loss: 0.9739354252815247, Accuracy: 0.6943359375\n",
      "Batch: 76, Loss: 1.0980980396270752, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.049654483795166, Accuracy: 0.6552734375\n",
      "Batch: 78, Loss: 1.0940907001495361, Accuracy: 0.6689453125\n",
      "Batch: 79, Loss: 0.9609516859054565, Accuracy: 0.7119140625\n",
      "Batch: 80, Loss: 1.0067161321640015, Accuracy: 0.6474609375\n",
      "Batch: 81, Loss: 1.1701416969299316, Accuracy: 0.6025390625\n",
      "Batch: 82, Loss: 1.1379945278167725, Accuracy: 0.634765625\n",
      "Batch: 83, Loss: 0.9711591005325317, Accuracy: 0.7060546875\n",
      "Batch: 84, Loss: 1.0429247617721558, Accuracy: 0.6748046875\n",
      "Batch: 85, Loss: 0.9827845096588135, Accuracy: 0.6787109375\n",
      "Batch: 86, Loss: 1.2087070941925049, Accuracy: 0.6240234375\n",
      "Batch: 87, Loss: 1.0181663036346436, Accuracy: 0.689453125\n",
      "Batch: 88, Loss: 1.1522068977355957, Accuracy: 0.6591796875\n",
      "Batch: 89, Loss: 1.1351079940795898, Accuracy: 0.6484375\n",
      "Batch: 90, Loss: 1.0219382047653198, Accuracy: 0.673828125\n",
      "Batch: 91, Loss: 1.0999270677566528, Accuracy: 0.64453125\n",
      "Batch: 92, Loss: 1.0919890403747559, Accuracy: 0.642578125\n",
      "Batch: 93, Loss: 1.042555809020996, Accuracy: 0.671875\n",
      "Batch: 94, Loss: 1.0379078388214111, Accuracy: 0.65234375\n",
      "Batch: 95, Loss: 1.1227319240570068, Accuracy: 0.6201171875\n",
      "Batch: 96, Loss: 1.068558692932129, Accuracy: 0.6572265625\n",
      "Batch: 97, Loss: 0.9785962700843811, Accuracy: 0.677734375\n",
      "Batch: 98, Loss: 0.9861176013946533, Accuracy: 0.6884765625\n",
      "Batch: 99, Loss: 0.9780688285827637, Accuracy: 0.681640625\n",
      "Batch: 100, Loss: 1.0358233451843262, Accuracy: 0.67578125\n",
      "Batch: 101, Loss: 1.1274762153625488, Accuracy: 0.65234375\n",
      "Batch: 102, Loss: 1.04245924949646, Accuracy: 0.6533203125\n",
      "Batch: 103, Loss: 1.1330482959747314, Accuracy: 0.65234375\n",
      "Batch: 104, Loss: 1.0089327096939087, Accuracy: 0.6484375\n",
      "Batch: 105, Loss: 1.1000226736068726, Accuracy: 0.6396484375\n",
      "Batch: 106, Loss: 1.0941596031188965, Accuracy: 0.62890625\n",
      "Batch: 107, Loss: 1.1750727891921997, Accuracy: 0.6318359375\n",
      "Batch: 108, Loss: 1.1066068410873413, Accuracy: 0.6416015625\n",
      "Batch: 109, Loss: 1.2115249633789062, Accuracy: 0.609375\n",
      "Batch: 110, Loss: 0.9269128441810608, Accuracy: 0.7060546875\n",
      "Batch: 111, Loss: 1.1288175582885742, Accuracy: 0.626953125\n",
      "Batch: 112, Loss: 1.0703492164611816, Accuracy: 0.6865234375\n",
      "Batch: 113, Loss: 1.0914456844329834, Accuracy: 0.6591796875\n",
      "Batch: 114, Loss: 1.2047700881958008, Accuracy: 0.6171875\n",
      "Batch: 115, Loss: 1.1988416910171509, Accuracy: 0.6259765625\n",
      "Batch: 116, Loss: 1.1611887216567993, Accuracy: 0.62890625\n",
      "Batch: 117, Loss: 1.1780469417572021, Accuracy: 0.634765625\n",
      "Batch: 118, Loss: 0.9849406480789185, Accuracy: 0.697265625\n",
      "Batch: 119, Loss: 0.9849031567573547, Accuracy: 0.6943359375\n",
      "Batch: 120, Loss: 1.1234232187271118, Accuracy: 0.63671875\n",
      "Batch: 121, Loss: 1.1477341651916504, Accuracy: 0.6455078125\n",
      "Batch: 122, Loss: 1.0539824962615967, Accuracy: 0.6806640625\n",
      "Batch: 123, Loss: 1.0444130897521973, Accuracy: 0.681640625\n",
      "Batch: 124, Loss: 1.1278332471847534, Accuracy: 0.6279296875\n",
      "Batch: 125, Loss: 1.1475025415420532, Accuracy: 0.6259765625\n",
      "Batch: 126, Loss: 1.1136066913604736, Accuracy: 0.6328125\n",
      "Batch: 127, Loss: 1.003570318222046, Accuracy: 0.6953125\n",
      "Batch: 128, Loss: 1.2153136730194092, Accuracy: 0.6181640625\n",
      "Batch: 129, Loss: 1.0319958925247192, Accuracy: 0.66015625\n",
      "Batch: 130, Loss: 1.2393195629119873, Accuracy: 0.595703125\n",
      "Batch: 131, Loss: 1.1377766132354736, Accuracy: 0.6337890625\n",
      "Batch: 132, Loss: 1.1710116863250732, Accuracy: 0.626953125\n",
      "Batch: 133, Loss: 1.0294134616851807, Accuracy: 0.6611328125\n",
      "Batch: 134, Loss: 1.1309924125671387, Accuracy: 0.642578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 135, Loss: 1.0194711685180664, Accuracy: 0.6787109375\n",
      "Batch: 136, Loss: 1.0813968181610107, Accuracy: 0.6748046875\n",
      "Batch: 137, Loss: 0.9893982410430908, Accuracy: 0.6513671875\n",
      "Batch: 138, Loss: 0.8990219831466675, Accuracy: 0.69140625\n",
      "Batch: 139, Loss: 0.9916644096374512, Accuracy: 0.6669921875\n",
      "Batch: 140, Loss: 1.0669091939926147, Accuracy: 0.6552734375\n",
      "Batch: 141, Loss: 1.0912307500839233, Accuracy: 0.6435546875\n",
      "Batch: 142, Loss: 1.1294195652008057, Accuracy: 0.6572265625\n",
      "Batch: 143, Loss: 1.0922399759292603, Accuracy: 0.6328125\n",
      "Batch: 144, Loss: 1.1173076629638672, Accuracy: 0.6533203125\n",
      "Batch: 145, Loss: 1.0123467445373535, Accuracy: 0.658203125\n",
      "Batch: 146, Loss: 1.1342192888259888, Accuracy: 0.6298828125\n",
      "Batch: 147, Loss: 1.0869678258895874, Accuracy: 0.6484375\n",
      "Batch: 148, Loss: 1.2216193675994873, Accuracy: 0.5908203125\n",
      "Batch: 149, Loss: 1.1087532043457031, Accuracy: 0.619140625\n",
      "Batch: 150, Loss: 1.029754638671875, Accuracy: 0.6630859375\n",
      "Batch: 151, Loss: 0.9547748565673828, Accuracy: 0.693359375\n",
      "Epoch 14/90\n",
      "Batch: 1, Loss: 1.331601858139038, Accuracy: 0.568359375\n",
      "Batch: 2, Loss: 1.123816728591919, Accuracy: 0.630859375\n",
      "Batch: 3, Loss: 1.0296857357025146, Accuracy: 0.662109375\n",
      "Batch: 4, Loss: 0.969929575920105, Accuracy: 0.7001953125\n",
      "Batch: 5, Loss: 0.9434328675270081, Accuracy: 0.697265625\n",
      "Batch: 6, Loss: 1.0731542110443115, Accuracy: 0.62890625\n",
      "Batch: 7, Loss: 1.0335593223571777, Accuracy: 0.638671875\n",
      "Batch: 8, Loss: 0.9756807088851929, Accuracy: 0.6708984375\n",
      "Batch: 9, Loss: 0.9438813328742981, Accuracy: 0.6962890625\n",
      "Batch: 10, Loss: 0.9644235372543335, Accuracy: 0.685546875\n",
      "Batch: 11, Loss: 1.1740176677703857, Accuracy: 0.6083984375\n",
      "Batch: 12, Loss: 1.158118724822998, Accuracy: 0.615234375\n",
      "Batch: 13, Loss: 0.9035617113113403, Accuracy: 0.7001953125\n",
      "Batch: 14, Loss: 1.1713414192199707, Accuracy: 0.6103515625\n",
      "Batch: 15, Loss: 0.9916404485702515, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 0.9969558715820312, Accuracy: 0.6943359375\n",
      "Batch: 17, Loss: 1.0942838191986084, Accuracy: 0.64453125\n",
      "Batch: 18, Loss: 1.0797851085662842, Accuracy: 0.64453125\n",
      "Batch: 19, Loss: 1.1592376232147217, Accuracy: 0.640625\n",
      "Batch: 20, Loss: 1.001603126525879, Accuracy: 0.685546875\n",
      "Batch: 21, Loss: 1.0074952840805054, Accuracy: 0.6669921875\n",
      "Batch: 22, Loss: 1.1244258880615234, Accuracy: 0.6376953125\n",
      "Batch: 23, Loss: 1.0558890104293823, Accuracy: 0.658203125\n",
      "Batch: 24, Loss: 1.0900397300720215, Accuracy: 0.63671875\n",
      "Batch: 25, Loss: 1.054617166519165, Accuracy: 0.6611328125\n",
      "Batch: 26, Loss: 0.9707115888595581, Accuracy: 0.6826171875\n",
      "Batch: 27, Loss: 1.012921690940857, Accuracy: 0.6650390625\n",
      "Batch: 28, Loss: 1.1106821298599243, Accuracy: 0.626953125\n",
      "Batch: 29, Loss: 1.1101043224334717, Accuracy: 0.61328125\n",
      "Batch: 30, Loss: 1.0272984504699707, Accuracy: 0.6689453125\n",
      "Batch: 31, Loss: 1.0060076713562012, Accuracy: 0.681640625\n",
      "Batch: 32, Loss: 0.9707671403884888, Accuracy: 0.6826171875\n",
      "Batch: 33, Loss: 1.157835602760315, Accuracy: 0.6162109375\n",
      "Batch: 34, Loss: 1.2188997268676758, Accuracy: 0.6162109375\n",
      "Batch: 35, Loss: 1.1045398712158203, Accuracy: 0.6376953125\n",
      "Batch: 36, Loss: 1.1214994192123413, Accuracy: 0.65625\n",
      "Batch: 37, Loss: 1.0615979433059692, Accuracy: 0.6611328125\n",
      "Batch: 38, Loss: 1.0885645151138306, Accuracy: 0.6494140625\n",
      "Batch: 39, Loss: 1.096375823020935, Accuracy: 0.66796875\n",
      "Batch: 40, Loss: 1.0942645072937012, Accuracy: 0.6669921875\n",
      "Batch: 41, Loss: 1.085480809211731, Accuracy: 0.6689453125\n",
      "Batch: 42, Loss: 0.8721613883972168, Accuracy: 0.69921875\n",
      "Batch: 43, Loss: 1.0814846754074097, Accuracy: 0.6455078125\n",
      "Batch: 44, Loss: 1.0775980949401855, Accuracy: 0.6357421875\n",
      "Batch: 45, Loss: 0.9202185273170471, Accuracy: 0.708984375\n",
      "Batch: 46, Loss: 1.0551371574401855, Accuracy: 0.685546875\n",
      "Batch: 47, Loss: 1.0323529243469238, Accuracy: 0.67578125\n",
      "Batch: 48, Loss: 0.9824944138526917, Accuracy: 0.6689453125\n",
      "Batch: 49, Loss: 1.1622614860534668, Accuracy: 0.6142578125\n",
      "Batch: 50, Loss: 1.127382516860962, Accuracy: 0.6357421875\n",
      "Batch: 51, Loss: 1.1912391185760498, Accuracy: 0.6220703125\n",
      "Batch: 52, Loss: 1.1636172533035278, Accuracy: 0.63671875\n",
      "Batch: 53, Loss: 0.961466908454895, Accuracy: 0.673828125\n",
      "Batch: 54, Loss: 1.0570205450057983, Accuracy: 0.6728515625\n",
      "Batch: 55, Loss: 1.1311390399932861, Accuracy: 0.6162109375\n",
      "Batch: 56, Loss: 1.1098051071166992, Accuracy: 0.6513671875\n",
      "Batch: 57, Loss: 1.0631285905838013, Accuracy: 0.66015625\n",
      "Batch: 58, Loss: 1.1556575298309326, Accuracy: 0.626953125\n",
      "Batch: 59, Loss: 1.0110749006271362, Accuracy: 0.693359375\n",
      "Batch: 60, Loss: 0.9774917960166931, Accuracy: 0.697265625\n",
      "Batch: 61, Loss: 1.0929839611053467, Accuracy: 0.65234375\n",
      "Batch: 62, Loss: 1.0450973510742188, Accuracy: 0.6669921875\n",
      "Batch: 63, Loss: 1.067986249923706, Accuracy: 0.654296875\n",
      "Batch: 64, Loss: 1.0303843021392822, Accuracy: 0.6611328125\n",
      "Batch: 65, Loss: 1.098900318145752, Accuracy: 0.677734375\n",
      "Batch: 66, Loss: 1.0004630088806152, Accuracy: 0.6845703125\n",
      "Batch: 67, Loss: 1.1174442768096924, Accuracy: 0.6396484375\n",
      "Batch: 68, Loss: 1.1508634090423584, Accuracy: 0.642578125\n",
      "Batch: 69, Loss: 1.1063412427902222, Accuracy: 0.6337890625\n",
      "Batch: 70, Loss: 1.08397376537323, Accuracy: 0.6640625\n",
      "Batch: 71, Loss: 1.091827630996704, Accuracy: 0.6484375\n",
      "Batch: 72, Loss: 0.9455583691596985, Accuracy: 0.6875\n",
      "Batch: 73, Loss: 1.0230756998062134, Accuracy: 0.6904296875\n",
      "Batch: 74, Loss: 0.9958016872406006, Accuracy: 0.689453125\n",
      "Batch: 75, Loss: 0.9324615597724915, Accuracy: 0.70703125\n",
      "Batch: 76, Loss: 1.0633580684661865, Accuracy: 0.6611328125\n",
      "Batch: 77, Loss: 1.0282970666885376, Accuracy: 0.666015625\n",
      "Batch: 78, Loss: 1.0559380054473877, Accuracy: 0.677734375\n",
      "Batch: 79, Loss: 0.9415968656539917, Accuracy: 0.7255859375\n",
      "Batch: 80, Loss: 1.0057837963104248, Accuracy: 0.6533203125\n",
      "Batch: 81, Loss: 1.125421166419983, Accuracy: 0.6044921875\n",
      "Batch: 82, Loss: 1.089099645614624, Accuracy: 0.6494140625\n",
      "Batch: 83, Loss: 0.9552185535430908, Accuracy: 0.7080078125\n",
      "Batch: 84, Loss: 1.0158257484436035, Accuracy: 0.6669921875\n",
      "Batch: 85, Loss: 0.9605510234832764, Accuracy: 0.6884765625\n",
      "Batch: 86, Loss: 1.2044107913970947, Accuracy: 0.6201171875\n",
      "Batch: 87, Loss: 1.0030012130737305, Accuracy: 0.689453125\n",
      "Batch: 88, Loss: 1.128096342086792, Accuracy: 0.669921875\n",
      "Batch: 89, Loss: 1.1042609214782715, Accuracy: 0.6630859375\n",
      "Batch: 90, Loss: 1.0030879974365234, Accuracy: 0.6806640625\n",
      "Batch: 91, Loss: 1.0753881931304932, Accuracy: 0.6484375\n",
      "Batch: 92, Loss: 1.066978931427002, Accuracy: 0.6630859375\n",
      "Batch: 93, Loss: 1.0146971940994263, Accuracy: 0.6806640625\n",
      "Batch: 94, Loss: 1.0283565521240234, Accuracy: 0.673828125\n",
      "Batch: 95, Loss: 1.0899428129196167, Accuracy: 0.6474609375\n",
      "Batch: 96, Loss: 1.0268657207489014, Accuracy: 0.6748046875\n",
      "Batch: 97, Loss: 0.9601320028305054, Accuracy: 0.6806640625\n",
      "Batch: 98, Loss: 0.9735123515129089, Accuracy: 0.7138671875\n",
      "Batch: 99, Loss: 0.9704603552818298, Accuracy: 0.6826171875\n",
      "Batch: 100, Loss: 1.0173248052597046, Accuracy: 0.677734375\n",
      "Batch: 101, Loss: 1.116511583328247, Accuracy: 0.6376953125\n",
      "Batch: 102, Loss: 1.0135555267333984, Accuracy: 0.6611328125\n",
      "Batch: 103, Loss: 1.114797592163086, Accuracy: 0.6630859375\n",
      "Batch: 104, Loss: 0.9805189371109009, Accuracy: 0.67578125\n",
      "Batch: 105, Loss: 1.0607235431671143, Accuracy: 0.6416015625\n",
      "Batch: 106, Loss: 1.0516202449798584, Accuracy: 0.6572265625\n",
      "Batch: 107, Loss: 1.1218396425247192, Accuracy: 0.6474609375\n",
      "Batch: 108, Loss: 1.0819423198699951, Accuracy: 0.6435546875\n",
      "Batch: 109, Loss: 1.154573917388916, Accuracy: 0.6279296875\n",
      "Batch: 110, Loss: 0.9158862829208374, Accuracy: 0.7060546875\n",
      "Batch: 111, Loss: 1.1171501874923706, Accuracy: 0.6220703125\n",
      "Batch: 112, Loss: 1.059819221496582, Accuracy: 0.673828125\n",
      "Batch: 113, Loss: 1.0568701028823853, Accuracy: 0.669921875\n",
      "Batch: 114, Loss: 1.1764097213745117, Accuracy: 0.6328125\n",
      "Batch: 115, Loss: 1.166851282119751, Accuracy: 0.646484375\n",
      "Batch: 116, Loss: 1.1167547702789307, Accuracy: 0.6494140625\n",
      "Batch: 117, Loss: 1.1411962509155273, Accuracy: 0.650390625\n",
      "Batch: 118, Loss: 0.9288361072540283, Accuracy: 0.703125\n",
      "Batch: 119, Loss: 0.9530858397483826, Accuracy: 0.70703125\n",
      "Batch: 120, Loss: 1.086674690246582, Accuracy: 0.6533203125\n",
      "Batch: 121, Loss: 1.1261235475540161, Accuracy: 0.6416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 122, Loss: 1.0269877910614014, Accuracy: 0.6884765625\n",
      "Batch: 123, Loss: 1.014277458190918, Accuracy: 0.689453125\n",
      "Batch: 124, Loss: 1.105254888534546, Accuracy: 0.6259765625\n",
      "Batch: 125, Loss: 1.1048948764801025, Accuracy: 0.6328125\n",
      "Batch: 126, Loss: 1.0937938690185547, Accuracy: 0.646484375\n",
      "Batch: 127, Loss: 0.9815573692321777, Accuracy: 0.6923828125\n",
      "Batch: 128, Loss: 1.19557785987854, Accuracy: 0.62890625\n",
      "Batch: 129, Loss: 1.00428307056427, Accuracy: 0.677734375\n",
      "Batch: 130, Loss: 1.2002824544906616, Accuracy: 0.6025390625\n",
      "Batch: 131, Loss: 1.121056079864502, Accuracy: 0.64453125\n",
      "Batch: 132, Loss: 1.162264347076416, Accuracy: 0.6142578125\n",
      "Batch: 133, Loss: 0.9962728023529053, Accuracy: 0.66015625\n",
      "Batch: 134, Loss: 1.0995210409164429, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 0.997212290763855, Accuracy: 0.673828125\n",
      "Batch: 136, Loss: 1.0648103952407837, Accuracy: 0.66015625\n",
      "Batch: 137, Loss: 0.9945622086524963, Accuracy: 0.671875\n",
      "Batch: 138, Loss: 0.8617315292358398, Accuracy: 0.705078125\n",
      "Batch: 139, Loss: 0.982434868812561, Accuracy: 0.6796875\n",
      "Batch: 140, Loss: 1.0286999940872192, Accuracy: 0.65625\n",
      "Batch: 141, Loss: 1.0859177112579346, Accuracy: 0.6474609375\n",
      "Batch: 142, Loss: 1.1208370923995972, Accuracy: 0.64453125\n",
      "Batch: 143, Loss: 1.0642468929290771, Accuracy: 0.6533203125\n",
      "Batch: 144, Loss: 1.0709233283996582, Accuracy: 0.65625\n",
      "Batch: 145, Loss: 0.9850912690162659, Accuracy: 0.6708984375\n",
      "Batch: 146, Loss: 1.119300127029419, Accuracy: 0.63671875\n",
      "Batch: 147, Loss: 1.0804436206817627, Accuracy: 0.6396484375\n",
      "Batch: 148, Loss: 1.2027833461761475, Accuracy: 0.6025390625\n",
      "Batch: 149, Loss: 1.0730233192443848, Accuracy: 0.6328125\n",
      "Batch: 150, Loss: 0.9936696290969849, Accuracy: 0.685546875\n",
      "Batch: 151, Loss: 0.9312216639518738, Accuracy: 0.7021484375\n",
      "Epoch 15/90\n",
      "Batch: 1, Loss: 1.2995526790618896, Accuracy: 0.5625\n",
      "Batch: 2, Loss: 1.1173524856567383, Accuracy: 0.615234375\n",
      "Batch: 3, Loss: 0.9878220558166504, Accuracy: 0.6650390625\n",
      "Batch: 4, Loss: 0.9631694555282593, Accuracy: 0.697265625\n",
      "Batch: 5, Loss: 0.9596702456474304, Accuracy: 0.69140625\n",
      "Batch: 6, Loss: 1.055975079536438, Accuracy: 0.65625\n",
      "Batch: 7, Loss: 0.9984160661697388, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 0.9620230793952942, Accuracy: 0.673828125\n",
      "Batch: 9, Loss: 0.9263400435447693, Accuracy: 0.7060546875\n",
      "Batch: 10, Loss: 0.9655332565307617, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 1.1517276763916016, Accuracy: 0.6171875\n",
      "Batch: 12, Loss: 1.1331228017807007, Accuracy: 0.64453125\n",
      "Batch: 13, Loss: 0.9033082723617554, Accuracy: 0.7119140625\n",
      "Batch: 14, Loss: 1.1249033212661743, Accuracy: 0.6357421875\n",
      "Batch: 15, Loss: 0.9578344821929932, Accuracy: 0.7041015625\n",
      "Batch: 16, Loss: 0.9682321548461914, Accuracy: 0.6962890625\n",
      "Batch: 17, Loss: 1.0532362461090088, Accuracy: 0.671875\n",
      "Batch: 18, Loss: 1.0624791383743286, Accuracy: 0.6533203125\n",
      "Batch: 19, Loss: 1.1378555297851562, Accuracy: 0.630859375\n",
      "Batch: 20, Loss: 1.0024126768112183, Accuracy: 0.6787109375\n",
      "Batch: 21, Loss: 0.9959818720817566, Accuracy: 0.6689453125\n",
      "Batch: 22, Loss: 1.1077170372009277, Accuracy: 0.6552734375\n",
      "Batch: 23, Loss: 1.0333242416381836, Accuracy: 0.67578125\n",
      "Batch: 24, Loss: 1.0845954418182373, Accuracy: 0.6484375\n",
      "Batch: 25, Loss: 1.0501954555511475, Accuracy: 0.658203125\n",
      "Batch: 26, Loss: 0.9209762811660767, Accuracy: 0.69921875\n",
      "Batch: 27, Loss: 0.9758070111274719, Accuracy: 0.6767578125\n",
      "Batch: 28, Loss: 1.0849671363830566, Accuracy: 0.634765625\n",
      "Batch: 29, Loss: 1.058100700378418, Accuracy: 0.6552734375\n",
      "Batch: 30, Loss: 1.0148365497589111, Accuracy: 0.6748046875\n",
      "Batch: 31, Loss: 1.0092158317565918, Accuracy: 0.6767578125\n",
      "Batch: 32, Loss: 0.9515318274497986, Accuracy: 0.6884765625\n",
      "Batch: 33, Loss: 1.1345653533935547, Accuracy: 0.638671875\n",
      "Batch: 34, Loss: 1.201645851135254, Accuracy: 0.60546875\n",
      "Batch: 35, Loss: 1.0929113626480103, Accuracy: 0.6474609375\n",
      "Batch: 36, Loss: 1.0902011394500732, Accuracy: 0.6611328125\n",
      "Batch: 37, Loss: 1.0251884460449219, Accuracy: 0.6689453125\n",
      "Batch: 38, Loss: 1.0530202388763428, Accuracy: 0.6572265625\n",
      "Batch: 39, Loss: 1.0749881267547607, Accuracy: 0.6611328125\n",
      "Batch: 40, Loss: 1.0787813663482666, Accuracy: 0.6572265625\n",
      "Batch: 41, Loss: 1.0784194469451904, Accuracy: 0.666015625\n",
      "Batch: 42, Loss: 0.8842982053756714, Accuracy: 0.7138671875\n",
      "Batch: 43, Loss: 1.0807744264602661, Accuracy: 0.6396484375\n",
      "Batch: 44, Loss: 1.0427082777023315, Accuracy: 0.6513671875\n",
      "Batch: 45, Loss: 0.938396692276001, Accuracy: 0.701171875\n",
      "Batch: 46, Loss: 1.0292456150054932, Accuracy: 0.6806640625\n",
      "Batch: 47, Loss: 1.0141345262527466, Accuracy: 0.697265625\n",
      "Batch: 48, Loss: 0.9493960738182068, Accuracy: 0.6923828125\n",
      "Batch: 49, Loss: 1.1801129579544067, Accuracy: 0.6083984375\n",
      "Batch: 50, Loss: 1.1108719110488892, Accuracy: 0.6435546875\n",
      "Batch: 51, Loss: 1.1535632610321045, Accuracy: 0.626953125\n",
      "Batch: 52, Loss: 1.1425367593765259, Accuracy: 0.6298828125\n",
      "Batch: 53, Loss: 0.9411342740058899, Accuracy: 0.685546875\n",
      "Batch: 54, Loss: 1.0337989330291748, Accuracy: 0.6689453125\n",
      "Batch: 55, Loss: 1.0985567569732666, Accuracy: 0.640625\n",
      "Batch: 56, Loss: 1.109883427619934, Accuracy: 0.65625\n",
      "Batch: 57, Loss: 1.0301120281219482, Accuracy: 0.6708984375\n",
      "Batch: 58, Loss: 1.1144413948059082, Accuracy: 0.6533203125\n",
      "Batch: 59, Loss: 0.9920558929443359, Accuracy: 0.6806640625\n",
      "Batch: 60, Loss: 0.9414812326431274, Accuracy: 0.693359375\n",
      "Batch: 61, Loss: 1.0729668140411377, Accuracy: 0.6533203125\n",
      "Batch: 62, Loss: 1.040663719177246, Accuracy: 0.6689453125\n",
      "Batch: 63, Loss: 1.037953495979309, Accuracy: 0.673828125\n",
      "Batch: 64, Loss: 1.0191359519958496, Accuracy: 0.6787109375\n",
      "Batch: 65, Loss: 1.0491725206375122, Accuracy: 0.6748046875\n",
      "Batch: 66, Loss: 0.9861577749252319, Accuracy: 0.6806640625\n",
      "Batch: 67, Loss: 1.1098097562789917, Accuracy: 0.6396484375\n",
      "Batch: 68, Loss: 1.159693717956543, Accuracy: 0.6376953125\n",
      "Batch: 69, Loss: 1.0744562149047852, Accuracy: 0.646484375\n",
      "Batch: 70, Loss: 1.0450241565704346, Accuracy: 0.662109375\n",
      "Batch: 71, Loss: 1.06972336769104, Accuracy: 0.654296875\n",
      "Batch: 72, Loss: 0.916923999786377, Accuracy: 0.701171875\n",
      "Batch: 73, Loss: 0.9914630055427551, Accuracy: 0.6875\n",
      "Batch: 74, Loss: 0.9485964775085449, Accuracy: 0.6962890625\n",
      "Batch: 75, Loss: 0.9357473850250244, Accuracy: 0.6962890625\n",
      "Batch: 76, Loss: 1.0476326942443848, Accuracy: 0.6484375\n",
      "Batch: 77, Loss: 0.9959015250205994, Accuracy: 0.669921875\n",
      "Batch: 78, Loss: 1.0284461975097656, Accuracy: 0.6806640625\n",
      "Batch: 79, Loss: 0.9523729085922241, Accuracy: 0.7158203125\n",
      "Batch: 80, Loss: 0.9787534475326538, Accuracy: 0.669921875\n",
      "Batch: 81, Loss: 1.100694179534912, Accuracy: 0.63671875\n",
      "Batch: 82, Loss: 1.063088059425354, Accuracy: 0.671875\n",
      "Batch: 83, Loss: 0.9233651161193848, Accuracy: 0.7099609375\n",
      "Batch: 84, Loss: 0.9964152574539185, Accuracy: 0.6796875\n",
      "Batch: 85, Loss: 0.9156972169876099, Accuracy: 0.6943359375\n",
      "Batch: 86, Loss: 1.1714860200881958, Accuracy: 0.6337890625\n",
      "Batch: 87, Loss: 0.9482604265213013, Accuracy: 0.712890625\n",
      "Batch: 88, Loss: 1.092313528060913, Accuracy: 0.6630859375\n",
      "Batch: 89, Loss: 1.073991060256958, Accuracy: 0.6748046875\n",
      "Batch: 90, Loss: 0.9651204347610474, Accuracy: 0.6884765625\n",
      "Batch: 91, Loss: 1.0538878440856934, Accuracy: 0.6650390625\n",
      "Batch: 92, Loss: 1.0359452962875366, Accuracy: 0.6748046875\n",
      "Batch: 93, Loss: 1.002247929573059, Accuracy: 0.685546875\n",
      "Batch: 94, Loss: 0.9898697137832642, Accuracy: 0.6806640625\n",
      "Batch: 95, Loss: 1.0565755367279053, Accuracy: 0.63671875\n",
      "Batch: 96, Loss: 0.9962359666824341, Accuracy: 0.67578125\n",
      "Batch: 97, Loss: 0.9200912714004517, Accuracy: 0.6962890625\n",
      "Batch: 98, Loss: 0.9382960796356201, Accuracy: 0.7041015625\n",
      "Batch: 99, Loss: 0.9392774105072021, Accuracy: 0.6904296875\n",
      "Batch: 100, Loss: 0.9846616387367249, Accuracy: 0.689453125\n",
      "Batch: 101, Loss: 1.0723843574523926, Accuracy: 0.6513671875\n",
      "Batch: 102, Loss: 0.9756293296813965, Accuracy: 0.6904296875\n",
      "Batch: 103, Loss: 1.0915915966033936, Accuracy: 0.6689453125\n",
      "Batch: 104, Loss: 0.9595149755477905, Accuracy: 0.6748046875\n",
      "Batch: 105, Loss: 1.0514663457870483, Accuracy: 0.650390625\n",
      "Batch: 106, Loss: 1.02567720413208, Accuracy: 0.677734375\n",
      "Batch: 107, Loss: 1.0976507663726807, Accuracy: 0.6552734375\n",
      "Batch: 108, Loss: 1.0252306461334229, Accuracy: 0.6611328125\n",
      "Batch: 109, Loss: 1.1390907764434814, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 110, Loss: 0.8858123421669006, Accuracy: 0.70703125\n",
      "Batch: 111, Loss: 1.059347152709961, Accuracy: 0.6357421875\n",
      "Batch: 112, Loss: 1.0264050960540771, Accuracy: 0.685546875\n",
      "Batch: 113, Loss: 1.0335419178009033, Accuracy: 0.6669921875\n",
      "Batch: 114, Loss: 1.1260719299316406, Accuracy: 0.6533203125\n",
      "Batch: 115, Loss: 1.1628077030181885, Accuracy: 0.6435546875\n",
      "Batch: 116, Loss: 1.1024049520492554, Accuracy: 0.6416015625\n",
      "Batch: 117, Loss: 1.1454133987426758, Accuracy: 0.64453125\n",
      "Batch: 118, Loss: 0.9125255346298218, Accuracy: 0.712890625\n",
      "Batch: 119, Loss: 0.9545254707336426, Accuracy: 0.6962890625\n",
      "Batch: 120, Loss: 1.08188796043396, Accuracy: 0.662109375\n",
      "Batch: 121, Loss: 1.0867842435836792, Accuracy: 0.65234375\n",
      "Batch: 122, Loss: 1.0114282369613647, Accuracy: 0.6728515625\n",
      "Batch: 123, Loss: 1.002921462059021, Accuracy: 0.6962890625\n",
      "Batch: 124, Loss: 1.0705286264419556, Accuracy: 0.65625\n",
      "Batch: 125, Loss: 1.0672324895858765, Accuracy: 0.6552734375\n",
      "Batch: 126, Loss: 1.0744094848632812, Accuracy: 0.634765625\n",
      "Batch: 127, Loss: 0.9434695243835449, Accuracy: 0.705078125\n",
      "Batch: 128, Loss: 1.1466648578643799, Accuracy: 0.646484375\n",
      "Batch: 129, Loss: 0.9861676096916199, Accuracy: 0.677734375\n",
      "Batch: 130, Loss: 1.1890441179275513, Accuracy: 0.615234375\n",
      "Batch: 131, Loss: 1.0947656631469727, Accuracy: 0.6494140625\n",
      "Batch: 132, Loss: 1.1021273136138916, Accuracy: 0.6435546875\n",
      "Batch: 133, Loss: 0.995729923248291, Accuracy: 0.6748046875\n",
      "Batch: 134, Loss: 1.0759341716766357, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 0.9931434988975525, Accuracy: 0.681640625\n",
      "Batch: 136, Loss: 1.0564926862716675, Accuracy: 0.6689453125\n",
      "Batch: 137, Loss: 0.9603029489517212, Accuracy: 0.6787109375\n",
      "Batch: 138, Loss: 0.8673361539840698, Accuracy: 0.71484375\n",
      "Batch: 139, Loss: 0.9668511152267456, Accuracy: 0.6904296875\n",
      "Batch: 140, Loss: 1.0515568256378174, Accuracy: 0.666015625\n",
      "Batch: 141, Loss: 1.0363459587097168, Accuracy: 0.6552734375\n",
      "Batch: 142, Loss: 1.074742078781128, Accuracy: 0.65625\n",
      "Batch: 143, Loss: 1.0601916313171387, Accuracy: 0.654296875\n",
      "Batch: 144, Loss: 1.04268217086792, Accuracy: 0.66796875\n",
      "Batch: 145, Loss: 0.9896764755249023, Accuracy: 0.6533203125\n",
      "Batch: 146, Loss: 1.0949472188949585, Accuracy: 0.630859375\n",
      "Batch: 147, Loss: 1.0474729537963867, Accuracy: 0.65625\n",
      "Batch: 148, Loss: 1.156162142753601, Accuracy: 0.6201171875\n",
      "Batch: 149, Loss: 1.048574686050415, Accuracy: 0.6474609375\n",
      "Batch: 150, Loss: 0.969304621219635, Accuracy: 0.6796875\n",
      "Batch: 151, Loss: 0.8997790813446045, Accuracy: 0.7060546875\n",
      "Epoch 16/90\n",
      "Batch: 1, Loss: 1.3191360235214233, Accuracy: 0.57421875\n",
      "Batch: 2, Loss: 1.108054280281067, Accuracy: 0.6259765625\n",
      "Batch: 3, Loss: 0.9824224710464478, Accuracy: 0.669921875\n",
      "Batch: 4, Loss: 0.947137713432312, Accuracy: 0.7060546875\n",
      "Batch: 5, Loss: 0.9337807297706604, Accuracy: 0.7021484375\n",
      "Batch: 6, Loss: 1.0479246377944946, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 0.985864520072937, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 0.9144793748855591, Accuracy: 0.693359375\n",
      "Batch: 9, Loss: 0.896030068397522, Accuracy: 0.72265625\n",
      "Batch: 10, Loss: 0.9411802291870117, Accuracy: 0.7021484375\n",
      "Batch: 11, Loss: 1.1111785173416138, Accuracy: 0.6298828125\n",
      "Batch: 12, Loss: 1.1244354248046875, Accuracy: 0.634765625\n",
      "Batch: 13, Loss: 0.8830022215843201, Accuracy: 0.70703125\n",
      "Batch: 14, Loss: 1.12111234664917, Accuracy: 0.6201171875\n",
      "Batch: 15, Loss: 0.9255775213241577, Accuracy: 0.70703125\n",
      "Batch: 16, Loss: 0.9504823684692383, Accuracy: 0.6962890625\n",
      "Batch: 17, Loss: 1.0336061716079712, Accuracy: 0.671875\n",
      "Batch: 18, Loss: 1.0696182250976562, Accuracy: 0.66015625\n",
      "Batch: 19, Loss: 1.1288094520568848, Accuracy: 0.64453125\n",
      "Batch: 20, Loss: 0.9602415561676025, Accuracy: 0.69140625\n",
      "Batch: 21, Loss: 0.9799293875694275, Accuracy: 0.681640625\n",
      "Batch: 22, Loss: 1.0737595558166504, Accuracy: 0.6552734375\n",
      "Batch: 23, Loss: 1.010401964187622, Accuracy: 0.6689453125\n",
      "Batch: 24, Loss: 1.049599289894104, Accuracy: 0.6513671875\n",
      "Batch: 25, Loss: 1.0159014463424683, Accuracy: 0.66796875\n",
      "Batch: 26, Loss: 0.9179989695549011, Accuracy: 0.6884765625\n",
      "Batch: 27, Loss: 0.9444655179977417, Accuracy: 0.6748046875\n",
      "Batch: 28, Loss: 1.0811958312988281, Accuracy: 0.640625\n",
      "Batch: 29, Loss: 1.033939003944397, Accuracy: 0.6689453125\n",
      "Batch: 30, Loss: 0.9658738374710083, Accuracy: 0.6962890625\n",
      "Batch: 31, Loss: 0.9720297455787659, Accuracy: 0.6875\n",
      "Batch: 32, Loss: 0.942258894443512, Accuracy: 0.6884765625\n",
      "Batch: 33, Loss: 1.0935046672821045, Accuracy: 0.6533203125\n",
      "Batch: 34, Loss: 1.1730058193206787, Accuracy: 0.626953125\n",
      "Batch: 35, Loss: 1.071083426475525, Accuracy: 0.6435546875\n",
      "Batch: 36, Loss: 1.064624547958374, Accuracy: 0.6689453125\n",
      "Batch: 37, Loss: 1.0098702907562256, Accuracy: 0.6796875\n",
      "Batch: 38, Loss: 1.036539077758789, Accuracy: 0.6650390625\n",
      "Batch: 39, Loss: 1.0444525480270386, Accuracy: 0.673828125\n",
      "Batch: 40, Loss: 1.052487850189209, Accuracy: 0.6552734375\n",
      "Batch: 41, Loss: 1.062408447265625, Accuracy: 0.677734375\n",
      "Batch: 42, Loss: 0.8334606885910034, Accuracy: 0.73046875\n",
      "Batch: 43, Loss: 1.0571650266647339, Accuracy: 0.6669921875\n",
      "Batch: 44, Loss: 1.0365009307861328, Accuracy: 0.6494140625\n",
      "Batch: 45, Loss: 0.9024946093559265, Accuracy: 0.703125\n",
      "Batch: 46, Loss: 0.9989473223686218, Accuracy: 0.681640625\n",
      "Batch: 47, Loss: 0.9922931790351868, Accuracy: 0.701171875\n",
      "Batch: 48, Loss: 0.9227688312530518, Accuracy: 0.6884765625\n",
      "Batch: 49, Loss: 1.1087651252746582, Accuracy: 0.6337890625\n",
      "Batch: 50, Loss: 1.0881068706512451, Accuracy: 0.666015625\n",
      "Batch: 51, Loss: 1.1359868049621582, Accuracy: 0.630859375\n",
      "Batch: 52, Loss: 1.095167636871338, Accuracy: 0.6513671875\n",
      "Batch: 53, Loss: 0.9379701018333435, Accuracy: 0.689453125\n",
      "Batch: 54, Loss: 1.0048439502716064, Accuracy: 0.6904296875\n",
      "Batch: 55, Loss: 1.0738121271133423, Accuracy: 0.6455078125\n",
      "Batch: 56, Loss: 1.05812406539917, Accuracy: 0.662109375\n",
      "Batch: 57, Loss: 1.0221030712127686, Accuracy: 0.6708984375\n",
      "Batch: 58, Loss: 1.0932190418243408, Accuracy: 0.66015625\n",
      "Batch: 59, Loss: 0.9596249461174011, Accuracy: 0.701171875\n",
      "Batch: 60, Loss: 0.920005202293396, Accuracy: 0.7021484375\n",
      "Batch: 61, Loss: 1.0218443870544434, Accuracy: 0.6640625\n",
      "Batch: 62, Loss: 0.9989745616912842, Accuracy: 0.669921875\n",
      "Batch: 63, Loss: 1.0152184963226318, Accuracy: 0.681640625\n",
      "Batch: 64, Loss: 0.9781444668769836, Accuracy: 0.6748046875\n",
      "Batch: 65, Loss: 1.0189954042434692, Accuracy: 0.689453125\n",
      "Batch: 66, Loss: 0.9604299068450928, Accuracy: 0.6982421875\n",
      "Batch: 67, Loss: 1.0937533378601074, Accuracy: 0.6591796875\n",
      "Batch: 68, Loss: 1.1252093315124512, Accuracy: 0.642578125\n",
      "Batch: 69, Loss: 1.0496073961257935, Accuracy: 0.6513671875\n",
      "Batch: 70, Loss: 1.011624813079834, Accuracy: 0.681640625\n",
      "Batch: 71, Loss: 1.02896249294281, Accuracy: 0.6669921875\n",
      "Batch: 72, Loss: 0.8833022117614746, Accuracy: 0.7119140625\n",
      "Batch: 73, Loss: 0.9579873085021973, Accuracy: 0.7021484375\n",
      "Batch: 74, Loss: 0.9475229978561401, Accuracy: 0.705078125\n",
      "Batch: 75, Loss: 0.9063864946365356, Accuracy: 0.70703125\n",
      "Batch: 76, Loss: 1.0055381059646606, Accuracy: 0.681640625\n",
      "Batch: 77, Loss: 0.9617449045181274, Accuracy: 0.68359375\n",
      "Batch: 78, Loss: 0.971503734588623, Accuracy: 0.685546875\n",
      "Batch: 79, Loss: 0.8901084661483765, Accuracy: 0.736328125\n",
      "Batch: 80, Loss: 0.9468019008636475, Accuracy: 0.66015625\n",
      "Batch: 81, Loss: 1.04703950881958, Accuracy: 0.642578125\n",
      "Batch: 82, Loss: 1.044925332069397, Accuracy: 0.673828125\n",
      "Batch: 83, Loss: 0.9117554426193237, Accuracy: 0.708984375\n",
      "Batch: 84, Loss: 1.0006009340286255, Accuracy: 0.689453125\n",
      "Batch: 85, Loss: 0.9179036617279053, Accuracy: 0.705078125\n",
      "Batch: 86, Loss: 1.1576018333435059, Accuracy: 0.625\n",
      "Batch: 87, Loss: 0.9500770568847656, Accuracy: 0.7060546875\n",
      "Batch: 88, Loss: 1.0791232585906982, Accuracy: 0.666015625\n",
      "Batch: 89, Loss: 1.0619025230407715, Accuracy: 0.658203125\n",
      "Batch: 90, Loss: 0.9409257173538208, Accuracy: 0.703125\n",
      "Batch: 91, Loss: 1.0072154998779297, Accuracy: 0.6787109375\n",
      "Batch: 92, Loss: 1.004241943359375, Accuracy: 0.671875\n",
      "Batch: 93, Loss: 0.9833722710609436, Accuracy: 0.6826171875\n",
      "Batch: 94, Loss: 0.9953641891479492, Accuracy: 0.6884765625\n",
      "Batch: 95, Loss: 1.0437287092208862, Accuracy: 0.6455078125\n",
      "Batch: 96, Loss: 0.9909002184867859, Accuracy: 0.67578125\n",
      "Batch: 97, Loss: 0.9088172912597656, Accuracy: 0.69921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 98, Loss: 0.9459555149078369, Accuracy: 0.701171875\n",
      "Batch: 99, Loss: 0.9142017960548401, Accuracy: 0.69921875\n",
      "Batch: 100, Loss: 0.9677934646606445, Accuracy: 0.6884765625\n",
      "Batch: 101, Loss: 1.052929162979126, Accuracy: 0.6513671875\n",
      "Batch: 102, Loss: 0.9745465517044067, Accuracy: 0.6787109375\n",
      "Batch: 103, Loss: 1.0550180673599243, Accuracy: 0.6689453125\n",
      "Batch: 104, Loss: 0.9409413933753967, Accuracy: 0.68359375\n",
      "Batch: 105, Loss: 1.032366156578064, Accuracy: 0.6669921875\n",
      "Batch: 106, Loss: 0.9993053674697876, Accuracy: 0.685546875\n",
      "Batch: 107, Loss: 1.0675135850906372, Accuracy: 0.6611328125\n",
      "Batch: 108, Loss: 1.0038182735443115, Accuracy: 0.669921875\n",
      "Batch: 109, Loss: 1.1378910541534424, Accuracy: 0.630859375\n",
      "Batch: 110, Loss: 0.8786776661872864, Accuracy: 0.720703125\n",
      "Batch: 111, Loss: 1.0708436965942383, Accuracy: 0.6396484375\n",
      "Batch: 112, Loss: 1.0047826766967773, Accuracy: 0.681640625\n",
      "Batch: 113, Loss: 1.01200270652771, Accuracy: 0.6826171875\n",
      "Batch: 114, Loss: 1.1326525211334229, Accuracy: 0.6298828125\n",
      "Batch: 115, Loss: 1.1330935955047607, Accuracy: 0.654296875\n",
      "Batch: 116, Loss: 1.097639799118042, Accuracy: 0.6552734375\n",
      "Batch: 117, Loss: 1.1078600883483887, Accuracy: 0.650390625\n",
      "Batch: 118, Loss: 0.916326105594635, Accuracy: 0.708984375\n",
      "Batch: 119, Loss: 0.9181027412414551, Accuracy: 0.7119140625\n",
      "Batch: 120, Loss: 1.049595832824707, Accuracy: 0.66796875\n",
      "Batch: 121, Loss: 1.0749374628067017, Accuracy: 0.6337890625\n",
      "Batch: 122, Loss: 0.9644767642021179, Accuracy: 0.685546875\n",
      "Batch: 123, Loss: 0.9588975310325623, Accuracy: 0.70703125\n",
      "Batch: 124, Loss: 1.0567893981933594, Accuracy: 0.658203125\n",
      "Batch: 125, Loss: 1.064573049545288, Accuracy: 0.6474609375\n",
      "Batch: 126, Loss: 1.0442392826080322, Accuracy: 0.6513671875\n",
      "Batch: 127, Loss: 0.9315681457519531, Accuracy: 0.70703125\n",
      "Batch: 128, Loss: 1.1124577522277832, Accuracy: 0.65234375\n",
      "Batch: 129, Loss: 0.9628918766975403, Accuracy: 0.6953125\n",
      "Batch: 130, Loss: 1.1604173183441162, Accuracy: 0.619140625\n",
      "Batch: 131, Loss: 1.0702323913574219, Accuracy: 0.640625\n",
      "Batch: 132, Loss: 1.0965880155563354, Accuracy: 0.65625\n",
      "Batch: 133, Loss: 0.9720122814178467, Accuracy: 0.6728515625\n",
      "Batch: 134, Loss: 1.0425245761871338, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 0.9679956436157227, Accuracy: 0.689453125\n",
      "Batch: 136, Loss: 1.0494831800460815, Accuracy: 0.681640625\n",
      "Batch: 137, Loss: 0.9501432180404663, Accuracy: 0.673828125\n",
      "Batch: 138, Loss: 0.854351282119751, Accuracy: 0.70703125\n",
      "Batch: 139, Loss: 0.9412530660629272, Accuracy: 0.70703125\n",
      "Batch: 140, Loss: 0.9961515665054321, Accuracy: 0.6650390625\n",
      "Batch: 141, Loss: 1.0311833620071411, Accuracy: 0.6591796875\n",
      "Batch: 142, Loss: 1.0585601329803467, Accuracy: 0.662109375\n",
      "Batch: 143, Loss: 1.0407675504684448, Accuracy: 0.65625\n",
      "Batch: 144, Loss: 1.0091938972473145, Accuracy: 0.669921875\n",
      "Batch: 145, Loss: 0.9667187333106995, Accuracy: 0.654296875\n",
      "Batch: 146, Loss: 1.0441443920135498, Accuracy: 0.65625\n",
      "Batch: 147, Loss: 1.0095773935317993, Accuracy: 0.65625\n",
      "Batch: 148, Loss: 1.162527084350586, Accuracy: 0.6181640625\n",
      "Batch: 149, Loss: 1.0033766031265259, Accuracy: 0.6640625\n",
      "Batch: 150, Loss: 0.9550793170928955, Accuracy: 0.6787109375\n",
      "Batch: 151, Loss: 0.889775276184082, Accuracy: 0.7294921875\n",
      "Epoch 17/90\n",
      "Batch: 1, Loss: 1.276574969291687, Accuracy: 0.5791015625\n",
      "Batch: 2, Loss: 1.098781943321228, Accuracy: 0.6396484375\n",
      "Batch: 3, Loss: 0.9774653911590576, Accuracy: 0.6728515625\n",
      "Batch: 4, Loss: 0.9102091193199158, Accuracy: 0.7197265625\n",
      "Batch: 5, Loss: 0.9070296287536621, Accuracy: 0.7021484375\n",
      "Batch: 6, Loss: 1.0063343048095703, Accuracy: 0.6669921875\n",
      "Batch: 7, Loss: 0.9620102047920227, Accuracy: 0.6728515625\n",
      "Batch: 8, Loss: 0.9105039834976196, Accuracy: 0.693359375\n",
      "Batch: 9, Loss: 0.9160023927688599, Accuracy: 0.7060546875\n",
      "Batch: 10, Loss: 0.8980646729469299, Accuracy: 0.7099609375\n",
      "Batch: 11, Loss: 1.0951526165008545, Accuracy: 0.626953125\n",
      "Batch: 12, Loss: 1.0810483694076538, Accuracy: 0.6494140625\n",
      "Batch: 13, Loss: 0.8471184968948364, Accuracy: 0.734375\n",
      "Batch: 14, Loss: 1.0981483459472656, Accuracy: 0.638671875\n",
      "Batch: 15, Loss: 0.9434314966201782, Accuracy: 0.712890625\n",
      "Batch: 16, Loss: 0.9335324764251709, Accuracy: 0.6982421875\n",
      "Batch: 17, Loss: 1.0243877172470093, Accuracy: 0.6689453125\n",
      "Batch: 18, Loss: 1.0333173274993896, Accuracy: 0.6650390625\n",
      "Batch: 19, Loss: 1.1040985584259033, Accuracy: 0.6455078125\n",
      "Batch: 20, Loss: 0.9213171005249023, Accuracy: 0.7099609375\n",
      "Batch: 21, Loss: 0.9539000391960144, Accuracy: 0.69921875\n",
      "Batch: 22, Loss: 1.0536389350891113, Accuracy: 0.6689453125\n",
      "Batch: 23, Loss: 0.9964150190353394, Accuracy: 0.6767578125\n",
      "Batch: 24, Loss: 1.0214531421661377, Accuracy: 0.6572265625\n",
      "Batch: 25, Loss: 0.9960536360740662, Accuracy: 0.689453125\n",
      "Batch: 26, Loss: 0.8886227607727051, Accuracy: 0.7138671875\n",
      "Batch: 27, Loss: 0.9361697435379028, Accuracy: 0.685546875\n",
      "Batch: 28, Loss: 1.034759283065796, Accuracy: 0.6572265625\n",
      "Batch: 29, Loss: 1.0119115114212036, Accuracy: 0.6669921875\n",
      "Batch: 30, Loss: 0.934678316116333, Accuracy: 0.7021484375\n",
      "Batch: 31, Loss: 0.9385718107223511, Accuracy: 0.697265625\n",
      "Batch: 32, Loss: 0.9071874618530273, Accuracy: 0.701171875\n",
      "Batch: 33, Loss: 1.093593716621399, Accuracy: 0.65234375\n",
      "Batch: 34, Loss: 1.1424806118011475, Accuracy: 0.6455078125\n",
      "Batch: 35, Loss: 1.0489134788513184, Accuracy: 0.6669921875\n",
      "Batch: 36, Loss: 1.0614995956420898, Accuracy: 0.68359375\n",
      "Batch: 37, Loss: 0.978501558303833, Accuracy: 0.6865234375\n",
      "Batch: 38, Loss: 1.0131511688232422, Accuracy: 0.6796875\n",
      "Batch: 39, Loss: 1.0236607789993286, Accuracy: 0.6591796875\n",
      "Batch: 40, Loss: 1.041280746459961, Accuracy: 0.6904296875\n",
      "Batch: 41, Loss: 0.9869515895843506, Accuracy: 0.681640625\n",
      "Batch: 42, Loss: 0.7955222129821777, Accuracy: 0.7275390625\n",
      "Batch: 43, Loss: 1.0372637510299683, Accuracy: 0.6513671875\n",
      "Batch: 44, Loss: 1.0141913890838623, Accuracy: 0.66796875\n",
      "Batch: 45, Loss: 0.9055604934692383, Accuracy: 0.712890625\n",
      "Batch: 46, Loss: 0.980952799320221, Accuracy: 0.6884765625\n",
      "Batch: 47, Loss: 0.951895534992218, Accuracy: 0.703125\n",
      "Batch: 48, Loss: 0.9074525833129883, Accuracy: 0.6943359375\n",
      "Batch: 49, Loss: 1.0958847999572754, Accuracy: 0.6552734375\n",
      "Batch: 50, Loss: 1.0541332960128784, Accuracy: 0.66015625\n",
      "Batch: 51, Loss: 1.0990043878555298, Accuracy: 0.646484375\n",
      "Batch: 52, Loss: 1.092260718345642, Accuracy: 0.6533203125\n",
      "Batch: 53, Loss: 0.9010080099105835, Accuracy: 0.701171875\n",
      "Batch: 54, Loss: 0.9770181775093079, Accuracy: 0.685546875\n",
      "Batch: 55, Loss: 1.068459153175354, Accuracy: 0.6572265625\n",
      "Batch: 56, Loss: 1.0610796213150024, Accuracy: 0.6669921875\n",
      "Batch: 57, Loss: 0.9810481071472168, Accuracy: 0.68359375\n",
      "Batch: 58, Loss: 1.084704041481018, Accuracy: 0.6572265625\n",
      "Batch: 59, Loss: 0.953079879283905, Accuracy: 0.71875\n",
      "Batch: 60, Loss: 0.8928223848342896, Accuracy: 0.7060546875\n",
      "Batch: 61, Loss: 1.0202655792236328, Accuracy: 0.677734375\n",
      "Batch: 62, Loss: 0.9808312654495239, Accuracy: 0.677734375\n",
      "Batch: 63, Loss: 0.9997838139533997, Accuracy: 0.67578125\n",
      "Batch: 64, Loss: 0.977250337600708, Accuracy: 0.68359375\n",
      "Batch: 65, Loss: 1.0120067596435547, Accuracy: 0.673828125\n",
      "Batch: 66, Loss: 0.9421974420547485, Accuracy: 0.701171875\n",
      "Batch: 67, Loss: 1.0598293542861938, Accuracy: 0.6650390625\n",
      "Batch: 68, Loss: 1.0848053693771362, Accuracy: 0.6572265625\n",
      "Batch: 69, Loss: 1.027775526046753, Accuracy: 0.6669921875\n",
      "Batch: 70, Loss: 0.9685511589050293, Accuracy: 0.69921875\n",
      "Batch: 71, Loss: 1.01179838180542, Accuracy: 0.6796875\n",
      "Batch: 72, Loss: 0.8899585008621216, Accuracy: 0.7099609375\n",
      "Batch: 73, Loss: 0.944609522819519, Accuracy: 0.7021484375\n",
      "Batch: 74, Loss: 0.9205160140991211, Accuracy: 0.7021484375\n",
      "Batch: 75, Loss: 0.8852369785308838, Accuracy: 0.712890625\n",
      "Batch: 76, Loss: 0.9991400241851807, Accuracy: 0.6689453125\n",
      "Batch: 77, Loss: 0.9428859353065491, Accuracy: 0.6943359375\n",
      "Batch: 78, Loss: 0.9547445774078369, Accuracy: 0.6923828125\n",
      "Batch: 79, Loss: 0.8949516415596008, Accuracy: 0.7294921875\n",
      "Batch: 80, Loss: 0.9394873380661011, Accuracy: 0.6806640625\n",
      "Batch: 81, Loss: 1.0668365955352783, Accuracy: 0.6396484375\n",
      "Batch: 82, Loss: 1.047485589981079, Accuracy: 0.6748046875\n",
      "Batch: 83, Loss: 0.8871748447418213, Accuracy: 0.71875\n",
      "Batch: 84, Loss: 0.9592294096946716, Accuracy: 0.6875\n",
      "Batch: 85, Loss: 0.8763645887374878, Accuracy: 0.72265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 86, Loss: 1.134826421737671, Accuracy: 0.6455078125\n",
      "Batch: 87, Loss: 0.9114013910293579, Accuracy: 0.7197265625\n",
      "Batch: 88, Loss: 1.0395660400390625, Accuracy: 0.68359375\n",
      "Batch: 89, Loss: 1.0405128002166748, Accuracy: 0.67578125\n",
      "Batch: 90, Loss: 0.9167289733886719, Accuracy: 0.7119140625\n",
      "Batch: 91, Loss: 1.0055770874023438, Accuracy: 0.673828125\n",
      "Batch: 92, Loss: 0.9881531596183777, Accuracy: 0.6767578125\n",
      "Batch: 93, Loss: 0.9555017948150635, Accuracy: 0.697265625\n",
      "Batch: 94, Loss: 0.9382466077804565, Accuracy: 0.68359375\n",
      "Batch: 95, Loss: 1.0145859718322754, Accuracy: 0.6611328125\n",
      "Batch: 96, Loss: 0.9522666931152344, Accuracy: 0.6943359375\n",
      "Batch: 97, Loss: 0.8528400659561157, Accuracy: 0.7265625\n",
      "Batch: 98, Loss: 0.9122035503387451, Accuracy: 0.720703125\n",
      "Batch: 99, Loss: 0.89814293384552, Accuracy: 0.701171875\n",
      "Batch: 100, Loss: 0.9161167740821838, Accuracy: 0.6943359375\n",
      "Batch: 101, Loss: 1.033023715019226, Accuracy: 0.66015625\n",
      "Batch: 102, Loss: 0.9329366683959961, Accuracy: 0.6943359375\n",
      "Batch: 103, Loss: 1.0290135145187378, Accuracy: 0.6806640625\n",
      "Batch: 104, Loss: 0.9232953190803528, Accuracy: 0.701171875\n",
      "Batch: 105, Loss: 1.0015549659729004, Accuracy: 0.681640625\n",
      "Batch: 106, Loss: 0.9778528213500977, Accuracy: 0.689453125\n",
      "Batch: 107, Loss: 1.0216147899627686, Accuracy: 0.6865234375\n",
      "Batch: 108, Loss: 0.9744588136672974, Accuracy: 0.6708984375\n",
      "Batch: 109, Loss: 1.0796772241592407, Accuracy: 0.6376953125\n",
      "Batch: 110, Loss: 0.8523818254470825, Accuracy: 0.71875\n",
      "Batch: 111, Loss: 1.0268504619598389, Accuracy: 0.65625\n",
      "Batch: 112, Loss: 1.0036091804504395, Accuracy: 0.6875\n",
      "Batch: 113, Loss: 0.9741041660308838, Accuracy: 0.7021484375\n",
      "Batch: 114, Loss: 1.0925345420837402, Accuracy: 0.6513671875\n",
      "Batch: 115, Loss: 1.1074988842010498, Accuracy: 0.666015625\n",
      "Batch: 116, Loss: 1.0692187547683716, Accuracy: 0.6494140625\n",
      "Batch: 117, Loss: 1.0794975757598877, Accuracy: 0.6572265625\n",
      "Batch: 118, Loss: 0.896233856678009, Accuracy: 0.7197265625\n",
      "Batch: 119, Loss: 0.8961591124534607, Accuracy: 0.720703125\n",
      "Batch: 120, Loss: 1.0320407152175903, Accuracy: 0.6640625\n",
      "Batch: 121, Loss: 1.0195823907852173, Accuracy: 0.66796875\n",
      "Batch: 122, Loss: 0.9695795774459839, Accuracy: 0.7080078125\n",
      "Batch: 123, Loss: 0.9512958526611328, Accuracy: 0.69921875\n",
      "Batch: 124, Loss: 1.0246299505233765, Accuracy: 0.6708984375\n",
      "Batch: 125, Loss: 1.0114696025848389, Accuracy: 0.68359375\n",
      "Batch: 126, Loss: 1.0193663835525513, Accuracy: 0.6572265625\n",
      "Batch: 127, Loss: 0.9005369544029236, Accuracy: 0.71875\n",
      "Batch: 128, Loss: 1.1152453422546387, Accuracy: 0.6455078125\n",
      "Batch: 129, Loss: 0.9406369924545288, Accuracy: 0.7060546875\n",
      "Batch: 130, Loss: 1.1357018947601318, Accuracy: 0.62890625\n",
      "Batch: 131, Loss: 1.060459852218628, Accuracy: 0.65234375\n",
      "Batch: 132, Loss: 1.063110113143921, Accuracy: 0.66015625\n",
      "Batch: 133, Loss: 0.9462708234786987, Accuracy: 0.6767578125\n",
      "Batch: 134, Loss: 1.0471391677856445, Accuracy: 0.6689453125\n",
      "Batch: 135, Loss: 0.9197977185249329, Accuracy: 0.7109375\n",
      "Batch: 136, Loss: 1.0073351860046387, Accuracy: 0.6943359375\n",
      "Batch: 137, Loss: 0.9316649436950684, Accuracy: 0.69140625\n",
      "Batch: 138, Loss: 0.8394519090652466, Accuracy: 0.71484375\n",
      "Batch: 139, Loss: 0.9014982581138611, Accuracy: 0.7099609375\n",
      "Batch: 140, Loss: 0.9702532291412354, Accuracy: 0.6796875\n",
      "Batch: 141, Loss: 1.0146163702011108, Accuracy: 0.6748046875\n",
      "Batch: 142, Loss: 1.0318952798843384, Accuracy: 0.6591796875\n",
      "Batch: 143, Loss: 1.0097743272781372, Accuracy: 0.66796875\n",
      "Batch: 144, Loss: 0.9956342577934265, Accuracy: 0.6787109375\n",
      "Batch: 145, Loss: 0.9202266931533813, Accuracy: 0.6806640625\n",
      "Batch: 146, Loss: 1.0363690853118896, Accuracy: 0.6552734375\n",
      "Batch: 147, Loss: 1.0054622888565063, Accuracy: 0.6708984375\n",
      "Batch: 148, Loss: 1.1122759580612183, Accuracy: 0.6298828125\n",
      "Batch: 149, Loss: 1.001164436340332, Accuracy: 0.6640625\n",
      "Batch: 150, Loss: 0.9489471912384033, Accuracy: 0.689453125\n",
      "Batch: 151, Loss: 0.8443537950515747, Accuracy: 0.7275390625\n",
      "Epoch 18/90\n",
      "Batch: 1, Loss: 1.2364959716796875, Accuracy: 0.6025390625\n",
      "Batch: 2, Loss: 1.0752134323120117, Accuracy: 0.63671875\n",
      "Batch: 3, Loss: 0.9300060272216797, Accuracy: 0.6845703125\n",
      "Batch: 4, Loss: 0.9001721143722534, Accuracy: 0.708984375\n",
      "Batch: 5, Loss: 0.8533656597137451, Accuracy: 0.7275390625\n",
      "Batch: 6, Loss: 0.9833325147628784, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 0.9491071701049805, Accuracy: 0.6962890625\n",
      "Batch: 8, Loss: 0.8865621089935303, Accuracy: 0.7041015625\n",
      "Batch: 9, Loss: 0.8821669816970825, Accuracy: 0.724609375\n",
      "Batch: 10, Loss: 0.8877196907997131, Accuracy: 0.7158203125\n",
      "Batch: 11, Loss: 1.061678409576416, Accuracy: 0.6474609375\n",
      "Batch: 12, Loss: 1.0726776123046875, Accuracy: 0.6513671875\n",
      "Batch: 13, Loss: 0.8245573043823242, Accuracy: 0.728515625\n",
      "Batch: 14, Loss: 1.0718255043029785, Accuracy: 0.6455078125\n",
      "Batch: 15, Loss: 0.9133063554763794, Accuracy: 0.7080078125\n",
      "Batch: 16, Loss: 0.9222330451011658, Accuracy: 0.6884765625\n",
      "Batch: 17, Loss: 0.9830851554870605, Accuracy: 0.6845703125\n",
      "Batch: 18, Loss: 1.0149433612823486, Accuracy: 0.669921875\n",
      "Batch: 19, Loss: 1.0462977886199951, Accuracy: 0.673828125\n",
      "Batch: 20, Loss: 0.8750578165054321, Accuracy: 0.720703125\n",
      "Batch: 21, Loss: 0.9308122396469116, Accuracy: 0.6767578125\n",
      "Batch: 22, Loss: 1.0324254035949707, Accuracy: 0.66015625\n",
      "Batch: 23, Loss: 0.990378201007843, Accuracy: 0.66796875\n",
      "Batch: 24, Loss: 0.9985623955726624, Accuracy: 0.66796875\n",
      "Batch: 25, Loss: 0.9699019193649292, Accuracy: 0.6953125\n",
      "Batch: 26, Loss: 0.8636866211891174, Accuracy: 0.7255859375\n",
      "Batch: 27, Loss: 0.9173434972763062, Accuracy: 0.6865234375\n",
      "Batch: 28, Loss: 1.0188400745391846, Accuracy: 0.658203125\n",
      "Batch: 29, Loss: 0.9928871989250183, Accuracy: 0.677734375\n",
      "Batch: 30, Loss: 0.94614177942276, Accuracy: 0.70703125\n",
      "Batch: 31, Loss: 0.8993236422538757, Accuracy: 0.7080078125\n",
      "Batch: 32, Loss: 0.8688673973083496, Accuracy: 0.701171875\n",
      "Batch: 33, Loss: 1.0339107513427734, Accuracy: 0.6796875\n",
      "Batch: 34, Loss: 1.1373989582061768, Accuracy: 0.64453125\n",
      "Batch: 35, Loss: 1.0028318166732788, Accuracy: 0.6728515625\n",
      "Batch: 36, Loss: 1.0450493097305298, Accuracy: 0.669921875\n",
      "Batch: 37, Loss: 0.9668686389923096, Accuracy: 0.69140625\n",
      "Batch: 38, Loss: 0.9846484661102295, Accuracy: 0.6787109375\n",
      "Batch: 39, Loss: 0.9899153113365173, Accuracy: 0.6845703125\n",
      "Batch: 40, Loss: 1.0088635683059692, Accuracy: 0.6787109375\n",
      "Batch: 41, Loss: 0.9677254557609558, Accuracy: 0.705078125\n",
      "Batch: 42, Loss: 0.7975125312805176, Accuracy: 0.7314453125\n",
      "Batch: 43, Loss: 1.0017619132995605, Accuracy: 0.6669921875\n",
      "Batch: 44, Loss: 0.9988892078399658, Accuracy: 0.669921875\n",
      "Batch: 45, Loss: 0.8624517917633057, Accuracy: 0.7080078125\n",
      "Batch: 46, Loss: 0.9666671752929688, Accuracy: 0.6904296875\n",
      "Batch: 47, Loss: 0.9417478442192078, Accuracy: 0.705078125\n",
      "Batch: 48, Loss: 0.8784554600715637, Accuracy: 0.7021484375\n",
      "Batch: 49, Loss: 1.0702261924743652, Accuracy: 0.65625\n",
      "Batch: 50, Loss: 1.0455290079116821, Accuracy: 0.6591796875\n",
      "Batch: 51, Loss: 1.040055513381958, Accuracy: 0.6748046875\n",
      "Batch: 52, Loss: 1.0516102313995361, Accuracy: 0.6650390625\n",
      "Batch: 53, Loss: 0.8819479942321777, Accuracy: 0.705078125\n",
      "Batch: 54, Loss: 0.9537010788917542, Accuracy: 0.6982421875\n",
      "Batch: 55, Loss: 1.0396490097045898, Accuracy: 0.65234375\n",
      "Batch: 56, Loss: 1.0276436805725098, Accuracy: 0.6748046875\n",
      "Batch: 57, Loss: 0.9698456525802612, Accuracy: 0.693359375\n",
      "Batch: 58, Loss: 1.0489141941070557, Accuracy: 0.68359375\n",
      "Batch: 59, Loss: 0.9168730974197388, Accuracy: 0.724609375\n",
      "Batch: 60, Loss: 0.8600854873657227, Accuracy: 0.7216796875\n",
      "Batch: 61, Loss: 0.9794352650642395, Accuracy: 0.6796875\n",
      "Batch: 62, Loss: 0.9449028968811035, Accuracy: 0.6875\n",
      "Batch: 63, Loss: 0.9800890684127808, Accuracy: 0.6826171875\n",
      "Batch: 64, Loss: 0.9333757162094116, Accuracy: 0.7001953125\n",
      "Batch: 65, Loss: 0.9988148808479309, Accuracy: 0.6845703125\n",
      "Batch: 66, Loss: 0.9171039462089539, Accuracy: 0.71484375\n",
      "Batch: 67, Loss: 1.0269849300384521, Accuracy: 0.6591796875\n",
      "Batch: 68, Loss: 1.045854926109314, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 0.9789049625396729, Accuracy: 0.662109375\n",
      "Batch: 70, Loss: 0.9473782777786255, Accuracy: 0.712890625\n",
      "Batch: 71, Loss: 0.9868720769882202, Accuracy: 0.67578125\n",
      "Batch: 72, Loss: 0.8463441133499146, Accuracy: 0.716796875\n",
      "Batch: 73, Loss: 0.9133477210998535, Accuracy: 0.7041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 74, Loss: 0.8951541781425476, Accuracy: 0.71484375\n",
      "Batch: 75, Loss: 0.8656180500984192, Accuracy: 0.720703125\n",
      "Batch: 76, Loss: 0.9636520147323608, Accuracy: 0.6708984375\n",
      "Batch: 77, Loss: 0.8947964906692505, Accuracy: 0.6953125\n",
      "Batch: 78, Loss: 0.9336572885513306, Accuracy: 0.6982421875\n",
      "Batch: 79, Loss: 0.845848560333252, Accuracy: 0.7392578125\n",
      "Batch: 80, Loss: 0.9025335311889648, Accuracy: 0.6923828125\n",
      "Batch: 81, Loss: 1.0191222429275513, Accuracy: 0.6572265625\n",
      "Batch: 82, Loss: 1.0055103302001953, Accuracy: 0.6669921875\n",
      "Batch: 83, Loss: 0.8596145510673523, Accuracy: 0.7353515625\n",
      "Batch: 84, Loss: 0.946373701095581, Accuracy: 0.70703125\n",
      "Batch: 85, Loss: 0.877010703086853, Accuracy: 0.720703125\n",
      "Batch: 86, Loss: 1.0699462890625, Accuracy: 0.66015625\n",
      "Batch: 87, Loss: 0.8834713101387024, Accuracy: 0.7197265625\n",
      "Batch: 88, Loss: 1.0272084474563599, Accuracy: 0.689453125\n",
      "Batch: 89, Loss: 1.009408950805664, Accuracy: 0.68359375\n",
      "Batch: 90, Loss: 0.9177545309066772, Accuracy: 0.6884765625\n",
      "Batch: 91, Loss: 0.9851759076118469, Accuracy: 0.673828125\n",
      "Batch: 92, Loss: 0.9777528643608093, Accuracy: 0.685546875\n",
      "Batch: 93, Loss: 0.919430673122406, Accuracy: 0.705078125\n",
      "Batch: 94, Loss: 0.9334648847579956, Accuracy: 0.69140625\n",
      "Batch: 95, Loss: 1.0054450035095215, Accuracy: 0.671875\n",
      "Batch: 96, Loss: 0.9514206051826477, Accuracy: 0.6904296875\n",
      "Batch: 97, Loss: 0.850371241569519, Accuracy: 0.720703125\n",
      "Batch: 98, Loss: 0.8813506960868835, Accuracy: 0.7158203125\n",
      "Batch: 99, Loss: 0.8855303525924683, Accuracy: 0.7138671875\n",
      "Batch: 100, Loss: 0.9207208156585693, Accuracy: 0.703125\n",
      "Batch: 101, Loss: 1.0096712112426758, Accuracy: 0.6650390625\n",
      "Batch: 102, Loss: 0.9203342199325562, Accuracy: 0.689453125\n",
      "Batch: 103, Loss: 0.988816499710083, Accuracy: 0.6953125\n",
      "Batch: 104, Loss: 0.891433596611023, Accuracy: 0.693359375\n",
      "Batch: 105, Loss: 0.9718319177627563, Accuracy: 0.6806640625\n",
      "Batch: 106, Loss: 0.9322224259376526, Accuracy: 0.6904296875\n",
      "Batch: 107, Loss: 0.9844162464141846, Accuracy: 0.6796875\n",
      "Batch: 108, Loss: 0.9640345573425293, Accuracy: 0.6845703125\n",
      "Batch: 109, Loss: 1.0762546062469482, Accuracy: 0.642578125\n",
      "Batch: 110, Loss: 0.8409736752510071, Accuracy: 0.7197265625\n",
      "Batch: 111, Loss: 1.021051049232483, Accuracy: 0.6630859375\n",
      "Batch: 112, Loss: 0.9738529920578003, Accuracy: 0.6953125\n",
      "Batch: 113, Loss: 0.9647334814071655, Accuracy: 0.6962890625\n",
      "Batch: 114, Loss: 1.069230318069458, Accuracy: 0.650390625\n",
      "Batch: 115, Loss: 1.078089952468872, Accuracy: 0.6630859375\n",
      "Batch: 116, Loss: 1.052128791809082, Accuracy: 0.662109375\n",
      "Batch: 117, Loss: 1.0614951848983765, Accuracy: 0.66796875\n",
      "Batch: 118, Loss: 0.8550859689712524, Accuracy: 0.7255859375\n",
      "Batch: 119, Loss: 0.8634220361709595, Accuracy: 0.7255859375\n",
      "Batch: 120, Loss: 0.9824665784835815, Accuracy: 0.68359375\n",
      "Batch: 121, Loss: 1.015568494796753, Accuracy: 0.673828125\n",
      "Batch: 122, Loss: 0.9409236907958984, Accuracy: 0.68359375\n",
      "Batch: 123, Loss: 0.910676121711731, Accuracy: 0.716796875\n",
      "Batch: 124, Loss: 1.0054010152816772, Accuracy: 0.6806640625\n",
      "Batch: 125, Loss: 1.00956130027771, Accuracy: 0.6591796875\n",
      "Batch: 126, Loss: 1.0013904571533203, Accuracy: 0.6669921875\n",
      "Batch: 127, Loss: 0.8859126567840576, Accuracy: 0.720703125\n",
      "Batch: 128, Loss: 1.06657075881958, Accuracy: 0.6708984375\n",
      "Batch: 129, Loss: 0.9205929636955261, Accuracy: 0.7197265625\n",
      "Batch: 130, Loss: 1.1084518432617188, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.0203396081924438, Accuracy: 0.67578125\n",
      "Batch: 132, Loss: 1.0460082292556763, Accuracy: 0.67578125\n",
      "Batch: 133, Loss: 0.9405273199081421, Accuracy: 0.6826171875\n",
      "Batch: 134, Loss: 1.0086315870285034, Accuracy: 0.6630859375\n",
      "Batch: 135, Loss: 0.8784478902816772, Accuracy: 0.7197265625\n",
      "Batch: 136, Loss: 0.9738377332687378, Accuracy: 0.6884765625\n",
      "Batch: 137, Loss: 0.8969021439552307, Accuracy: 0.6953125\n",
      "Batch: 138, Loss: 0.8175254464149475, Accuracy: 0.7177734375\n",
      "Batch: 139, Loss: 0.8881266117095947, Accuracy: 0.7080078125\n",
      "Batch: 140, Loss: 0.9752196073532104, Accuracy: 0.6806640625\n",
      "Batch: 141, Loss: 0.9936634302139282, Accuracy: 0.6787109375\n",
      "Batch: 142, Loss: 1.0044928789138794, Accuracy: 0.6669921875\n",
      "Batch: 143, Loss: 0.9892803430557251, Accuracy: 0.6650390625\n",
      "Batch: 144, Loss: 0.9513038992881775, Accuracy: 0.697265625\n",
      "Batch: 145, Loss: 0.9226144552230835, Accuracy: 0.673828125\n",
      "Batch: 146, Loss: 1.0269861221313477, Accuracy: 0.65625\n",
      "Batch: 147, Loss: 0.9866142868995667, Accuracy: 0.67578125\n",
      "Batch: 148, Loss: 1.1004867553710938, Accuracy: 0.6376953125\n",
      "Batch: 149, Loss: 0.9916161894798279, Accuracy: 0.6806640625\n",
      "Batch: 150, Loss: 0.9309110641479492, Accuracy: 0.69921875\n",
      "Batch: 151, Loss: 0.8522149324417114, Accuracy: 0.7158203125\n",
      "Epoch 19/90\n",
      "Batch: 1, Loss: 1.2022453546524048, Accuracy: 0.611328125\n",
      "Batch: 2, Loss: 1.0536491870880127, Accuracy: 0.6357421875\n",
      "Batch: 3, Loss: 0.9194638729095459, Accuracy: 0.6923828125\n",
      "Batch: 4, Loss: 0.8866862058639526, Accuracy: 0.7177734375\n",
      "Batch: 5, Loss: 0.86467444896698, Accuracy: 0.7255859375\n",
      "Batch: 6, Loss: 0.9887372851371765, Accuracy: 0.666015625\n",
      "Batch: 7, Loss: 0.9413184523582458, Accuracy: 0.6904296875\n",
      "Batch: 8, Loss: 0.8785049915313721, Accuracy: 0.7138671875\n",
      "Batch: 9, Loss: 0.8746351599693298, Accuracy: 0.71484375\n",
      "Batch: 10, Loss: 0.8481535911560059, Accuracy: 0.7177734375\n",
      "Batch: 11, Loss: 1.0390864610671997, Accuracy: 0.6533203125\n",
      "Batch: 12, Loss: 1.036123514175415, Accuracy: 0.66015625\n",
      "Batch: 13, Loss: 0.8150465488433838, Accuracy: 0.7255859375\n",
      "Batch: 14, Loss: 1.0613278150558472, Accuracy: 0.64453125\n",
      "Batch: 15, Loss: 0.9143266677856445, Accuracy: 0.728515625\n",
      "Batch: 16, Loss: 0.8941740989685059, Accuracy: 0.7177734375\n",
      "Batch: 17, Loss: 0.9676005840301514, Accuracy: 0.681640625\n",
      "Batch: 18, Loss: 0.9784194231033325, Accuracy: 0.6728515625\n",
      "Batch: 19, Loss: 1.0216675996780396, Accuracy: 0.673828125\n",
      "Batch: 20, Loss: 0.8899957537651062, Accuracy: 0.7109375\n",
      "Batch: 21, Loss: 0.8875057697296143, Accuracy: 0.6962890625\n",
      "Batch: 22, Loss: 1.0007288455963135, Accuracy: 0.6806640625\n",
      "Batch: 23, Loss: 0.9628853797912598, Accuracy: 0.68359375\n",
      "Batch: 24, Loss: 0.9858431220054626, Accuracy: 0.67578125\n",
      "Batch: 25, Loss: 0.9517942070960999, Accuracy: 0.6875\n",
      "Batch: 26, Loss: 0.8403157591819763, Accuracy: 0.7216796875\n",
      "Batch: 27, Loss: 0.8934513330459595, Accuracy: 0.7080078125\n",
      "Batch: 28, Loss: 0.9864431023597717, Accuracy: 0.6630859375\n",
      "Batch: 29, Loss: 0.9611847996711731, Accuracy: 0.681640625\n",
      "Batch: 30, Loss: 0.8875329494476318, Accuracy: 0.71875\n",
      "Batch: 31, Loss: 0.8782448172569275, Accuracy: 0.7080078125\n",
      "Batch: 32, Loss: 0.8503227233886719, Accuracy: 0.7216796875\n",
      "Batch: 33, Loss: 0.9838466644287109, Accuracy: 0.6865234375\n",
      "Batch: 34, Loss: 1.0805855989456177, Accuracy: 0.666015625\n",
      "Batch: 35, Loss: 1.007338047027588, Accuracy: 0.673828125\n",
      "Batch: 36, Loss: 1.0179288387298584, Accuracy: 0.6748046875\n",
      "Batch: 37, Loss: 0.9337561130523682, Accuracy: 0.7099609375\n",
      "Batch: 38, Loss: 0.9814138412475586, Accuracy: 0.6796875\n",
      "Batch: 39, Loss: 0.9754001498222351, Accuracy: 0.69921875\n",
      "Batch: 40, Loss: 0.9849815964698792, Accuracy: 0.693359375\n",
      "Batch: 41, Loss: 0.9402250051498413, Accuracy: 0.703125\n",
      "Batch: 42, Loss: 0.7599526047706604, Accuracy: 0.76171875\n",
      "Batch: 43, Loss: 1.0090305805206299, Accuracy: 0.666015625\n",
      "Batch: 44, Loss: 0.9606102705001831, Accuracy: 0.6904296875\n",
      "Batch: 45, Loss: 0.8485453128814697, Accuracy: 0.7294921875\n",
      "Batch: 46, Loss: 0.9251691102981567, Accuracy: 0.7041015625\n",
      "Batch: 47, Loss: 0.9030625820159912, Accuracy: 0.7197265625\n",
      "Batch: 48, Loss: 0.8665441274642944, Accuracy: 0.708984375\n",
      "Batch: 49, Loss: 1.0403931140899658, Accuracy: 0.6689453125\n",
      "Batch: 50, Loss: 0.9979007244110107, Accuracy: 0.67578125\n",
      "Batch: 51, Loss: 1.029183030128479, Accuracy: 0.6806640625\n",
      "Batch: 52, Loss: 1.020329475402832, Accuracy: 0.6865234375\n",
      "Batch: 53, Loss: 0.8778150677680969, Accuracy: 0.7021484375\n",
      "Batch: 54, Loss: 0.9223570823669434, Accuracy: 0.703125\n",
      "Batch: 55, Loss: 1.0225133895874023, Accuracy: 0.6630859375\n",
      "Batch: 56, Loss: 1.00092613697052, Accuracy: 0.6845703125\n",
      "Batch: 57, Loss: 0.9540056586265564, Accuracy: 0.68359375\n",
      "Batch: 58, Loss: 1.0184834003448486, Accuracy: 0.671875\n",
      "Batch: 59, Loss: 0.9016082882881165, Accuracy: 0.7197265625\n",
      "Batch: 60, Loss: 0.8590034246444702, Accuracy: 0.7314453125\n",
      "Batch: 61, Loss: 0.977674663066864, Accuracy: 0.68359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 62, Loss: 0.9098635911941528, Accuracy: 0.7080078125\n",
      "Batch: 63, Loss: 0.9525039196014404, Accuracy: 0.69921875\n",
      "Batch: 64, Loss: 0.9392900466918945, Accuracy: 0.6982421875\n",
      "Batch: 65, Loss: 0.9711639881134033, Accuracy: 0.689453125\n",
      "Batch: 66, Loss: 0.9108188152313232, Accuracy: 0.7138671875\n",
      "Batch: 67, Loss: 1.0109450817108154, Accuracy: 0.6728515625\n",
      "Batch: 68, Loss: 1.0441359281539917, Accuracy: 0.671875\n",
      "Batch: 69, Loss: 0.9676300883293152, Accuracy: 0.6767578125\n",
      "Batch: 70, Loss: 0.9533616304397583, Accuracy: 0.71484375\n",
      "Batch: 71, Loss: 0.9837538003921509, Accuracy: 0.6728515625\n",
      "Batch: 72, Loss: 0.8329520225524902, Accuracy: 0.71875\n",
      "Batch: 73, Loss: 0.9037910103797913, Accuracy: 0.7109375\n",
      "Batch: 74, Loss: 0.8851351737976074, Accuracy: 0.7099609375\n",
      "Batch: 75, Loss: 0.8244403600692749, Accuracy: 0.728515625\n",
      "Batch: 76, Loss: 0.959502637386322, Accuracy: 0.6826171875\n",
      "Batch: 77, Loss: 0.8989230394363403, Accuracy: 0.705078125\n",
      "Batch: 78, Loss: 0.8965736627578735, Accuracy: 0.7138671875\n",
      "Batch: 79, Loss: 0.832903265953064, Accuracy: 0.7412109375\n",
      "Batch: 80, Loss: 0.8836997151374817, Accuracy: 0.6982421875\n",
      "Batch: 81, Loss: 1.002773642539978, Accuracy: 0.6640625\n",
      "Batch: 82, Loss: 0.9861823916435242, Accuracy: 0.6796875\n",
      "Batch: 83, Loss: 0.8403515815734863, Accuracy: 0.73828125\n",
      "Batch: 84, Loss: 0.9238137006759644, Accuracy: 0.701171875\n",
      "Batch: 85, Loss: 0.8320877552032471, Accuracy: 0.73828125\n",
      "Batch: 86, Loss: 1.0731236934661865, Accuracy: 0.6552734375\n",
      "Batch: 87, Loss: 0.8631170988082886, Accuracy: 0.7294921875\n",
      "Batch: 88, Loss: 1.0005967617034912, Accuracy: 0.6865234375\n",
      "Batch: 89, Loss: 0.9788084030151367, Accuracy: 0.689453125\n",
      "Batch: 90, Loss: 0.88056480884552, Accuracy: 0.7197265625\n",
      "Batch: 91, Loss: 0.9561095237731934, Accuracy: 0.6826171875\n",
      "Batch: 92, Loss: 0.9400250315666199, Accuracy: 0.68359375\n",
      "Batch: 93, Loss: 0.9170404672622681, Accuracy: 0.697265625\n",
      "Batch: 94, Loss: 0.9312452673912048, Accuracy: 0.697265625\n",
      "Batch: 95, Loss: 0.9756852984428406, Accuracy: 0.677734375\n",
      "Batch: 96, Loss: 0.923446536064148, Accuracy: 0.7080078125\n",
      "Batch: 97, Loss: 0.7855519652366638, Accuracy: 0.7392578125\n",
      "Batch: 98, Loss: 0.8521715402603149, Accuracy: 0.7275390625\n",
      "Batch: 99, Loss: 0.8512833118438721, Accuracy: 0.7109375\n",
      "Batch: 100, Loss: 0.9109950065612793, Accuracy: 0.7021484375\n",
      "Batch: 101, Loss: 0.9632090926170349, Accuracy: 0.689453125\n",
      "Batch: 102, Loss: 0.9099259376525879, Accuracy: 0.7041015625\n",
      "Batch: 103, Loss: 0.9710967540740967, Accuracy: 0.7109375\n",
      "Batch: 104, Loss: 0.8669751882553101, Accuracy: 0.7041015625\n",
      "Batch: 105, Loss: 0.9442391395568848, Accuracy: 0.7001953125\n",
      "Batch: 106, Loss: 0.9120330810546875, Accuracy: 0.7080078125\n",
      "Batch: 107, Loss: 0.967126727104187, Accuracy: 0.685546875\n",
      "Batch: 108, Loss: 0.9285213351249695, Accuracy: 0.6865234375\n",
      "Batch: 109, Loss: 1.0275970697402954, Accuracy: 0.673828125\n",
      "Batch: 110, Loss: 0.8313583135604858, Accuracy: 0.7373046875\n",
      "Batch: 111, Loss: 0.9840508103370667, Accuracy: 0.6875\n",
      "Batch: 112, Loss: 0.9481895565986633, Accuracy: 0.7119140625\n",
      "Batch: 113, Loss: 0.9382772445678711, Accuracy: 0.7060546875\n",
      "Batch: 114, Loss: 1.038308024406433, Accuracy: 0.6689453125\n",
      "Batch: 115, Loss: 1.0534520149230957, Accuracy: 0.68359375\n",
      "Batch: 116, Loss: 0.9795423746109009, Accuracy: 0.6865234375\n",
      "Batch: 117, Loss: 1.021547794342041, Accuracy: 0.6796875\n",
      "Batch: 118, Loss: 0.8136791586875916, Accuracy: 0.7353515625\n",
      "Batch: 119, Loss: 0.8409014344215393, Accuracy: 0.7265625\n",
      "Batch: 120, Loss: 0.9768676161766052, Accuracy: 0.6845703125\n",
      "Batch: 121, Loss: 0.9914081692695618, Accuracy: 0.6708984375\n",
      "Batch: 122, Loss: 0.931827962398529, Accuracy: 0.6748046875\n",
      "Batch: 123, Loss: 0.8789179921150208, Accuracy: 0.7119140625\n",
      "Batch: 124, Loss: 0.9603932499885559, Accuracy: 0.689453125\n",
      "Batch: 125, Loss: 0.9651815295219421, Accuracy: 0.69921875\n",
      "Batch: 126, Loss: 0.9717029333114624, Accuracy: 0.6904296875\n",
      "Batch: 127, Loss: 0.8756403923034668, Accuracy: 0.728515625\n",
      "Batch: 128, Loss: 1.0335302352905273, Accuracy: 0.6796875\n",
      "Batch: 129, Loss: 0.8973997831344604, Accuracy: 0.7158203125\n",
      "Batch: 130, Loss: 1.0976085662841797, Accuracy: 0.63671875\n",
      "Batch: 131, Loss: 0.9627460241317749, Accuracy: 0.6845703125\n",
      "Batch: 132, Loss: 1.004174828529358, Accuracy: 0.685546875\n",
      "Batch: 133, Loss: 0.9178285598754883, Accuracy: 0.6962890625\n",
      "Batch: 134, Loss: 0.9608451128005981, Accuracy: 0.689453125\n",
      "Batch: 135, Loss: 0.875426173210144, Accuracy: 0.728515625\n",
      "Batch: 136, Loss: 0.9555051326751709, Accuracy: 0.693359375\n",
      "Batch: 137, Loss: 0.8758901357650757, Accuracy: 0.703125\n",
      "Batch: 138, Loss: 0.8189401626586914, Accuracy: 0.7216796875\n",
      "Batch: 139, Loss: 0.8579000234603882, Accuracy: 0.7333984375\n",
      "Batch: 140, Loss: 0.9330472946166992, Accuracy: 0.6845703125\n",
      "Batch: 141, Loss: 0.9785082936286926, Accuracy: 0.6826171875\n",
      "Batch: 142, Loss: 0.9875261783599854, Accuracy: 0.685546875\n",
      "Batch: 143, Loss: 0.9526300430297852, Accuracy: 0.6923828125\n",
      "Batch: 144, Loss: 0.9563685655593872, Accuracy: 0.6884765625\n",
      "Batch: 145, Loss: 0.9042276740074158, Accuracy: 0.6826171875\n",
      "Batch: 146, Loss: 0.9910606145858765, Accuracy: 0.66796875\n",
      "Batch: 147, Loss: 0.9885895848274231, Accuracy: 0.6689453125\n",
      "Batch: 148, Loss: 1.069164752960205, Accuracy: 0.65625\n",
      "Batch: 149, Loss: 0.944869875907898, Accuracy: 0.6982421875\n",
      "Batch: 150, Loss: 0.9135384559631348, Accuracy: 0.6962890625\n",
      "Batch: 151, Loss: 0.8307502865791321, Accuracy: 0.7333984375\n",
      "Epoch 20/90\n",
      "Batch: 1, Loss: 1.158926248550415, Accuracy: 0.6123046875\n",
      "Batch: 2, Loss: 1.0326052904129028, Accuracy: 0.6376953125\n",
      "Batch: 3, Loss: 0.9208821058273315, Accuracy: 0.689453125\n",
      "Batch: 4, Loss: 0.8472694158554077, Accuracy: 0.7216796875\n",
      "Batch: 5, Loss: 0.8454158902168274, Accuracy: 0.716796875\n",
      "Batch: 6, Loss: 0.9463580846786499, Accuracy: 0.6865234375\n",
      "Batch: 7, Loss: 0.886380672454834, Accuracy: 0.7021484375\n",
      "Batch: 8, Loss: 0.8483911752700806, Accuracy: 0.7216796875\n",
      "Batch: 9, Loss: 0.8347983360290527, Accuracy: 0.7431640625\n",
      "Batch: 10, Loss: 0.843683660030365, Accuracy: 0.7197265625\n",
      "Batch: 11, Loss: 0.9934853911399841, Accuracy: 0.671875\n",
      "Batch: 12, Loss: 1.002652645111084, Accuracy: 0.6748046875\n",
      "Batch: 13, Loss: 0.7925145626068115, Accuracy: 0.73828125\n",
      "Batch: 14, Loss: 1.0471312999725342, Accuracy: 0.65625\n",
      "Batch: 15, Loss: 0.870658278465271, Accuracy: 0.7373046875\n",
      "Batch: 16, Loss: 0.8666430115699768, Accuracy: 0.728515625\n",
      "Batch: 17, Loss: 0.9512014389038086, Accuracy: 0.6884765625\n",
      "Batch: 18, Loss: 0.9577022790908813, Accuracy: 0.6845703125\n",
      "Batch: 19, Loss: 1.002685785293579, Accuracy: 0.671875\n",
      "Batch: 20, Loss: 0.8429384827613831, Accuracy: 0.732421875\n",
      "Batch: 21, Loss: 0.8889392018318176, Accuracy: 0.70703125\n",
      "Batch: 22, Loss: 0.9893688559532166, Accuracy: 0.6826171875\n",
      "Batch: 23, Loss: 0.9537410736083984, Accuracy: 0.6875\n",
      "Batch: 24, Loss: 0.9441684484481812, Accuracy: 0.67578125\n",
      "Batch: 25, Loss: 0.9251733422279358, Accuracy: 0.7001953125\n",
      "Batch: 26, Loss: 0.8156176805496216, Accuracy: 0.7314453125\n",
      "Batch: 27, Loss: 0.8908519744873047, Accuracy: 0.7021484375\n",
      "Batch: 28, Loss: 0.9669109582901001, Accuracy: 0.6708984375\n",
      "Batch: 29, Loss: 0.9367579221725464, Accuracy: 0.6875\n",
      "Batch: 30, Loss: 0.8835892677307129, Accuracy: 0.7197265625\n",
      "Batch: 31, Loss: 0.8863461017608643, Accuracy: 0.712890625\n",
      "Batch: 32, Loss: 0.8408048748970032, Accuracy: 0.7294921875\n",
      "Batch: 33, Loss: 0.9933313131332397, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 1.045445203781128, Accuracy: 0.666015625\n",
      "Batch: 35, Loss: 0.9646405577659607, Accuracy: 0.6826171875\n",
      "Batch: 36, Loss: 0.9858564138412476, Accuracy: 0.6904296875\n",
      "Batch: 37, Loss: 0.9246757626533508, Accuracy: 0.7109375\n",
      "Batch: 38, Loss: 0.9390116930007935, Accuracy: 0.69140625\n",
      "Batch: 39, Loss: 0.9374525547027588, Accuracy: 0.7099609375\n",
      "Batch: 40, Loss: 0.9607058763504028, Accuracy: 0.6953125\n",
      "Batch: 41, Loss: 0.9236428737640381, Accuracy: 0.71875\n",
      "Batch: 42, Loss: 0.7740563154220581, Accuracy: 0.734375\n",
      "Batch: 43, Loss: 0.9635513424873352, Accuracy: 0.6875\n",
      "Batch: 44, Loss: 0.9380155801773071, Accuracy: 0.6953125\n",
      "Batch: 45, Loss: 0.8259845972061157, Accuracy: 0.736328125\n",
      "Batch: 46, Loss: 0.9105252027511597, Accuracy: 0.7138671875\n",
      "Batch: 47, Loss: 0.8762534856796265, Accuracy: 0.732421875\n",
      "Batch: 48, Loss: 0.859649658203125, Accuracy: 0.7109375\n",
      "Batch: 49, Loss: 1.012832760810852, Accuracy: 0.68359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Loss: 0.9795064926147461, Accuracy: 0.6923828125\n",
      "Batch: 51, Loss: 1.0034695863723755, Accuracy: 0.6796875\n",
      "Batch: 52, Loss: 0.9930615425109863, Accuracy: 0.6796875\n",
      "Batch: 53, Loss: 0.8443339467048645, Accuracy: 0.7216796875\n",
      "Batch: 54, Loss: 0.9042313694953918, Accuracy: 0.71484375\n",
      "Batch: 55, Loss: 0.9999065399169922, Accuracy: 0.654296875\n",
      "Batch: 56, Loss: 1.004516839981079, Accuracy: 0.6767578125\n",
      "Batch: 57, Loss: 0.9025467038154602, Accuracy: 0.7041015625\n",
      "Batch: 58, Loss: 1.0103769302368164, Accuracy: 0.6884765625\n",
      "Batch: 59, Loss: 0.8664722442626953, Accuracy: 0.7333984375\n",
      "Batch: 60, Loss: 0.837212085723877, Accuracy: 0.7216796875\n",
      "Batch: 61, Loss: 0.9464491605758667, Accuracy: 0.6962890625\n",
      "Batch: 62, Loss: 0.891737699508667, Accuracy: 0.7001953125\n",
      "Batch: 63, Loss: 0.9317419528961182, Accuracy: 0.7041015625\n",
      "Batch: 64, Loss: 0.8946950435638428, Accuracy: 0.716796875\n",
      "Batch: 65, Loss: 0.9448777437210083, Accuracy: 0.693359375\n",
      "Batch: 66, Loss: 0.8807721138000488, Accuracy: 0.73046875\n",
      "Batch: 67, Loss: 0.9716556668281555, Accuracy: 0.681640625\n",
      "Batch: 68, Loss: 1.0056326389312744, Accuracy: 0.671875\n",
      "Batch: 69, Loss: 0.9552767276763916, Accuracy: 0.6943359375\n",
      "Batch: 70, Loss: 0.9299207925796509, Accuracy: 0.71484375\n",
      "Batch: 71, Loss: 0.9689293503761292, Accuracy: 0.6748046875\n",
      "Batch: 72, Loss: 0.810217022895813, Accuracy: 0.7294921875\n",
      "Batch: 73, Loss: 0.869182825088501, Accuracy: 0.720703125\n",
      "Batch: 74, Loss: 0.8351876735687256, Accuracy: 0.736328125\n",
      "Batch: 75, Loss: 0.8028576374053955, Accuracy: 0.734375\n",
      "Batch: 76, Loss: 0.9332248568534851, Accuracy: 0.703125\n",
      "Batch: 77, Loss: 0.8793420791625977, Accuracy: 0.716796875\n",
      "Batch: 78, Loss: 0.8989919424057007, Accuracy: 0.7138671875\n",
      "Batch: 79, Loss: 0.8115912675857544, Accuracy: 0.7529296875\n",
      "Batch: 80, Loss: 0.867339015007019, Accuracy: 0.7041015625\n",
      "Batch: 81, Loss: 0.944970428943634, Accuracy: 0.6884765625\n",
      "Batch: 82, Loss: 0.9782962799072266, Accuracy: 0.6865234375\n",
      "Batch: 83, Loss: 0.834161639213562, Accuracy: 0.7509765625\n",
      "Batch: 84, Loss: 0.905493438243866, Accuracy: 0.7119140625\n",
      "Batch: 85, Loss: 0.8136694431304932, Accuracy: 0.734375\n",
      "Batch: 86, Loss: 1.021435022354126, Accuracy: 0.6689453125\n",
      "Batch: 87, Loss: 0.8446887135505676, Accuracy: 0.7275390625\n",
      "Batch: 88, Loss: 0.9821492433547974, Accuracy: 0.6953125\n",
      "Batch: 89, Loss: 0.9729337692260742, Accuracy: 0.6865234375\n",
      "Batch: 90, Loss: 0.8650060296058655, Accuracy: 0.71484375\n",
      "Batch: 91, Loss: 0.9139103293418884, Accuracy: 0.6884765625\n",
      "Batch: 92, Loss: 0.918620228767395, Accuracy: 0.708984375\n",
      "Batch: 93, Loss: 0.8962615132331848, Accuracy: 0.712890625\n",
      "Batch: 94, Loss: 0.8929403424263, Accuracy: 0.71484375\n",
      "Batch: 95, Loss: 0.9545886516571045, Accuracy: 0.681640625\n",
      "Batch: 96, Loss: 0.8925533294677734, Accuracy: 0.7275390625\n",
      "Batch: 97, Loss: 0.786598801612854, Accuracy: 0.744140625\n",
      "Batch: 98, Loss: 0.8282410502433777, Accuracy: 0.7412109375\n",
      "Batch: 99, Loss: 0.8229564428329468, Accuracy: 0.7265625\n",
      "Batch: 100, Loss: 0.8802475333213806, Accuracy: 0.716796875\n",
      "Batch: 101, Loss: 0.9596924781799316, Accuracy: 0.6923828125\n",
      "Batch: 102, Loss: 0.9165064096450806, Accuracy: 0.7109375\n",
      "Batch: 103, Loss: 0.9532053470611572, Accuracy: 0.70703125\n",
      "Batch: 104, Loss: 0.8364764451980591, Accuracy: 0.7080078125\n",
      "Batch: 105, Loss: 0.9460868835449219, Accuracy: 0.701171875\n",
      "Batch: 106, Loss: 0.8838803768157959, Accuracy: 0.7099609375\n",
      "Batch: 107, Loss: 0.9395996332168579, Accuracy: 0.7080078125\n",
      "Batch: 108, Loss: 0.8917482495307922, Accuracy: 0.705078125\n",
      "Batch: 109, Loss: 1.0154426097869873, Accuracy: 0.66796875\n",
      "Batch: 110, Loss: 0.8121956586837769, Accuracy: 0.7265625\n",
      "Batch: 111, Loss: 0.9894980788230896, Accuracy: 0.6650390625\n",
      "Batch: 112, Loss: 0.9270524978637695, Accuracy: 0.6953125\n",
      "Batch: 113, Loss: 0.9231055974960327, Accuracy: 0.7109375\n",
      "Batch: 114, Loss: 1.0170884132385254, Accuracy: 0.6591796875\n",
      "Batch: 115, Loss: 1.0531777143478394, Accuracy: 0.6669921875\n",
      "Batch: 116, Loss: 0.9940906763076782, Accuracy: 0.669921875\n",
      "Batch: 117, Loss: 1.022072434425354, Accuracy: 0.6796875\n",
      "Batch: 118, Loss: 0.8108651041984558, Accuracy: 0.744140625\n",
      "Batch: 119, Loss: 0.8178914785385132, Accuracy: 0.74609375\n",
      "Batch: 120, Loss: 0.9347184300422668, Accuracy: 0.693359375\n",
      "Batch: 121, Loss: 0.9498152732849121, Accuracy: 0.6806640625\n",
      "Batch: 122, Loss: 0.9021929502487183, Accuracy: 0.7138671875\n",
      "Batch: 123, Loss: 0.8691757917404175, Accuracy: 0.7197265625\n",
      "Batch: 124, Loss: 0.945646345615387, Accuracy: 0.6875\n",
      "Batch: 125, Loss: 0.9710513353347778, Accuracy: 0.68359375\n",
      "Batch: 126, Loss: 0.9541456699371338, Accuracy: 0.6982421875\n",
      "Batch: 127, Loss: 0.8541814684867859, Accuracy: 0.7431640625\n",
      "Batch: 128, Loss: 1.029099941253662, Accuracy: 0.68359375\n",
      "Batch: 129, Loss: 0.8725586533546448, Accuracy: 0.7138671875\n",
      "Batch: 130, Loss: 1.0333845615386963, Accuracy: 0.6650390625\n",
      "Batch: 131, Loss: 0.9317390322685242, Accuracy: 0.6982421875\n",
      "Batch: 132, Loss: 1.010982871055603, Accuracy: 0.6845703125\n",
      "Batch: 133, Loss: 0.8902320265769958, Accuracy: 0.716796875\n",
      "Batch: 134, Loss: 0.9424577951431274, Accuracy: 0.6953125\n",
      "Batch: 135, Loss: 0.863555908203125, Accuracy: 0.724609375\n",
      "Batch: 136, Loss: 0.9389611482620239, Accuracy: 0.6923828125\n",
      "Batch: 137, Loss: 0.8769066333770752, Accuracy: 0.689453125\n",
      "Batch: 138, Loss: 0.7864139080047607, Accuracy: 0.7392578125\n",
      "Batch: 139, Loss: 0.8324820399284363, Accuracy: 0.7294921875\n",
      "Batch: 140, Loss: 0.9222323894500732, Accuracy: 0.69921875\n",
      "Batch: 141, Loss: 0.9672296047210693, Accuracy: 0.68359375\n",
      "Batch: 142, Loss: 0.9569506645202637, Accuracy: 0.689453125\n",
      "Batch: 143, Loss: 0.9183528423309326, Accuracy: 0.693359375\n",
      "Batch: 144, Loss: 0.9287419319152832, Accuracy: 0.69921875\n",
      "Batch: 145, Loss: 0.8816418647766113, Accuracy: 0.6953125\n",
      "Batch: 146, Loss: 0.9730335474014282, Accuracy: 0.681640625\n",
      "Batch: 147, Loss: 0.9451848864555359, Accuracy: 0.6865234375\n",
      "Batch: 148, Loss: 1.0489803552627563, Accuracy: 0.6513671875\n",
      "Batch: 149, Loss: 0.9336333274841309, Accuracy: 0.6923828125\n",
      "Batch: 150, Loss: 0.8952165842056274, Accuracy: 0.708984375\n",
      "Batch: 151, Loss: 0.8134820461273193, Accuracy: 0.7333984375\n",
      "Saved Weights at epoch 20 to file Weights_20.h5\n",
      "Epoch 21/90\n",
      "Batch: 1, Loss: 1.1591596603393555, Accuracy: 0.6171875\n",
      "Batch: 2, Loss: 1.0213596820831299, Accuracy: 0.642578125\n",
      "Batch: 3, Loss: 0.89754319190979, Accuracy: 0.6943359375\n",
      "Batch: 4, Loss: 0.8292309045791626, Accuracy: 0.720703125\n",
      "Batch: 5, Loss: 0.8302754163742065, Accuracy: 0.734375\n",
      "Batch: 6, Loss: 0.9204556941986084, Accuracy: 0.69140625\n",
      "Batch: 7, Loss: 0.8670059442520142, Accuracy: 0.7138671875\n",
      "Batch: 8, Loss: 0.8618464469909668, Accuracy: 0.7060546875\n",
      "Batch: 9, Loss: 0.8520764112472534, Accuracy: 0.736328125\n",
      "Batch: 10, Loss: 0.8139688968658447, Accuracy: 0.7333984375\n",
      "Batch: 11, Loss: 0.9851868748664856, Accuracy: 0.671875\n",
      "Batch: 12, Loss: 0.994996964931488, Accuracy: 0.6748046875\n",
      "Batch: 13, Loss: 0.7590276002883911, Accuracy: 0.755859375\n",
      "Batch: 14, Loss: 1.0568292140960693, Accuracy: 0.6552734375\n",
      "Batch: 15, Loss: 0.854060709476471, Accuracy: 0.71875\n",
      "Batch: 16, Loss: 0.8607262372970581, Accuracy: 0.720703125\n",
      "Batch: 17, Loss: 0.9399458169937134, Accuracy: 0.701171875\n",
      "Batch: 18, Loss: 0.9440175294876099, Accuracy: 0.6953125\n",
      "Batch: 19, Loss: 0.9704653024673462, Accuracy: 0.6982421875\n",
      "Batch: 20, Loss: 0.8166807293891907, Accuracy: 0.7451171875\n",
      "Batch: 21, Loss: 0.8693928718566895, Accuracy: 0.712890625\n",
      "Batch: 22, Loss: 0.9771117568016052, Accuracy: 0.6728515625\n",
      "Batch: 23, Loss: 0.9366111159324646, Accuracy: 0.6875\n",
      "Batch: 24, Loss: 0.9455182552337646, Accuracy: 0.67578125\n",
      "Batch: 25, Loss: 0.9201440215110779, Accuracy: 0.712890625\n",
      "Batch: 26, Loss: 0.8141574859619141, Accuracy: 0.7236328125\n",
      "Batch: 27, Loss: 0.8547757267951965, Accuracy: 0.712890625\n",
      "Batch: 28, Loss: 0.9274706244468689, Accuracy: 0.6767578125\n",
      "Batch: 29, Loss: 0.9074603915214539, Accuracy: 0.6953125\n",
      "Batch: 30, Loss: 0.8287481069564819, Accuracy: 0.7392578125\n",
      "Batch: 31, Loss: 0.8289270997047424, Accuracy: 0.7421875\n",
      "Batch: 32, Loss: 0.8086057901382446, Accuracy: 0.7294921875\n",
      "Batch: 33, Loss: 0.9596146941184998, Accuracy: 0.685546875\n",
      "Batch: 34, Loss: 1.0312292575836182, Accuracy: 0.6796875\n",
      "Batch: 35, Loss: 0.9182488918304443, Accuracy: 0.6962890625\n",
      "Batch: 36, Loss: 0.9727095365524292, Accuracy: 0.697265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 37, Loss: 0.8846288919448853, Accuracy: 0.7119140625\n",
      "Batch: 38, Loss: 0.8997268676757812, Accuracy: 0.6923828125\n",
      "Batch: 39, Loss: 0.9273719191551208, Accuracy: 0.7021484375\n",
      "Batch: 40, Loss: 0.9543304443359375, Accuracy: 0.697265625\n",
      "Batch: 41, Loss: 0.8889331221580505, Accuracy: 0.724609375\n",
      "Batch: 42, Loss: 0.6947205662727356, Accuracy: 0.7685546875\n",
      "Batch: 43, Loss: 0.9544988870620728, Accuracy: 0.67578125\n",
      "Batch: 44, Loss: 0.9154658317565918, Accuracy: 0.703125\n",
      "Batch: 45, Loss: 0.8324465751647949, Accuracy: 0.73046875\n",
      "Batch: 46, Loss: 0.8810845017433167, Accuracy: 0.712890625\n",
      "Batch: 47, Loss: 0.8549757599830627, Accuracy: 0.732421875\n",
      "Batch: 48, Loss: 0.8193380832672119, Accuracy: 0.71875\n",
      "Batch: 49, Loss: 0.9622501134872437, Accuracy: 0.6865234375\n",
      "Batch: 50, Loss: 0.9598702192306519, Accuracy: 0.7001953125\n",
      "Batch: 51, Loss: 0.9634823203086853, Accuracy: 0.701171875\n",
      "Batch: 52, Loss: 0.9672762155532837, Accuracy: 0.701171875\n",
      "Batch: 53, Loss: 0.8187251091003418, Accuracy: 0.724609375\n",
      "Batch: 54, Loss: 0.9006478786468506, Accuracy: 0.6953125\n",
      "Batch: 55, Loss: 0.9924124479293823, Accuracy: 0.6689453125\n",
      "Batch: 56, Loss: 0.9861977696418762, Accuracy: 0.689453125\n",
      "Batch: 57, Loss: 0.8898836374282837, Accuracy: 0.693359375\n",
      "Batch: 58, Loss: 0.9840898513793945, Accuracy: 0.6953125\n",
      "Batch: 59, Loss: 0.8876597285270691, Accuracy: 0.720703125\n",
      "Batch: 60, Loss: 0.8054931163787842, Accuracy: 0.7421875\n",
      "Batch: 61, Loss: 0.9088340997695923, Accuracy: 0.693359375\n",
      "Batch: 62, Loss: 0.8742696046829224, Accuracy: 0.708984375\n",
      "Batch: 63, Loss: 0.8994474411010742, Accuracy: 0.7021484375\n",
      "Batch: 64, Loss: 0.8762300610542297, Accuracy: 0.708984375\n",
      "Batch: 65, Loss: 0.9163342118263245, Accuracy: 0.708984375\n",
      "Batch: 66, Loss: 0.8558900952339172, Accuracy: 0.7333984375\n",
      "Batch: 67, Loss: 0.9396344423294067, Accuracy: 0.7060546875\n",
      "Batch: 68, Loss: 0.987328052520752, Accuracy: 0.6982421875\n",
      "Batch: 69, Loss: 0.9280182123184204, Accuracy: 0.6962890625\n",
      "Batch: 70, Loss: 0.8966183662414551, Accuracy: 0.7021484375\n",
      "Batch: 71, Loss: 0.9230054020881653, Accuracy: 0.6943359375\n",
      "Batch: 72, Loss: 0.7995827198028564, Accuracy: 0.732421875\n",
      "Batch: 73, Loss: 0.8513118028640747, Accuracy: 0.728515625\n",
      "Batch: 74, Loss: 0.8063548803329468, Accuracy: 0.7431640625\n",
      "Batch: 75, Loss: 0.7865516543388367, Accuracy: 0.7353515625\n",
      "Batch: 76, Loss: 0.9052302837371826, Accuracy: 0.7060546875\n",
      "Batch: 77, Loss: 0.8583126068115234, Accuracy: 0.720703125\n",
      "Batch: 78, Loss: 0.8488596677780151, Accuracy: 0.7373046875\n",
      "Batch: 79, Loss: 0.7822064757347107, Accuracy: 0.76171875\n",
      "Batch: 80, Loss: 0.880851686000824, Accuracy: 0.693359375\n",
      "Batch: 81, Loss: 0.9634478688240051, Accuracy: 0.681640625\n",
      "Batch: 82, Loss: 0.9335793256759644, Accuracy: 0.70703125\n",
      "Batch: 83, Loss: 0.7974246740341187, Accuracy: 0.751953125\n",
      "Batch: 84, Loss: 0.8983008861541748, Accuracy: 0.71484375\n",
      "Batch: 85, Loss: 0.7925536036491394, Accuracy: 0.74609375\n",
      "Batch: 86, Loss: 1.031247854232788, Accuracy: 0.66015625\n",
      "Batch: 87, Loss: 0.8341461420059204, Accuracy: 0.7509765625\n",
      "Batch: 88, Loss: 0.9508644342422485, Accuracy: 0.701171875\n",
      "Batch: 89, Loss: 0.9473079442977905, Accuracy: 0.7080078125\n",
      "Batch: 90, Loss: 0.85066819190979, Accuracy: 0.7275390625\n",
      "Batch: 91, Loss: 0.8896275162696838, Accuracy: 0.70703125\n",
      "Batch: 92, Loss: 0.8871679306030273, Accuracy: 0.7099609375\n",
      "Batch: 93, Loss: 0.8647084832191467, Accuracy: 0.712890625\n",
      "Batch: 94, Loss: 0.8631410598754883, Accuracy: 0.720703125\n",
      "Batch: 95, Loss: 0.9124960899353027, Accuracy: 0.6845703125\n",
      "Batch: 96, Loss: 0.8822001218795776, Accuracy: 0.7119140625\n",
      "Batch: 97, Loss: 0.7647073864936829, Accuracy: 0.748046875\n",
      "Batch: 98, Loss: 0.8048617839813232, Accuracy: 0.73828125\n",
      "Batch: 99, Loss: 0.8264232873916626, Accuracy: 0.73046875\n",
      "Batch: 100, Loss: 0.8837071657180786, Accuracy: 0.7197265625\n",
      "Batch: 101, Loss: 0.9306384325027466, Accuracy: 0.6953125\n",
      "Batch: 102, Loss: 0.8762149214744568, Accuracy: 0.728515625\n",
      "Batch: 103, Loss: 0.9225142002105713, Accuracy: 0.7080078125\n",
      "Batch: 104, Loss: 0.8255051374435425, Accuracy: 0.7236328125\n",
      "Batch: 105, Loss: 0.8991949558258057, Accuracy: 0.712890625\n",
      "Batch: 106, Loss: 0.8912879228591919, Accuracy: 0.71484375\n",
      "Batch: 107, Loss: 0.908531129360199, Accuracy: 0.7158203125\n",
      "Batch: 108, Loss: 0.8654665946960449, Accuracy: 0.712890625\n",
      "Batch: 109, Loss: 0.9922227263450623, Accuracy: 0.6796875\n",
      "Batch: 110, Loss: 0.7912953495979309, Accuracy: 0.73828125\n",
      "Batch: 111, Loss: 0.9689053297042847, Accuracy: 0.6845703125\n",
      "Batch: 112, Loss: 0.8958332538604736, Accuracy: 0.7119140625\n",
      "Batch: 113, Loss: 0.912645697593689, Accuracy: 0.7119140625\n",
      "Batch: 114, Loss: 0.9878954291343689, Accuracy: 0.6767578125\n",
      "Batch: 115, Loss: 1.013475775718689, Accuracy: 0.69140625\n",
      "Batch: 116, Loss: 0.9494000673294067, Accuracy: 0.6943359375\n",
      "Batch: 117, Loss: 1.0006102323532104, Accuracy: 0.689453125\n",
      "Batch: 118, Loss: 0.8208701610565186, Accuracy: 0.7421875\n",
      "Batch: 119, Loss: 0.7974807024002075, Accuracy: 0.7490234375\n",
      "Batch: 120, Loss: 0.9174515008926392, Accuracy: 0.6982421875\n",
      "Batch: 121, Loss: 0.9443049430847168, Accuracy: 0.68359375\n",
      "Batch: 122, Loss: 0.8812718391418457, Accuracy: 0.720703125\n",
      "Batch: 123, Loss: 0.8476066589355469, Accuracy: 0.7255859375\n",
      "Batch: 124, Loss: 0.9511119723320007, Accuracy: 0.6923828125\n",
      "Batch: 125, Loss: 0.9432289600372314, Accuracy: 0.7001953125\n",
      "Batch: 126, Loss: 0.9416122436523438, Accuracy: 0.68359375\n",
      "Batch: 127, Loss: 0.8251743316650391, Accuracy: 0.7431640625\n",
      "Batch: 128, Loss: 1.0001049041748047, Accuracy: 0.7080078125\n",
      "Batch: 129, Loss: 0.8641542196273804, Accuracy: 0.7265625\n",
      "Batch: 130, Loss: 1.0097112655639648, Accuracy: 0.6630859375\n",
      "Batch: 131, Loss: 0.9280688762664795, Accuracy: 0.69921875\n",
      "Batch: 132, Loss: 0.9837056398391724, Accuracy: 0.669921875\n",
      "Batch: 133, Loss: 0.8446571826934814, Accuracy: 0.712890625\n",
      "Batch: 134, Loss: 0.9358156323432922, Accuracy: 0.69140625\n",
      "Batch: 135, Loss: 0.8081831336021423, Accuracy: 0.73046875\n",
      "Batch: 136, Loss: 0.9040223956108093, Accuracy: 0.7119140625\n",
      "Batch: 137, Loss: 0.8552021980285645, Accuracy: 0.7041015625\n",
      "Batch: 138, Loss: 0.774921178817749, Accuracy: 0.73828125\n",
      "Batch: 139, Loss: 0.8510538339614868, Accuracy: 0.720703125\n",
      "Batch: 140, Loss: 0.934760332107544, Accuracy: 0.693359375\n",
      "Batch: 141, Loss: 0.9567399024963379, Accuracy: 0.69140625\n",
      "Batch: 142, Loss: 0.9363195896148682, Accuracy: 0.693359375\n",
      "Batch: 143, Loss: 0.9360531568527222, Accuracy: 0.6923828125\n",
      "Batch: 144, Loss: 0.8987820744514465, Accuracy: 0.7158203125\n",
      "Batch: 145, Loss: 0.8565250635147095, Accuracy: 0.6953125\n",
      "Batch: 146, Loss: 0.9405015707015991, Accuracy: 0.6806640625\n",
      "Batch: 147, Loss: 0.9235681295394897, Accuracy: 0.689453125\n",
      "Batch: 148, Loss: 1.0297846794128418, Accuracy: 0.6611328125\n",
      "Batch: 149, Loss: 0.909794270992279, Accuracy: 0.705078125\n",
      "Batch: 150, Loss: 0.8755836486816406, Accuracy: 0.7119140625\n",
      "Batch: 151, Loss: 0.780951738357544, Accuracy: 0.744140625\n",
      "Epoch 22/90\n",
      "Batch: 1, Loss: 1.102512001991272, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 1.006736397743225, Accuracy: 0.6455078125\n",
      "Batch: 3, Loss: 0.9000604152679443, Accuracy: 0.6884765625\n",
      "Batch: 4, Loss: 0.7969590425491333, Accuracy: 0.7353515625\n",
      "Batch: 5, Loss: 0.8037533164024353, Accuracy: 0.744140625\n",
      "Batch: 6, Loss: 0.9121320843696594, Accuracy: 0.701171875\n",
      "Batch: 7, Loss: 0.8690762519836426, Accuracy: 0.7080078125\n",
      "Batch: 8, Loss: 0.8362443447113037, Accuracy: 0.7119140625\n",
      "Batch: 9, Loss: 0.8149548172950745, Accuracy: 0.7431640625\n",
      "Batch: 10, Loss: 0.8291486501693726, Accuracy: 0.7197265625\n",
      "Batch: 11, Loss: 0.9730019569396973, Accuracy: 0.6865234375\n",
      "Batch: 12, Loss: 0.9843206405639648, Accuracy: 0.689453125\n",
      "Batch: 13, Loss: 0.7475680112838745, Accuracy: 0.7509765625\n",
      "Batch: 14, Loss: 0.9899833798408508, Accuracy: 0.6689453125\n",
      "Batch: 15, Loss: 0.8467367887496948, Accuracy: 0.734375\n",
      "Batch: 16, Loss: 0.8532804250717163, Accuracy: 0.7177734375\n",
      "Batch: 17, Loss: 0.9038892984390259, Accuracy: 0.716796875\n",
      "Batch: 18, Loss: 0.9193217158317566, Accuracy: 0.7099609375\n",
      "Batch: 19, Loss: 0.9771040678024292, Accuracy: 0.681640625\n",
      "Batch: 20, Loss: 0.8112465739250183, Accuracy: 0.748046875\n",
      "Batch: 21, Loss: 0.8423618078231812, Accuracy: 0.712890625\n",
      "Batch: 22, Loss: 0.9555274248123169, Accuracy: 0.6982421875\n",
      "Batch: 23, Loss: 0.9157090783119202, Accuracy: 0.701171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 24, Loss: 0.9029009342193604, Accuracy: 0.685546875\n",
      "Batch: 25, Loss: 0.9025897979736328, Accuracy: 0.7080078125\n",
      "Batch: 26, Loss: 0.7903440594673157, Accuracy: 0.7333984375\n",
      "Batch: 27, Loss: 0.8377501964569092, Accuracy: 0.7119140625\n",
      "Batch: 28, Loss: 0.9282526969909668, Accuracy: 0.6826171875\n",
      "Batch: 29, Loss: 0.8910328149795532, Accuracy: 0.7001953125\n",
      "Batch: 30, Loss: 0.8201838135719299, Accuracy: 0.751953125\n",
      "Batch: 31, Loss: 0.7983558177947998, Accuracy: 0.7470703125\n",
      "Batch: 32, Loss: 0.7830233573913574, Accuracy: 0.7412109375\n",
      "Batch: 33, Loss: 0.9581160545349121, Accuracy: 0.6904296875\n",
      "Batch: 34, Loss: 1.0247431993484497, Accuracy: 0.6708984375\n",
      "Batch: 35, Loss: 0.9384773373603821, Accuracy: 0.6982421875\n",
      "Batch: 36, Loss: 0.9635823369026184, Accuracy: 0.7021484375\n",
      "Batch: 37, Loss: 0.8778114318847656, Accuracy: 0.71484375\n",
      "Batch: 38, Loss: 0.930740475654602, Accuracy: 0.69140625\n",
      "Batch: 39, Loss: 0.9159413576126099, Accuracy: 0.7080078125\n",
      "Batch: 40, Loss: 0.9247514009475708, Accuracy: 0.7080078125\n",
      "Batch: 41, Loss: 0.8762726187705994, Accuracy: 0.724609375\n",
      "Batch: 42, Loss: 0.693232536315918, Accuracy: 0.763671875\n",
      "Batch: 43, Loss: 0.932587742805481, Accuracy: 0.6865234375\n",
      "Batch: 44, Loss: 0.8952081799507141, Accuracy: 0.7109375\n",
      "Batch: 45, Loss: 0.7940075397491455, Accuracy: 0.748046875\n",
      "Batch: 46, Loss: 0.8643671274185181, Accuracy: 0.720703125\n",
      "Batch: 47, Loss: 0.8484973907470703, Accuracy: 0.7490234375\n",
      "Batch: 48, Loss: 0.7812005281448364, Accuracy: 0.7255859375\n",
      "Batch: 49, Loss: 0.9494727849960327, Accuracy: 0.6982421875\n",
      "Batch: 50, Loss: 0.9265503287315369, Accuracy: 0.697265625\n",
      "Batch: 51, Loss: 0.9565263986587524, Accuracy: 0.6953125\n",
      "Batch: 52, Loss: 0.9543256759643555, Accuracy: 0.6875\n",
      "Batch: 53, Loss: 0.8125061392784119, Accuracy: 0.72265625\n",
      "Batch: 54, Loss: 0.8706530332565308, Accuracy: 0.7109375\n",
      "Batch: 55, Loss: 0.9491048455238342, Accuracy: 0.6875\n",
      "Batch: 56, Loss: 0.9310142993927002, Accuracy: 0.69921875\n",
      "Batch: 57, Loss: 0.8920542001724243, Accuracy: 0.7099609375\n",
      "Batch: 58, Loss: 0.9834199547767639, Accuracy: 0.6875\n",
      "Batch: 59, Loss: 0.8503697514533997, Accuracy: 0.7314453125\n",
      "Batch: 60, Loss: 0.7999457120895386, Accuracy: 0.744140625\n",
      "Batch: 61, Loss: 0.9283928871154785, Accuracy: 0.7001953125\n",
      "Batch: 62, Loss: 0.8468422889709473, Accuracy: 0.7177734375\n",
      "Batch: 63, Loss: 0.9144245386123657, Accuracy: 0.708984375\n",
      "Batch: 64, Loss: 0.8616020083427429, Accuracy: 0.71875\n",
      "Batch: 65, Loss: 0.9190746545791626, Accuracy: 0.69921875\n",
      "Batch: 66, Loss: 0.8545528650283813, Accuracy: 0.73828125\n",
      "Batch: 67, Loss: 0.9400980472564697, Accuracy: 0.6962890625\n",
      "Batch: 68, Loss: 0.9690320491790771, Accuracy: 0.6865234375\n",
      "Batch: 69, Loss: 0.9051605463027954, Accuracy: 0.701171875\n",
      "Batch: 70, Loss: 0.8497533798217773, Accuracy: 0.7373046875\n",
      "Batch: 71, Loss: 0.9052445888519287, Accuracy: 0.7158203125\n",
      "Batch: 72, Loss: 0.7841312885284424, Accuracy: 0.7509765625\n",
      "Batch: 73, Loss: 0.8207744359970093, Accuracy: 0.744140625\n",
      "Batch: 74, Loss: 0.7996463775634766, Accuracy: 0.7509765625\n",
      "Batch: 75, Loss: 0.7667312622070312, Accuracy: 0.7529296875\n",
      "Batch: 76, Loss: 0.8835825324058533, Accuracy: 0.712890625\n",
      "Batch: 77, Loss: 0.8099607229232788, Accuracy: 0.73046875\n",
      "Batch: 78, Loss: 0.8123089075088501, Accuracy: 0.73828125\n",
      "Batch: 79, Loss: 0.7868287563323975, Accuracy: 0.7529296875\n",
      "Batch: 80, Loss: 0.8347554802894592, Accuracy: 0.71875\n",
      "Batch: 81, Loss: 0.9144721031188965, Accuracy: 0.6845703125\n",
      "Batch: 82, Loss: 0.9298566579818726, Accuracy: 0.69921875\n",
      "Batch: 83, Loss: 0.7958232164382935, Accuracy: 0.740234375\n",
      "Batch: 84, Loss: 0.86815345287323, Accuracy: 0.7080078125\n",
      "Batch: 85, Loss: 0.800735592842102, Accuracy: 0.734375\n",
      "Batch: 86, Loss: 1.004185438156128, Accuracy: 0.6689453125\n",
      "Batch: 87, Loss: 0.8001154661178589, Accuracy: 0.7451171875\n",
      "Batch: 88, Loss: 0.925728440284729, Accuracy: 0.71875\n",
      "Batch: 89, Loss: 0.9201083183288574, Accuracy: 0.7119140625\n",
      "Batch: 90, Loss: 0.8277690410614014, Accuracy: 0.732421875\n",
      "Batch: 91, Loss: 0.8913314342498779, Accuracy: 0.7099609375\n",
      "Batch: 92, Loss: 0.8652786016464233, Accuracy: 0.716796875\n",
      "Batch: 93, Loss: 0.8757877349853516, Accuracy: 0.7041015625\n",
      "Batch: 94, Loss: 0.8403282165527344, Accuracy: 0.7353515625\n",
      "Batch: 95, Loss: 0.9205591082572937, Accuracy: 0.701171875\n",
      "Batch: 96, Loss: 0.8729178309440613, Accuracy: 0.7099609375\n",
      "Batch: 97, Loss: 0.7272403836250305, Accuracy: 0.755859375\n",
      "Batch: 98, Loss: 0.8142929077148438, Accuracy: 0.7392578125\n",
      "Batch: 99, Loss: 0.8020814657211304, Accuracy: 0.7421875\n",
      "Batch: 100, Loss: 0.8473669290542603, Accuracy: 0.7216796875\n",
      "Batch: 101, Loss: 0.9297603368759155, Accuracy: 0.6953125\n",
      "Batch: 102, Loss: 0.8685009479522705, Accuracy: 0.7080078125\n",
      "Batch: 103, Loss: 0.8970001339912415, Accuracy: 0.7177734375\n",
      "Batch: 104, Loss: 0.7981857061386108, Accuracy: 0.7333984375\n",
      "Batch: 105, Loss: 0.8731898665428162, Accuracy: 0.708984375\n",
      "Batch: 106, Loss: 0.8701586127281189, Accuracy: 0.7255859375\n",
      "Batch: 107, Loss: 0.8980540037155151, Accuracy: 0.7119140625\n",
      "Batch: 108, Loss: 0.85035640001297, Accuracy: 0.7001953125\n",
      "Batch: 109, Loss: 0.9691426157951355, Accuracy: 0.6787109375\n",
      "Batch: 110, Loss: 0.8095709681510925, Accuracy: 0.7275390625\n",
      "Batch: 111, Loss: 0.9514175653457642, Accuracy: 0.703125\n",
      "Batch: 112, Loss: 0.8878319263458252, Accuracy: 0.7109375\n",
      "Batch: 113, Loss: 0.9001419544219971, Accuracy: 0.7119140625\n",
      "Batch: 114, Loss: 0.976432204246521, Accuracy: 0.67578125\n",
      "Batch: 115, Loss: 0.9866199493408203, Accuracy: 0.6884765625\n",
      "Batch: 116, Loss: 0.9419654607772827, Accuracy: 0.7021484375\n",
      "Batch: 117, Loss: 0.9517379999160767, Accuracy: 0.701171875\n",
      "Batch: 118, Loss: 0.8007621169090271, Accuracy: 0.759765625\n",
      "Batch: 119, Loss: 0.7479169368743896, Accuracy: 0.7685546875\n",
      "Batch: 120, Loss: 0.9034246206283569, Accuracy: 0.7236328125\n",
      "Batch: 121, Loss: 0.9239325523376465, Accuracy: 0.7041015625\n",
      "Batch: 122, Loss: 0.8706560134887695, Accuracy: 0.71875\n",
      "Batch: 123, Loss: 0.8171478509902954, Accuracy: 0.748046875\n",
      "Batch: 124, Loss: 0.8997980356216431, Accuracy: 0.7255859375\n",
      "Batch: 125, Loss: 0.912371814250946, Accuracy: 0.697265625\n",
      "Batch: 126, Loss: 0.9224550724029541, Accuracy: 0.705078125\n",
      "Batch: 127, Loss: 0.8324661254882812, Accuracy: 0.734375\n",
      "Batch: 128, Loss: 0.9668313264846802, Accuracy: 0.7060546875\n",
      "Batch: 129, Loss: 0.8573471903800964, Accuracy: 0.7275390625\n",
      "Batch: 130, Loss: 0.9605429172515869, Accuracy: 0.6875\n",
      "Batch: 131, Loss: 0.8902419805526733, Accuracy: 0.7197265625\n",
      "Batch: 132, Loss: 0.9718359708786011, Accuracy: 0.689453125\n",
      "Batch: 133, Loss: 0.8686375021934509, Accuracy: 0.708984375\n",
      "Batch: 134, Loss: 0.9261753559112549, Accuracy: 0.703125\n",
      "Batch: 135, Loss: 0.8102682828903198, Accuracy: 0.732421875\n",
      "Batch: 136, Loss: 0.9137302041053772, Accuracy: 0.708984375\n",
      "Batch: 137, Loss: 0.8361952304840088, Accuracy: 0.7177734375\n",
      "Batch: 138, Loss: 0.771545946598053, Accuracy: 0.732421875\n",
      "Batch: 139, Loss: 0.8342652320861816, Accuracy: 0.720703125\n",
      "Batch: 140, Loss: 0.91358482837677, Accuracy: 0.69140625\n",
      "Batch: 141, Loss: 0.9286403059959412, Accuracy: 0.6943359375\n",
      "Batch: 142, Loss: 0.9480794668197632, Accuracy: 0.689453125\n",
      "Batch: 143, Loss: 0.9011054039001465, Accuracy: 0.7080078125\n",
      "Batch: 144, Loss: 0.8765718340873718, Accuracy: 0.7216796875\n",
      "Batch: 145, Loss: 0.8197934627532959, Accuracy: 0.71875\n",
      "Batch: 146, Loss: 0.9144862294197083, Accuracy: 0.6923828125\n",
      "Batch: 147, Loss: 0.9189472198486328, Accuracy: 0.6962890625\n",
      "Batch: 148, Loss: 1.0127646923065186, Accuracy: 0.66015625\n",
      "Batch: 149, Loss: 0.9075095653533936, Accuracy: 0.693359375\n",
      "Batch: 150, Loss: 0.8621695637702942, Accuracy: 0.716796875\n",
      "Batch: 151, Loss: 0.7750506401062012, Accuracy: 0.7431640625\n",
      "Epoch 23/90\n",
      "Batch: 1, Loss: 1.1178497076034546, Accuracy: 0.6298828125\n",
      "Batch: 2, Loss: 0.9933814406394958, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 0.8532750606536865, Accuracy: 0.708984375\n",
      "Batch: 4, Loss: 0.7782759070396423, Accuracy: 0.7568359375\n",
      "Batch: 5, Loss: 0.8100726008415222, Accuracy: 0.7216796875\n",
      "Batch: 6, Loss: 0.8915908932685852, Accuracy: 0.7041015625\n",
      "Batch: 7, Loss: 0.852851152420044, Accuracy: 0.6982421875\n",
      "Batch: 8, Loss: 0.8252443075180054, Accuracy: 0.7138671875\n",
      "Batch: 9, Loss: 0.7945878505706787, Accuracy: 0.759765625\n",
      "Batch: 10, Loss: 0.8139136433601379, Accuracy: 0.7314453125\n",
      "Batch: 11, Loss: 0.9610736966133118, Accuracy: 0.6904296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12, Loss: 0.9567327499389648, Accuracy: 0.6845703125\n",
      "Batch: 13, Loss: 0.7353897094726562, Accuracy: 0.7529296875\n",
      "Batch: 14, Loss: 0.950122594833374, Accuracy: 0.6796875\n",
      "Batch: 15, Loss: 0.8101899027824402, Accuracy: 0.7578125\n",
      "Batch: 16, Loss: 0.8314580917358398, Accuracy: 0.7294921875\n",
      "Batch: 17, Loss: 0.8892841935157776, Accuracy: 0.71484375\n",
      "Batch: 18, Loss: 0.9169343709945679, Accuracy: 0.7001953125\n",
      "Batch: 19, Loss: 0.9477822184562683, Accuracy: 0.697265625\n",
      "Batch: 20, Loss: 0.7861901521682739, Accuracy: 0.75\n",
      "Batch: 21, Loss: 0.8165140151977539, Accuracy: 0.7275390625\n",
      "Batch: 22, Loss: 0.9395201206207275, Accuracy: 0.708984375\n",
      "Batch: 23, Loss: 0.8875739574432373, Accuracy: 0.697265625\n",
      "Batch: 24, Loss: 0.8900089859962463, Accuracy: 0.701171875\n",
      "Batch: 25, Loss: 0.870529055595398, Accuracy: 0.720703125\n",
      "Batch: 26, Loss: 0.7733550071716309, Accuracy: 0.7314453125\n",
      "Batch: 27, Loss: 0.8154390454292297, Accuracy: 0.72265625\n",
      "Batch: 28, Loss: 0.9054840803146362, Accuracy: 0.701171875\n",
      "Batch: 29, Loss: 0.8831964731216431, Accuracy: 0.7158203125\n",
      "Batch: 30, Loss: 0.8217411637306213, Accuracy: 0.7294921875\n",
      "Batch: 31, Loss: 0.7883652448654175, Accuracy: 0.7490234375\n",
      "Batch: 32, Loss: 0.7908369302749634, Accuracy: 0.73046875\n",
      "Batch: 33, Loss: 0.9092378616333008, Accuracy: 0.70703125\n",
      "Batch: 34, Loss: 0.984083354473114, Accuracy: 0.689453125\n",
      "Batch: 35, Loss: 0.8852169513702393, Accuracy: 0.697265625\n",
      "Batch: 36, Loss: 0.9454892873764038, Accuracy: 0.7001953125\n",
      "Batch: 37, Loss: 0.8497722148895264, Accuracy: 0.71484375\n",
      "Batch: 38, Loss: 0.8788849115371704, Accuracy: 0.7109375\n",
      "Batch: 39, Loss: 0.8858227729797363, Accuracy: 0.7109375\n",
      "Batch: 40, Loss: 0.9046463966369629, Accuracy: 0.7080078125\n",
      "Batch: 41, Loss: 0.86785888671875, Accuracy: 0.720703125\n",
      "Batch: 42, Loss: 0.6897727251052856, Accuracy: 0.7666015625\n",
      "Batch: 43, Loss: 0.9084863662719727, Accuracy: 0.697265625\n",
      "Batch: 44, Loss: 0.8965795636177063, Accuracy: 0.703125\n",
      "Batch: 45, Loss: 0.7973232269287109, Accuracy: 0.7392578125\n",
      "Batch: 46, Loss: 0.8254733085632324, Accuracy: 0.732421875\n",
      "Batch: 47, Loss: 0.8298414349555969, Accuracy: 0.7431640625\n",
      "Batch: 48, Loss: 0.7791377305984497, Accuracy: 0.7255859375\n",
      "Batch: 49, Loss: 0.9506644606590271, Accuracy: 0.7041015625\n",
      "Batch: 50, Loss: 0.9010100364685059, Accuracy: 0.708984375\n",
      "Batch: 51, Loss: 0.9283851385116577, Accuracy: 0.7001953125\n",
      "Batch: 52, Loss: 0.915554940700531, Accuracy: 0.70703125\n",
      "Batch: 53, Loss: 0.7920494079589844, Accuracy: 0.7490234375\n",
      "Batch: 54, Loss: 0.8415844440460205, Accuracy: 0.740234375\n",
      "Batch: 55, Loss: 0.9394931197166443, Accuracy: 0.6826171875\n",
      "Batch: 56, Loss: 0.9339084625244141, Accuracy: 0.703125\n",
      "Batch: 57, Loss: 0.8745548725128174, Accuracy: 0.7197265625\n",
      "Batch: 58, Loss: 0.9597156047821045, Accuracy: 0.6962890625\n",
      "Batch: 59, Loss: 0.8345658779144287, Accuracy: 0.7294921875\n",
      "Batch: 60, Loss: 0.7870799899101257, Accuracy: 0.7392578125\n",
      "Batch: 61, Loss: 0.9028390645980835, Accuracy: 0.7080078125\n",
      "Batch: 62, Loss: 0.8154274821281433, Accuracy: 0.7421875\n",
      "Batch: 63, Loss: 0.8775629997253418, Accuracy: 0.7138671875\n",
      "Batch: 64, Loss: 0.8615679740905762, Accuracy: 0.716796875\n",
      "Batch: 65, Loss: 0.8710825443267822, Accuracy: 0.7109375\n",
      "Batch: 66, Loss: 0.8188889026641846, Accuracy: 0.75390625\n",
      "Batch: 67, Loss: 0.9049807190895081, Accuracy: 0.7109375\n",
      "Batch: 68, Loss: 0.9490047693252563, Accuracy: 0.693359375\n",
      "Batch: 69, Loss: 0.8876560926437378, Accuracy: 0.7099609375\n",
      "Batch: 70, Loss: 0.8424912095069885, Accuracy: 0.73046875\n",
      "Batch: 71, Loss: 0.8967031240463257, Accuracy: 0.7021484375\n",
      "Batch: 72, Loss: 0.7736803293228149, Accuracy: 0.73828125\n",
      "Batch: 73, Loss: 0.7839177250862122, Accuracy: 0.7578125\n",
      "Batch: 74, Loss: 0.7554408311843872, Accuracy: 0.7646484375\n",
      "Batch: 75, Loss: 0.768964946269989, Accuracy: 0.74609375\n",
      "Batch: 76, Loss: 0.8818379640579224, Accuracy: 0.697265625\n",
      "Batch: 77, Loss: 0.8188533782958984, Accuracy: 0.7392578125\n",
      "Batch: 78, Loss: 0.8075307607650757, Accuracy: 0.7353515625\n",
      "Batch: 79, Loss: 0.751862645149231, Accuracy: 0.7685546875\n",
      "Batch: 80, Loss: 0.835379421710968, Accuracy: 0.7265625\n",
      "Batch: 81, Loss: 0.9149906635284424, Accuracy: 0.681640625\n",
      "Batch: 82, Loss: 0.9113624691963196, Accuracy: 0.701171875\n",
      "Batch: 83, Loss: 0.7649394273757935, Accuracy: 0.75390625\n",
      "Batch: 84, Loss: 0.8499566316604614, Accuracy: 0.7197265625\n",
      "Batch: 85, Loss: 0.7598738074302673, Accuracy: 0.74609375\n",
      "Batch: 86, Loss: 0.9673442244529724, Accuracy: 0.6884765625\n",
      "Batch: 87, Loss: 0.8043036460876465, Accuracy: 0.7412109375\n",
      "Batch: 88, Loss: 0.8938606977462769, Accuracy: 0.7333984375\n",
      "Batch: 89, Loss: 0.8747323751449585, Accuracy: 0.7236328125\n",
      "Batch: 90, Loss: 0.7920186519622803, Accuracy: 0.736328125\n",
      "Batch: 91, Loss: 0.8713012933731079, Accuracy: 0.708984375\n",
      "Batch: 92, Loss: 0.8363334536552429, Accuracy: 0.7265625\n",
      "Batch: 93, Loss: 0.870415210723877, Accuracy: 0.70703125\n",
      "Batch: 94, Loss: 0.8241986036300659, Accuracy: 0.72265625\n",
      "Batch: 95, Loss: 0.862517774105072, Accuracy: 0.7109375\n",
      "Batch: 96, Loss: 0.8288456201553345, Accuracy: 0.7353515625\n",
      "Batch: 97, Loss: 0.7229046821594238, Accuracy: 0.7578125\n",
      "Batch: 98, Loss: 0.799357533454895, Accuracy: 0.740234375\n",
      "Batch: 99, Loss: 0.8057321310043335, Accuracy: 0.7275390625\n",
      "Batch: 100, Loss: 0.8545088171958923, Accuracy: 0.708984375\n",
      "Batch: 101, Loss: 0.9010559320449829, Accuracy: 0.7021484375\n",
      "Batch: 102, Loss: 0.8469278812408447, Accuracy: 0.7275390625\n",
      "Batch: 103, Loss: 0.8769150972366333, Accuracy: 0.7255859375\n",
      "Batch: 104, Loss: 0.8053874373435974, Accuracy: 0.7314453125\n",
      "Batch: 105, Loss: 0.876783013343811, Accuracy: 0.7109375\n",
      "Batch: 106, Loss: 0.8166265487670898, Accuracy: 0.73828125\n",
      "Batch: 107, Loss: 0.8734256029129028, Accuracy: 0.7099609375\n",
      "Batch: 108, Loss: 0.8432562351226807, Accuracy: 0.720703125\n",
      "Batch: 109, Loss: 0.9384169578552246, Accuracy: 0.6923828125\n",
      "Batch: 110, Loss: 0.7996235489845276, Accuracy: 0.740234375\n",
      "Batch: 111, Loss: 0.9100672006607056, Accuracy: 0.6923828125\n",
      "Batch: 112, Loss: 0.8570823073387146, Accuracy: 0.7216796875\n",
      "Batch: 113, Loss: 0.8722042441368103, Accuracy: 0.72265625\n",
      "Batch: 114, Loss: 0.9453172087669373, Accuracy: 0.6826171875\n",
      "Batch: 115, Loss: 0.979291558265686, Accuracy: 0.6943359375\n",
      "Batch: 116, Loss: 0.9112163782119751, Accuracy: 0.6884765625\n",
      "Batch: 117, Loss: 0.9476348161697388, Accuracy: 0.708984375\n",
      "Batch: 118, Loss: 0.7791296243667603, Accuracy: 0.75390625\n",
      "Batch: 119, Loss: 0.7630203366279602, Accuracy: 0.763671875\n",
      "Batch: 120, Loss: 0.887238085269928, Accuracy: 0.7216796875\n",
      "Batch: 121, Loss: 0.8963266611099243, Accuracy: 0.7099609375\n",
      "Batch: 122, Loss: 0.845151960849762, Accuracy: 0.7314453125\n",
      "Batch: 123, Loss: 0.7903338670730591, Accuracy: 0.748046875\n",
      "Batch: 124, Loss: 0.8954091668128967, Accuracy: 0.7060546875\n",
      "Batch: 125, Loss: 0.9033894538879395, Accuracy: 0.720703125\n",
      "Batch: 126, Loss: 0.8825668096542358, Accuracy: 0.7021484375\n",
      "Batch: 127, Loss: 0.8096228241920471, Accuracy: 0.751953125\n",
      "Batch: 128, Loss: 0.9629518985748291, Accuracy: 0.703125\n",
      "Batch: 129, Loss: 0.8480690121650696, Accuracy: 0.7353515625\n",
      "Batch: 130, Loss: 0.9910919070243835, Accuracy: 0.6748046875\n",
      "Batch: 131, Loss: 0.8994834423065186, Accuracy: 0.7060546875\n",
      "Batch: 132, Loss: 0.9249954223632812, Accuracy: 0.7041015625\n",
      "Batch: 133, Loss: 0.8409363031387329, Accuracy: 0.71875\n",
      "Batch: 134, Loss: 0.8921827077865601, Accuracy: 0.703125\n",
      "Batch: 135, Loss: 0.7987889051437378, Accuracy: 0.74609375\n",
      "Batch: 136, Loss: 0.8856042623519897, Accuracy: 0.71875\n",
      "Batch: 137, Loss: 0.8293874263763428, Accuracy: 0.712890625\n",
      "Batch: 138, Loss: 0.7419273853302002, Accuracy: 0.751953125\n",
      "Batch: 139, Loss: 0.8083882331848145, Accuracy: 0.7294921875\n",
      "Batch: 140, Loss: 0.901185154914856, Accuracy: 0.7041015625\n",
      "Batch: 141, Loss: 0.9305127859115601, Accuracy: 0.6787109375\n",
      "Batch: 142, Loss: 0.9074132442474365, Accuracy: 0.7138671875\n",
      "Batch: 143, Loss: 0.8712237477302551, Accuracy: 0.7197265625\n",
      "Batch: 144, Loss: 0.8534790277481079, Accuracy: 0.7216796875\n",
      "Batch: 145, Loss: 0.8368575572967529, Accuracy: 0.712890625\n",
      "Batch: 146, Loss: 0.9039427638053894, Accuracy: 0.6982421875\n",
      "Batch: 147, Loss: 0.8965462446212769, Accuracy: 0.6923828125\n",
      "Batch: 148, Loss: 0.9862109422683716, Accuracy: 0.6748046875\n",
      "Batch: 149, Loss: 0.8731671571731567, Accuracy: 0.7177734375\n",
      "Batch: 150, Loss: 0.8411096334457397, Accuracy: 0.7197265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 151, Loss: 0.7693880796432495, Accuracy: 0.75390625\n",
      "Epoch 24/90\n",
      "Batch: 1, Loss: 1.0785844326019287, Accuracy: 0.6533203125\n",
      "Batch: 2, Loss: 0.9772947430610657, Accuracy: 0.6708984375\n",
      "Batch: 3, Loss: 0.8847721815109253, Accuracy: 0.71875\n",
      "Batch: 4, Loss: 0.7643640041351318, Accuracy: 0.755859375\n",
      "Batch: 5, Loss: 0.7896583676338196, Accuracy: 0.74609375\n",
      "Batch: 6, Loss: 0.8827698230743408, Accuracy: 0.7109375\n",
      "Batch: 7, Loss: 0.8481519222259521, Accuracy: 0.71484375\n",
      "Batch: 8, Loss: 0.8153635859489441, Accuracy: 0.7177734375\n",
      "Batch: 9, Loss: 0.8185895085334778, Accuracy: 0.7421875\n",
      "Batch: 10, Loss: 0.8038444519042969, Accuracy: 0.7255859375\n",
      "Batch: 11, Loss: 0.9369837045669556, Accuracy: 0.6845703125\n",
      "Batch: 12, Loss: 0.9180045127868652, Accuracy: 0.6904296875\n",
      "Batch: 13, Loss: 0.7308282852172852, Accuracy: 0.7529296875\n",
      "Batch: 14, Loss: 0.9560455679893494, Accuracy: 0.701171875\n",
      "Batch: 15, Loss: 0.8148045539855957, Accuracy: 0.748046875\n",
      "Batch: 16, Loss: 0.7934617400169373, Accuracy: 0.751953125\n",
      "Batch: 17, Loss: 0.8788297176361084, Accuracy: 0.7041015625\n",
      "Batch: 18, Loss: 0.8661337494850159, Accuracy: 0.7138671875\n",
      "Batch: 19, Loss: 0.9227786660194397, Accuracy: 0.7021484375\n",
      "Batch: 20, Loss: 0.775309681892395, Accuracy: 0.74609375\n",
      "Batch: 21, Loss: 0.822243332862854, Accuracy: 0.708984375\n",
      "Batch: 22, Loss: 0.9113463759422302, Accuracy: 0.7021484375\n",
      "Batch: 23, Loss: 0.8762863874435425, Accuracy: 0.7060546875\n",
      "Batch: 24, Loss: 0.888282299041748, Accuracy: 0.6943359375\n",
      "Batch: 25, Loss: 0.8567911982536316, Accuracy: 0.7099609375\n",
      "Batch: 26, Loss: 0.7359354496002197, Accuracy: 0.755859375\n",
      "Batch: 27, Loss: 0.8469533920288086, Accuracy: 0.7109375\n",
      "Batch: 28, Loss: 0.9003588557243347, Accuracy: 0.701171875\n",
      "Batch: 29, Loss: 0.8458892107009888, Accuracy: 0.7197265625\n",
      "Batch: 30, Loss: 0.7890380024909973, Accuracy: 0.763671875\n",
      "Batch: 31, Loss: 0.7662903070449829, Accuracy: 0.7529296875\n",
      "Batch: 32, Loss: 0.7854955196380615, Accuracy: 0.740234375\n",
      "Batch: 33, Loss: 0.906390368938446, Accuracy: 0.7080078125\n",
      "Batch: 34, Loss: 0.9748716354370117, Accuracy: 0.6865234375\n",
      "Batch: 35, Loss: 0.8731531500816345, Accuracy: 0.7060546875\n",
      "Batch: 36, Loss: 0.9336457252502441, Accuracy: 0.7138671875\n",
      "Batch: 37, Loss: 0.8254694938659668, Accuracy: 0.73046875\n",
      "Batch: 38, Loss: 0.8552930951118469, Accuracy: 0.7265625\n",
      "Batch: 39, Loss: 0.8511507511138916, Accuracy: 0.728515625\n",
      "Batch: 40, Loss: 0.8519308567047119, Accuracy: 0.732421875\n",
      "Batch: 41, Loss: 0.8473541736602783, Accuracy: 0.736328125\n",
      "Batch: 42, Loss: 0.6791400909423828, Accuracy: 0.7705078125\n",
      "Batch: 43, Loss: 0.9068977236747742, Accuracy: 0.6962890625\n",
      "Batch: 44, Loss: 0.8716287612915039, Accuracy: 0.7216796875\n",
      "Batch: 45, Loss: 0.7798300981521606, Accuracy: 0.73046875\n",
      "Batch: 46, Loss: 0.8125433921813965, Accuracy: 0.7451171875\n",
      "Batch: 47, Loss: 0.8144177198410034, Accuracy: 0.7548828125\n",
      "Batch: 48, Loss: 0.7579478025436401, Accuracy: 0.73828125\n",
      "Batch: 49, Loss: 0.918577253818512, Accuracy: 0.708984375\n",
      "Batch: 50, Loss: 0.8762490153312683, Accuracy: 0.7236328125\n",
      "Batch: 51, Loss: 0.8981900215148926, Accuracy: 0.7041015625\n",
      "Batch: 52, Loss: 0.8788608312606812, Accuracy: 0.7177734375\n",
      "Batch: 53, Loss: 0.7829882502555847, Accuracy: 0.7392578125\n",
      "Batch: 54, Loss: 0.8376451730728149, Accuracy: 0.7177734375\n",
      "Batch: 55, Loss: 0.9279268383979797, Accuracy: 0.6943359375\n",
      "Batch: 56, Loss: 0.9137241244316101, Accuracy: 0.705078125\n",
      "Batch: 57, Loss: 0.8694865703582764, Accuracy: 0.70703125\n",
      "Batch: 58, Loss: 0.9277610182762146, Accuracy: 0.7109375\n",
      "Batch: 59, Loss: 0.8257936239242554, Accuracy: 0.740234375\n",
      "Batch: 60, Loss: 0.7769666314125061, Accuracy: 0.7421875\n",
      "Batch: 61, Loss: 0.8794924020767212, Accuracy: 0.703125\n",
      "Batch: 62, Loss: 0.8014498949050903, Accuracy: 0.73046875\n",
      "Batch: 63, Loss: 0.8561064004898071, Accuracy: 0.7216796875\n",
      "Batch: 64, Loss: 0.8134981393814087, Accuracy: 0.7265625\n",
      "Batch: 65, Loss: 0.8594722747802734, Accuracy: 0.7275390625\n",
      "Batch: 66, Loss: 0.8120396137237549, Accuracy: 0.7529296875\n",
      "Batch: 67, Loss: 0.8885719180107117, Accuracy: 0.71484375\n",
      "Batch: 68, Loss: 0.9237432479858398, Accuracy: 0.7041015625\n",
      "Batch: 69, Loss: 0.867149829864502, Accuracy: 0.716796875\n",
      "Batch: 70, Loss: 0.8183848857879639, Accuracy: 0.740234375\n",
      "Batch: 71, Loss: 0.8868274688720703, Accuracy: 0.703125\n",
      "Batch: 72, Loss: 0.7509584426879883, Accuracy: 0.751953125\n",
      "Batch: 73, Loss: 0.7860434651374817, Accuracy: 0.7470703125\n",
      "Batch: 74, Loss: 0.7391808032989502, Accuracy: 0.755859375\n",
      "Batch: 75, Loss: 0.7606436014175415, Accuracy: 0.7490234375\n",
      "Batch: 76, Loss: 0.8541297316551208, Accuracy: 0.7216796875\n",
      "Batch: 77, Loss: 0.7984157204627991, Accuracy: 0.7470703125\n",
      "Batch: 78, Loss: 0.7759661078453064, Accuracy: 0.7451171875\n",
      "Batch: 79, Loss: 0.7465713620185852, Accuracy: 0.7705078125\n",
      "Batch: 80, Loss: 0.8092235922813416, Accuracy: 0.724609375\n",
      "Batch: 81, Loss: 0.9049903154373169, Accuracy: 0.685546875\n",
      "Batch: 82, Loss: 0.8757399320602417, Accuracy: 0.7080078125\n",
      "Batch: 83, Loss: 0.7311276793479919, Accuracy: 0.7607421875\n",
      "Batch: 84, Loss: 0.8316045999526978, Accuracy: 0.7353515625\n",
      "Batch: 85, Loss: 0.7446917295455933, Accuracy: 0.76953125\n",
      "Batch: 86, Loss: 0.9335152506828308, Accuracy: 0.7080078125\n",
      "Batch: 87, Loss: 0.7612876296043396, Accuracy: 0.765625\n",
      "Batch: 88, Loss: 0.8956751823425293, Accuracy: 0.732421875\n",
      "Batch: 89, Loss: 0.9054096341133118, Accuracy: 0.7177734375\n",
      "Batch: 90, Loss: 0.7857497930526733, Accuracy: 0.744140625\n",
      "Batch: 91, Loss: 0.8444550633430481, Accuracy: 0.7109375\n",
      "Batch: 92, Loss: 0.8432589769363403, Accuracy: 0.7275390625\n",
      "Batch: 93, Loss: 0.8479087948799133, Accuracy: 0.7158203125\n",
      "Batch: 94, Loss: 0.8175464868545532, Accuracy: 0.7392578125\n",
      "Batch: 95, Loss: 0.8764376640319824, Accuracy: 0.7060546875\n",
      "Batch: 96, Loss: 0.8427839279174805, Accuracy: 0.72265625\n",
      "Batch: 97, Loss: 0.7339043617248535, Accuracy: 0.75390625\n",
      "Batch: 98, Loss: 0.7916347980499268, Accuracy: 0.7587890625\n",
      "Batch: 99, Loss: 0.7911036610603333, Accuracy: 0.74609375\n",
      "Batch: 100, Loss: 0.8248305320739746, Accuracy: 0.72265625\n",
      "Batch: 101, Loss: 0.8642960786819458, Accuracy: 0.7236328125\n",
      "Batch: 102, Loss: 0.8517190217971802, Accuracy: 0.720703125\n",
      "Batch: 103, Loss: 0.8370686769485474, Accuracy: 0.73828125\n",
      "Batch: 104, Loss: 0.7540319561958313, Accuracy: 0.7548828125\n",
      "Batch: 105, Loss: 0.8316155076026917, Accuracy: 0.732421875\n",
      "Batch: 106, Loss: 0.8025850057601929, Accuracy: 0.736328125\n",
      "Batch: 107, Loss: 0.81618732213974, Accuracy: 0.7421875\n",
      "Batch: 108, Loss: 0.8168551921844482, Accuracy: 0.712890625\n",
      "Batch: 109, Loss: 0.924308180809021, Accuracy: 0.69921875\n",
      "Batch: 110, Loss: 0.7863916158676147, Accuracy: 0.7412109375\n",
      "Batch: 111, Loss: 0.9049252271652222, Accuracy: 0.693359375\n",
      "Batch: 112, Loss: 0.8255414962768555, Accuracy: 0.7275390625\n",
      "Batch: 113, Loss: 0.8329024910926819, Accuracy: 0.7314453125\n",
      "Batch: 114, Loss: 0.9267845153808594, Accuracy: 0.693359375\n",
      "Batch: 115, Loss: 0.9341453313827515, Accuracy: 0.705078125\n",
      "Batch: 116, Loss: 0.8809147477149963, Accuracy: 0.7138671875\n",
      "Batch: 117, Loss: 0.9419456124305725, Accuracy: 0.7060546875\n",
      "Batch: 118, Loss: 0.7473857402801514, Accuracy: 0.765625\n",
      "Batch: 119, Loss: 0.7393050193786621, Accuracy: 0.7763671875\n",
      "Batch: 120, Loss: 0.8635921478271484, Accuracy: 0.720703125\n",
      "Batch: 121, Loss: 0.8779721856117249, Accuracy: 0.724609375\n",
      "Batch: 122, Loss: 0.842723548412323, Accuracy: 0.73046875\n",
      "Batch: 123, Loss: 0.7946270704269409, Accuracy: 0.7421875\n",
      "Batch: 124, Loss: 0.8934440016746521, Accuracy: 0.71484375\n",
      "Batch: 125, Loss: 0.8953503370285034, Accuracy: 0.7138671875\n",
      "Batch: 126, Loss: 0.8909980654716492, Accuracy: 0.708984375\n",
      "Batch: 127, Loss: 0.7623562216758728, Accuracy: 0.7626953125\n",
      "Batch: 128, Loss: 0.917363166809082, Accuracy: 0.72265625\n",
      "Batch: 129, Loss: 0.7742742300033569, Accuracy: 0.7578125\n",
      "Batch: 130, Loss: 0.989486813545227, Accuracy: 0.6806640625\n",
      "Batch: 131, Loss: 0.8815498352050781, Accuracy: 0.6953125\n",
      "Batch: 132, Loss: 0.9223476648330688, Accuracy: 0.705078125\n",
      "Batch: 133, Loss: 0.8381518125534058, Accuracy: 0.728515625\n",
      "Batch: 134, Loss: 0.8661043643951416, Accuracy: 0.7177734375\n",
      "Batch: 135, Loss: 0.7858188152313232, Accuracy: 0.7353515625\n",
      "Batch: 136, Loss: 0.8910439014434814, Accuracy: 0.7255859375\n",
      "Batch: 137, Loss: 0.8404725790023804, Accuracy: 0.7197265625\n",
      "Batch: 138, Loss: 0.7413011789321899, Accuracy: 0.7509765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 139, Loss: 0.7923651933670044, Accuracy: 0.7333984375\n",
      "Batch: 140, Loss: 0.8677374720573425, Accuracy: 0.7177734375\n",
      "Batch: 141, Loss: 0.8965147733688354, Accuracy: 0.6884765625\n",
      "Batch: 142, Loss: 0.905117928981781, Accuracy: 0.7099609375\n",
      "Batch: 143, Loss: 0.8509299755096436, Accuracy: 0.716796875\n",
      "Batch: 144, Loss: 0.842041552066803, Accuracy: 0.724609375\n",
      "Batch: 145, Loss: 0.7977395057678223, Accuracy: 0.7119140625\n",
      "Batch: 146, Loss: 0.8613691926002502, Accuracy: 0.716796875\n",
      "Batch: 147, Loss: 0.8740338087081909, Accuracy: 0.7109375\n",
      "Batch: 148, Loss: 0.942173182964325, Accuracy: 0.69140625\n",
      "Batch: 149, Loss: 0.8412116169929504, Accuracy: 0.7177734375\n",
      "Batch: 150, Loss: 0.8256493806838989, Accuracy: 0.7294921875\n",
      "Batch: 151, Loss: 0.7345962524414062, Accuracy: 0.751953125\n",
      "Epoch 25/90\n",
      "Batch: 1, Loss: 1.0608643293380737, Accuracy: 0.6533203125\n",
      "Batch: 2, Loss: 0.9307743906974792, Accuracy: 0.689453125\n",
      "Batch: 3, Loss: 0.8289493918418884, Accuracy: 0.724609375\n",
      "Batch: 4, Loss: 0.7501431703567505, Accuracy: 0.765625\n",
      "Batch: 5, Loss: 0.7539176344871521, Accuracy: 0.7626953125\n",
      "Batch: 6, Loss: 0.8640924096107483, Accuracy: 0.7021484375\n",
      "Batch: 7, Loss: 0.8078180551528931, Accuracy: 0.7275390625\n",
      "Batch: 8, Loss: 0.8061131834983826, Accuracy: 0.73046875\n",
      "Batch: 9, Loss: 0.779358983039856, Accuracy: 0.7607421875\n",
      "Batch: 10, Loss: 0.7562482953071594, Accuracy: 0.7490234375\n",
      "Batch: 11, Loss: 0.8805421590805054, Accuracy: 0.7119140625\n",
      "Batch: 12, Loss: 0.894012451171875, Accuracy: 0.708984375\n",
      "Batch: 13, Loss: 0.6856056451797485, Accuracy: 0.775390625\n",
      "Batch: 14, Loss: 0.9443577527999878, Accuracy: 0.6875\n",
      "Batch: 15, Loss: 0.7911649942398071, Accuracy: 0.75390625\n",
      "Batch: 16, Loss: 0.7972283363342285, Accuracy: 0.7431640625\n",
      "Batch: 17, Loss: 0.8594942092895508, Accuracy: 0.724609375\n",
      "Batch: 18, Loss: 0.8443542718887329, Accuracy: 0.734375\n",
      "Batch: 19, Loss: 0.8821721076965332, Accuracy: 0.7177734375\n",
      "Batch: 20, Loss: 0.7407190799713135, Accuracy: 0.755859375\n",
      "Batch: 21, Loss: 0.7789254188537598, Accuracy: 0.7314453125\n",
      "Batch: 22, Loss: 0.9017814993858337, Accuracy: 0.716796875\n",
      "Batch: 23, Loss: 0.8596847653388977, Accuracy: 0.7197265625\n",
      "Batch: 24, Loss: 0.8390267491340637, Accuracy: 0.720703125\n",
      "Batch: 25, Loss: 0.8490155339241028, Accuracy: 0.72265625\n",
      "Batch: 26, Loss: 0.7461673617362976, Accuracy: 0.7470703125\n",
      "Batch: 27, Loss: 0.7992188930511475, Accuracy: 0.736328125\n",
      "Batch: 28, Loss: 0.8686313629150391, Accuracy: 0.6845703125\n",
      "Batch: 29, Loss: 0.8345685005187988, Accuracy: 0.7236328125\n",
      "Batch: 30, Loss: 0.7790219187736511, Accuracy: 0.7529296875\n",
      "Batch: 31, Loss: 0.7715309858322144, Accuracy: 0.75390625\n",
      "Batch: 32, Loss: 0.7510970830917358, Accuracy: 0.75\n",
      "Batch: 33, Loss: 0.9055856466293335, Accuracy: 0.7021484375\n",
      "Batch: 34, Loss: 0.929242730140686, Accuracy: 0.7060546875\n",
      "Batch: 35, Loss: 0.8329626321792603, Accuracy: 0.724609375\n",
      "Batch: 36, Loss: 0.9166957139968872, Accuracy: 0.7197265625\n",
      "Batch: 37, Loss: 0.8390158414840698, Accuracy: 0.71875\n",
      "Batch: 38, Loss: 0.8478137254714966, Accuracy: 0.71484375\n",
      "Batch: 39, Loss: 0.8533233404159546, Accuracy: 0.734375\n",
      "Batch: 40, Loss: 0.8606177568435669, Accuracy: 0.73046875\n",
      "Batch: 41, Loss: 0.8218405842781067, Accuracy: 0.7451171875\n",
      "Batch: 42, Loss: 0.6671069264411926, Accuracy: 0.78125\n",
      "Batch: 43, Loss: 0.8906067609786987, Accuracy: 0.70703125\n",
      "Batch: 44, Loss: 0.8688175678253174, Accuracy: 0.71484375\n",
      "Batch: 45, Loss: 0.7612062692642212, Accuracy: 0.7451171875\n",
      "Batch: 46, Loss: 0.7836635112762451, Accuracy: 0.7451171875\n",
      "Batch: 47, Loss: 0.7822293639183044, Accuracy: 0.763671875\n",
      "Batch: 48, Loss: 0.7348555326461792, Accuracy: 0.75390625\n",
      "Batch: 49, Loss: 0.8961786031723022, Accuracy: 0.7119140625\n",
      "Batch: 50, Loss: 0.8520750999450684, Accuracy: 0.716796875\n",
      "Batch: 51, Loss: 0.8668786287307739, Accuracy: 0.71875\n",
      "Batch: 52, Loss: 0.8792749643325806, Accuracy: 0.7275390625\n",
      "Batch: 53, Loss: 0.7594689130783081, Accuracy: 0.759765625\n",
      "Batch: 54, Loss: 0.8137638568878174, Accuracy: 0.728515625\n",
      "Batch: 55, Loss: 0.9136268496513367, Accuracy: 0.7021484375\n",
      "Batch: 56, Loss: 0.8965751528739929, Accuracy: 0.701171875\n",
      "Batch: 57, Loss: 0.8298966884613037, Accuracy: 0.7333984375\n",
      "Batch: 58, Loss: 0.8899749517440796, Accuracy: 0.7080078125\n",
      "Batch: 59, Loss: 0.8105828762054443, Accuracy: 0.734375\n",
      "Batch: 60, Loss: 0.7536790370941162, Accuracy: 0.75\n",
      "Batch: 61, Loss: 0.8844884037971497, Accuracy: 0.708984375\n",
      "Batch: 62, Loss: 0.7805025577545166, Accuracy: 0.7451171875\n",
      "Batch: 63, Loss: 0.8572410345077515, Accuracy: 0.7197265625\n",
      "Batch: 64, Loss: 0.8161466717720032, Accuracy: 0.7373046875\n",
      "Batch: 65, Loss: 0.8504630327224731, Accuracy: 0.720703125\n",
      "Batch: 66, Loss: 0.7986346483230591, Accuracy: 0.7421875\n",
      "Batch: 67, Loss: 0.9083966016769409, Accuracy: 0.701171875\n",
      "Batch: 68, Loss: 0.9009662866592407, Accuracy: 0.712890625\n",
      "Batch: 69, Loss: 0.8665096163749695, Accuracy: 0.7177734375\n",
      "Batch: 70, Loss: 0.8073973655700684, Accuracy: 0.740234375\n",
      "Batch: 71, Loss: 0.854117751121521, Accuracy: 0.7099609375\n",
      "Batch: 72, Loss: 0.7488336563110352, Accuracy: 0.7529296875\n",
      "Batch: 73, Loss: 0.7843314409255981, Accuracy: 0.7568359375\n",
      "Batch: 74, Loss: 0.7204157710075378, Accuracy: 0.7802734375\n",
      "Batch: 75, Loss: 0.7085980176925659, Accuracy: 0.765625\n",
      "Batch: 76, Loss: 0.8425418734550476, Accuracy: 0.720703125\n",
      "Batch: 77, Loss: 0.7639236450195312, Accuracy: 0.744140625\n",
      "Batch: 78, Loss: 0.761979341506958, Accuracy: 0.755859375\n",
      "Batch: 79, Loss: 0.7304917573928833, Accuracy: 0.7685546875\n",
      "Batch: 80, Loss: 0.8105440735816956, Accuracy: 0.7294921875\n",
      "Batch: 81, Loss: 0.8930986523628235, Accuracy: 0.6923828125\n",
      "Batch: 82, Loss: 0.8640987873077393, Accuracy: 0.7080078125\n",
      "Batch: 83, Loss: 0.7296179533004761, Accuracy: 0.767578125\n",
      "Batch: 84, Loss: 0.8463777303695679, Accuracy: 0.73046875\n",
      "Batch: 85, Loss: 0.7627384662628174, Accuracy: 0.7607421875\n",
      "Batch: 86, Loss: 0.9357520341873169, Accuracy: 0.6875\n",
      "Batch: 87, Loss: 0.7944208383560181, Accuracy: 0.74609375\n",
      "Batch: 88, Loss: 0.8713104724884033, Accuracy: 0.7333984375\n",
      "Batch: 89, Loss: 0.8564894795417786, Accuracy: 0.73046875\n",
      "Batch: 90, Loss: 0.7674604654312134, Accuracy: 0.751953125\n",
      "Batch: 91, Loss: 0.8545233607292175, Accuracy: 0.716796875\n",
      "Batch: 92, Loss: 0.8092433214187622, Accuracy: 0.736328125\n",
      "Batch: 93, Loss: 0.8322112560272217, Accuracy: 0.7294921875\n",
      "Batch: 94, Loss: 0.7849789261817932, Accuracy: 0.744140625\n",
      "Batch: 95, Loss: 0.8801771402359009, Accuracy: 0.6953125\n",
      "Batch: 96, Loss: 0.8037497997283936, Accuracy: 0.734375\n",
      "Batch: 97, Loss: 0.6908785104751587, Accuracy: 0.75390625\n",
      "Batch: 98, Loss: 0.7945358753204346, Accuracy: 0.7431640625\n",
      "Batch: 99, Loss: 0.7677158117294312, Accuracy: 0.7509765625\n",
      "Batch: 100, Loss: 0.807033896446228, Accuracy: 0.7392578125\n",
      "Batch: 101, Loss: 0.8334411382675171, Accuracy: 0.73046875\n",
      "Batch: 102, Loss: 0.8231663107872009, Accuracy: 0.7255859375\n",
      "Batch: 103, Loss: 0.826028048992157, Accuracy: 0.736328125\n",
      "Batch: 104, Loss: 0.7472683191299438, Accuracy: 0.74609375\n",
      "Batch: 105, Loss: 0.8177522420883179, Accuracy: 0.7353515625\n",
      "Batch: 106, Loss: 0.7709822058677673, Accuracy: 0.7509765625\n",
      "Batch: 107, Loss: 0.815523624420166, Accuracy: 0.75\n",
      "Batch: 108, Loss: 0.8087106943130493, Accuracy: 0.7275390625\n",
      "Batch: 109, Loss: 0.9057021141052246, Accuracy: 0.701171875\n",
      "Batch: 110, Loss: 0.7692865133285522, Accuracy: 0.7412109375\n",
      "Batch: 111, Loss: 0.8701193332672119, Accuracy: 0.7177734375\n",
      "Batch: 112, Loss: 0.846479058265686, Accuracy: 0.736328125\n",
      "Batch: 113, Loss: 0.8213822245597839, Accuracy: 0.7392578125\n",
      "Batch: 114, Loss: 0.9177341461181641, Accuracy: 0.7001953125\n",
      "Batch: 115, Loss: 0.9382066130638123, Accuracy: 0.7236328125\n",
      "Batch: 116, Loss: 0.8683574199676514, Accuracy: 0.7158203125\n",
      "Batch: 117, Loss: 0.8777101039886475, Accuracy: 0.71875\n",
      "Batch: 118, Loss: 0.7421269416809082, Accuracy: 0.7578125\n",
      "Batch: 119, Loss: 0.7035354375839233, Accuracy: 0.7802734375\n",
      "Batch: 120, Loss: 0.8358965516090393, Accuracy: 0.7333984375\n",
      "Batch: 121, Loss: 0.8699127435684204, Accuracy: 0.7021484375\n",
      "Batch: 122, Loss: 0.8106374740600586, Accuracy: 0.740234375\n",
      "Batch: 123, Loss: 0.7596954107284546, Accuracy: 0.7587890625\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv(os.path.join(data_directory, \"log.csv\"))\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
